{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 태양광 발전량 예측 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 충북 진천군의 2019년 7월 1일부터 2020년 6월 30일의 1년치 태양광 발전량 데이터\n",
    "\n",
    "\n",
    "- 2020년 1월 31일, 2020년 3월 31일, 2020년 5월 31일을 예측\n",
    "\n",
    "\n",
    "- 하루동안의 데이터는 96개의 데이터가 생성\n",
    "\n",
    "\n",
    "- 데이터는 15분 당 한개씩 생성\n",
    "\n",
    "\n",
    "- 데이터 구조\n",
    "    - 00:00:00 ~ 05:00:00 이 기간은 value=0 (20개) \n",
    "    - 05:15:00 ~ 20:00:00 이 기간은 value=? (63개)\n",
    "    - 21:00:00 ~ 23:00:00 이 기간은 value=0 (13개)\n",
    "    \n",
    "- 총 63개의 각 시간을 맞추는 데이터를 분리하고 모델 생성\n",
    "\n",
    "-> 15분 단위를 1시간 단위로 변경\n",
    "- 데이터 구조    \n",
    "    - 00:00:00 ~ 04:00:00 이 기간의 value = 0(5개)\n",
    "    - 05:00:00 ~ 21:00:00 이 기간의 value = ?(17개)\n",
    "    - 22:00:00 ~ 23:00:00 이 기간의 value = 0(2개)\n",
    "    \n",
    "    17개의 각 시간을 맞추는 데이터를 분리하고 모델 생성 모델 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 총 용량 133kw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 라이브러리 및 환경 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names1 = ['Date', 'Temp','Prec','Wind_S','Wind_D','Humidity','Pressure','Sunshine','Insolation','Snow','Cloud','Municipal','Ground temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/SolarPV_Elec_Problem.csv\", header=None, names=[\"Date\", \"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-01T00:00:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-01T00:15:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-01T00:30:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-01T00:45:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-01T01:00:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date  Value\n",
       "0  2019-07-01T00:00:00+09:00    0.0\n",
       "1  2019-07-01T00:15:00+09:00    0.0\n",
       "2  2019-07-01T00:30:00+09:00    0.0\n",
       "3  2019-07-01T00:45:00+09:00    0.0\n",
       "4  2019-07-01T01:00:00+09:00    0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OH59fBgbRLvm"
   },
   "outputs": [],
   "source": [
    "def utc_change (string) : \n",
    "    year = string[:4]\n",
    "    month = string[5:7]\n",
    "    day = string[8:10]\n",
    "    hour = string[11:13]\n",
    "    if hour in \":\" :\n",
    "        hour == int(string[11:12])\n",
    "    else : \n",
    "        hour == int(string[11:13])\n",
    "    minute = string[14:16]\n",
    "    second = string[17:19]\n",
    "    \n",
    "    date = year + \"-\" + month + \"-\" + day + \" \" + str(hour)\n",
    "\n",
    "    return date\n",
    "utc_change(data.loc[0][\"Date\"])\n",
    "data['Date'] = data['Date'].apply(lambda x :utc_change(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K_A0xtHEzaJh"
   },
   "outputs": [],
   "source": [
    "data['Date'] = pd.to_datetime(data['Date'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GhoR_EO77Qki"
   },
   "source": [
    "### 1시간 단위로 변환 후 데이터 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "odKDJ8ST8CIU"
   },
   "outputs": [],
   "source": [
    "data2=data.resample('H', on='Date').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U0O23kRRpoh-"
   },
   "outputs": [],
   "source": [
    "data2[\"Value\"] = data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Value = pd.DataFrame(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value    8782\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Value.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-06-30 17:00:00</th>\n",
       "      <td>7.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-30 18:00:00</th>\n",
       "      <td>3.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-30 19:00:00</th>\n",
       "      <td>0.467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-30 20:00:00</th>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-30 21:00:00</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Value\n",
       "Date                      \n",
       "2020-06-30 17:00:00  7.880\n",
       "2020-06-30 18:00:00  3.408\n",
       "2020-06-30 19:00:00  0.467\n",
       "2020-06-30 20:00:00  0.020\n",
       "2020-06-30 21:00:00  0.000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Value.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-07-01 00:00:00+09:00', '2019-07-01 01:00:00+09:00',\n",
       "               '2019-07-01 02:00:00+09:00', '2019-07-01 03:00:00+09:00',\n",
       "               '2019-07-01 04:00:00+09:00', '2019-07-01 05:00:00+09:00',\n",
       "               '2019-07-01 06:00:00+09:00', '2019-07-01 07:00:00+09:00',\n",
       "               '2019-07-01 08:00:00+09:00', '2019-07-01 09:00:00+09:00',\n",
       "               ...\n",
       "               '2020-06-30 12:00:00+09:00', '2020-06-30 13:00:00+09:00',\n",
       "               '2020-06-30 14:00:00+09:00', '2020-06-30 15:00:00+09:00',\n",
       "               '2020-06-30 16:00:00+09:00', '2020-06-30 17:00:00+09:00',\n",
       "               '2020-06-30 18:00:00+09:00', '2020-06-30 19:00:00+09:00',\n",
       "               '2020-06-30 20:00:00+09:00', '2020-06-30 21:00:00+09:00'],\n",
       "              dtype='datetime64[ns, Asia/Seoul]', length=8782, freq='H')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_date= pd.date_range(start = \"2019-07-01 00:00:00\", end = \"2020-06-30 21:00:00\", freq = \"H\",tz = 'Asia/Seoul')\n",
    "new_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_date= pd.date_range(start = \"2019-07-01 00:00:00\", end = \"2020-06-30 21:00:00\", freq = \"H\", tz = 'Asia/Seoul')\n",
    "\n",
    "data3 = pd.DataFrame({\"Date\" : new_date, \"Value\" : data2[\"Value\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-01 00:00:00</th>\n",
       "      <td>2019-07-01 00:00:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-01 01:00:00</th>\n",
       "      <td>2019-07-01 01:00:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-01 02:00:00</th>\n",
       "      <td>2019-07-01 02:00:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-01 03:00:00</th>\n",
       "      <td>2019-07-01 03:00:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-01 04:00:00</th>\n",
       "      <td>2019-07-01 04:00:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Date  Value\n",
       "Date                                                \n",
       "2019-07-01 00:00:00 2019-07-01 00:00:00+09:00    0.0\n",
       "2019-07-01 01:00:00 2019-07-01 01:00:00+09:00    0.0\n",
       "2019-07-01 02:00:00 2019-07-01 02:00:00+09:00    0.0\n",
       "2019-07-01 03:00:00 2019-07-01 03:00:00+09:00    0.0\n",
       "2019-07-01 04:00:00 2019-07-01 04:00:00+09:00    0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "data3['2020-01-31']['Value'] = np.nan\n",
    "data3['2020-03-31']['Value'] = np.nan\n",
    "data3['2020-05-31']['Value'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data3.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8032</th>\n",
       "      <td>2020-05-30 16:00:00+09:00</td>\n",
       "      <td>46.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8033</th>\n",
       "      <td>2020-05-30 17:00:00+09:00</td>\n",
       "      <td>28.297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8034</th>\n",
       "      <td>2020-05-30 18:00:00+09:00</td>\n",
       "      <td>11.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8035</th>\n",
       "      <td>2020-05-30 19:00:00+09:00</td>\n",
       "      <td>2.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8036</th>\n",
       "      <td>2020-05-30 20:00:00+09:00</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8037</th>\n",
       "      <td>2020-05-30 21:00:00+09:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8038</th>\n",
       "      <td>2020-05-30 22:00:00+09:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8039</th>\n",
       "      <td>2020-05-30 23:00:00+09:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8040</th>\n",
       "      <td>2020-05-31 00:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8041</th>\n",
       "      <td>2020-05-31 01:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8042</th>\n",
       "      <td>2020-05-31 02:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8043</th>\n",
       "      <td>2020-05-31 03:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8044</th>\n",
       "      <td>2020-05-31 04:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8045</th>\n",
       "      <td>2020-05-31 05:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8046</th>\n",
       "      <td>2020-05-31 06:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8047</th>\n",
       "      <td>2020-05-31 07:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8048</th>\n",
       "      <td>2020-05-31 08:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8049</th>\n",
       "      <td>2020-05-31 09:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8050</th>\n",
       "      <td>2020-05-31 10:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8051</th>\n",
       "      <td>2020-05-31 11:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8052</th>\n",
       "      <td>2020-05-31 12:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8053</th>\n",
       "      <td>2020-05-31 13:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8054</th>\n",
       "      <td>2020-05-31 14:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8055</th>\n",
       "      <td>2020-05-31 15:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8056</th>\n",
       "      <td>2020-05-31 16:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8057</th>\n",
       "      <td>2020-05-31 17:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8058</th>\n",
       "      <td>2020-05-31 18:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8059</th>\n",
       "      <td>2020-05-31 19:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8060</th>\n",
       "      <td>2020-05-31 20:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8061</th>\n",
       "      <td>2020-05-31 21:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8752</th>\n",
       "      <td>2020-06-29 16:00:00+09:00</td>\n",
       "      <td>11.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8753</th>\n",
       "      <td>2020-06-29 17:00:00+09:00</td>\n",
       "      <td>4.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8754</th>\n",
       "      <td>2020-06-29 18:00:00+09:00</td>\n",
       "      <td>1.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8755</th>\n",
       "      <td>2020-06-29 19:00:00+09:00</td>\n",
       "      <td>0.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8756</th>\n",
       "      <td>2020-06-29 20:00:00+09:00</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>2020-06-29 21:00:00+09:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>2020-06-29 22:00:00+09:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>2020-06-29 23:00:00+09:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8760</th>\n",
       "      <td>2020-06-30 00:00:00+09:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8761</th>\n",
       "      <td>2020-06-30 01:00:00+09:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8762</th>\n",
       "      <td>2020-06-30 02:00:00+09:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8763</th>\n",
       "      <td>2020-06-30 03:00:00+09:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8764</th>\n",
       "      <td>2020-06-30 04:00:00+09:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8765</th>\n",
       "      <td>2020-06-30 05:00:00+09:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8766</th>\n",
       "      <td>2020-06-30 06:00:00+09:00</td>\n",
       "      <td>0.614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8767</th>\n",
       "      <td>2020-06-30 07:00:00+09:00</td>\n",
       "      <td>3.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8768</th>\n",
       "      <td>2020-06-30 08:00:00+09:00</td>\n",
       "      <td>7.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8769</th>\n",
       "      <td>2020-06-30 09:00:00+09:00</td>\n",
       "      <td>16.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8770</th>\n",
       "      <td>2020-06-30 10:00:00+09:00</td>\n",
       "      <td>19.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8771</th>\n",
       "      <td>2020-06-30 11:00:00+09:00</td>\n",
       "      <td>19.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8772</th>\n",
       "      <td>2020-06-30 12:00:00+09:00</td>\n",
       "      <td>25.391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8773</th>\n",
       "      <td>2020-06-30 13:00:00+09:00</td>\n",
       "      <td>19.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8774</th>\n",
       "      <td>2020-06-30 14:00:00+09:00</td>\n",
       "      <td>10.835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8775</th>\n",
       "      <td>2020-06-30 15:00:00+09:00</td>\n",
       "      <td>15.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8776</th>\n",
       "      <td>2020-06-30 16:00:00+09:00</td>\n",
       "      <td>11.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8777</th>\n",
       "      <td>2020-06-30 17:00:00+09:00</td>\n",
       "      <td>7.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8778</th>\n",
       "      <td>2020-06-30 18:00:00+09:00</td>\n",
       "      <td>3.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8779</th>\n",
       "      <td>2020-06-30 19:00:00+09:00</td>\n",
       "      <td>0.467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780</th>\n",
       "      <td>2020-06-30 20:00:00+09:00</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8781</th>\n",
       "      <td>2020-06-30 21:00:00+09:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Date   Value\n",
       "8032 2020-05-30 16:00:00+09:00  46.671\n",
       "8033 2020-05-30 17:00:00+09:00  28.297\n",
       "8034 2020-05-30 18:00:00+09:00  11.976\n",
       "8035 2020-05-30 19:00:00+09:00   2.583\n",
       "8036 2020-05-30 20:00:00+09:00   0.028\n",
       "8037 2020-05-30 21:00:00+09:00   0.000\n",
       "8038 2020-05-30 22:00:00+09:00   0.000\n",
       "8039 2020-05-30 23:00:00+09:00   0.000\n",
       "8040 2020-05-31 00:00:00+09:00     NaN\n",
       "8041 2020-05-31 01:00:00+09:00     NaN\n",
       "8042 2020-05-31 02:00:00+09:00     NaN\n",
       "8043 2020-05-31 03:00:00+09:00     NaN\n",
       "8044 2020-05-31 04:00:00+09:00     NaN\n",
       "8045 2020-05-31 05:00:00+09:00     NaN\n",
       "8046 2020-05-31 06:00:00+09:00     NaN\n",
       "8047 2020-05-31 07:00:00+09:00     NaN\n",
       "8048 2020-05-31 08:00:00+09:00     NaN\n",
       "8049 2020-05-31 09:00:00+09:00     NaN\n",
       "8050 2020-05-31 10:00:00+09:00     NaN\n",
       "8051 2020-05-31 11:00:00+09:00     NaN\n",
       "8052 2020-05-31 12:00:00+09:00     NaN\n",
       "8053 2020-05-31 13:00:00+09:00     NaN\n",
       "8054 2020-05-31 14:00:00+09:00     NaN\n",
       "8055 2020-05-31 15:00:00+09:00     NaN\n",
       "8056 2020-05-31 16:00:00+09:00     NaN\n",
       "8057 2020-05-31 17:00:00+09:00     NaN\n",
       "8058 2020-05-31 18:00:00+09:00     NaN\n",
       "8059 2020-05-31 19:00:00+09:00     NaN\n",
       "8060 2020-05-31 20:00:00+09:00     NaN\n",
       "8061 2020-05-31 21:00:00+09:00     NaN\n",
       "...                        ...     ...\n",
       "8752 2020-06-29 16:00:00+09:00  11.988\n",
       "8753 2020-06-29 17:00:00+09:00   4.120\n",
       "8754 2020-06-29 18:00:00+09:00   1.022\n",
       "8755 2020-06-29 19:00:00+09:00   0.112\n",
       "8756 2020-06-29 20:00:00+09:00   0.001\n",
       "8757 2020-06-29 21:00:00+09:00   0.000\n",
       "8758 2020-06-29 22:00:00+09:00   0.000\n",
       "8759 2020-06-29 23:00:00+09:00   0.000\n",
       "8760 2020-06-30 00:00:00+09:00   0.000\n",
       "8761 2020-06-30 01:00:00+09:00   0.000\n",
       "8762 2020-06-30 02:00:00+09:00   0.000\n",
       "8763 2020-06-30 03:00:00+09:00   0.000\n",
       "8764 2020-06-30 04:00:00+09:00   0.000\n",
       "8765 2020-06-30 05:00:00+09:00   0.000\n",
       "8766 2020-06-30 06:00:00+09:00   0.614\n",
       "8767 2020-06-30 07:00:00+09:00   3.832\n",
       "8768 2020-06-30 08:00:00+09:00   7.549\n",
       "8769 2020-06-30 09:00:00+09:00  16.100\n",
       "8770 2020-06-30 10:00:00+09:00  19.989\n",
       "8771 2020-06-30 11:00:00+09:00  19.745\n",
       "8772 2020-06-30 12:00:00+09:00  25.391\n",
       "8773 2020-06-30 13:00:00+09:00  19.521\n",
       "8774 2020-06-30 14:00:00+09:00  10.835\n",
       "8775 2020-06-30 15:00:00+09:00  15.043\n",
       "8776 2020-06-30 16:00:00+09:00  11.863\n",
       "8777 2020-06-30 17:00:00+09:00   7.880\n",
       "8778 2020-06-30 18:00:00+09:00   3.408\n",
       "8779 2020-06-30 19:00:00+09:00   0.467\n",
       "8780 2020-06-30 20:00:00+09:00   0.020\n",
       "8781 2020-06-30 21:00:00+09:00   0.000\n",
       "\n",
       "[750 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.tail(750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = data3.groupby(data3['Date']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8782.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.991801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.090179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Value\n",
       "count  8782.000000\n",
       "mean      0.991801\n",
       "std       0.090179\n",
       "min       0.000000\n",
       "25%       1.000000\n",
       "50%       1.000000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data4.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8782 entries, 0 to 8781\n",
      "Data columns (total 2 columns):\n",
      "Date     8782 non-null datetime64[ns, Asia/Seoul]\n",
      "Value    8710 non-null float64\n",
      "dtypes: datetime64[ns, Asia/Seoul](1), float64(1)\n",
      "memory usage: 137.3 KB\n"
     ]
    }
   ],
   "source": [
    "data3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3['Date']= data3['Date'].apply(lambda x: x.strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FUNCTION_1 (data, dataframe_new, time) : \n",
    "    \n",
    "    for idx in data.index : \n",
    "    \n",
    "        if time in str(data.loc[idx][\"Date\"]) : \n",
    "\n",
    "            sample = pd.Series({\"Date\" : data.loc[idx][\"Date\"], \"Value\" : data.loc[idx][\"Value\"]})\n",
    "\n",
    "            dataframe_new = dataframe_new.append(sample, ignore_index=True)\n",
    "            \n",
    "    dataframe_new[\"past_01\"] = dataframe_new[\"Value\"].shift(1)\n",
    "    dataframe_new[\"past_02\"] = dataframe_new[\"Value\"].shift(2)\n",
    "    dataframe_new[\"past_03\"] = dataframe_new[\"Value\"].shift(3)\n",
    "    dataframe_new[\"past_04\"] = dataframe_new[\"Value\"].shift(4)\n",
    "    dataframe_new[\"past_05\"] = dataframe_new[\"Value\"].shift(5)\n",
    "    dataframe_new[\"past_06\"] = dataframe_new[\"Value\"].shift(6)\n",
    "    dataframe_new[\"past_07\"] = dataframe_new[\"Value\"].shift(7)\n",
    "\n",
    "    dataframe_new = dataframe_new.dropna(subset=[\"past_01\", \"past_02\", \"past_03\", \"past_04\", \"past_05\", \"past_06\", \"past_07\"])\n",
    "    \n",
    "    dataframe_new = dataframe_new.reset_index()\n",
    "    \n",
    "    dataframe_new = dataframe_new[dataframe_new.columns[1:]]\n",
    "    \n",
    "    return dataframe_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FUNCTION_2 (dataframe, time) : \n",
    "    \n",
    "    train = pd.DataFrame()\n",
    "    test = pd.DataFrame()\n",
    "    \n",
    "    for idx in dataframe.index : \n",
    "        \n",
    "        if dataframe.loc[idx][\"Date\"] == \"2020-01-31\"+\" \"+ time : \n",
    "            dataframe.loc[idx][\"Date\"]\n",
    "            test = test.append(dataframe.loc[idx])\n",
    "        elif dataframe.loc[idx][\"Date\"] == \"2020-03-31\"+\" \"+ time : \n",
    "            test = test.append(dataframe.loc[idx])\n",
    "        elif dataframe.loc[idx][\"Date\"] == \"2020-05-31\"+\" \"+ time : \n",
    "            test = test.append(dataframe.loc[idx])\n",
    "        else :\n",
    "            train = train.append(dataframe.loc[idx])\n",
    "            \n",
    "    train = train.reset_index()\n",
    "    test = test.reset_index()\n",
    "    \n",
    "    train = train[train.columns[1:]]\n",
    "    test = test[test.columns[1:]]\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0600 = pd.DataFrame()\n",
    "data_0600 = FUNCTION_1(data = data3, dataframe_new = data_0600, time = \"06:00:00\")\n",
    "data_0600_train = FUNCTION_2(data_0600, time=\"06:00:00\")[0]\n",
    "data_0600_test = FUNCTION_2(data_0600, time=\"06:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Value</th>\n",
       "      <th>past_01</th>\n",
       "      <th>past_02</th>\n",
       "      <th>past_03</th>\n",
       "      <th>past_04</th>\n",
       "      <th>past_05</th>\n",
       "      <th>past_06</th>\n",
       "      <th>past_07</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-08 06:00:00</td>\n",
       "      <td>1.999866</td>\n",
       "      <td>6.212866</td>\n",
       "      <td>3.969866</td>\n",
       "      <td>4.315866</td>\n",
       "      <td>4.112866</td>\n",
       "      <td>4.189866</td>\n",
       "      <td>5.089866</td>\n",
       "      <td>2.393866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-09 06:00:00</td>\n",
       "      <td>3.491866</td>\n",
       "      <td>1.999866</td>\n",
       "      <td>6.212866</td>\n",
       "      <td>3.969866</td>\n",
       "      <td>4.315866</td>\n",
       "      <td>4.112866</td>\n",
       "      <td>4.189866</td>\n",
       "      <td>5.089866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-10 06:00:00</td>\n",
       "      <td>3.257866</td>\n",
       "      <td>3.491866</td>\n",
       "      <td>1.999866</td>\n",
       "      <td>6.212866</td>\n",
       "      <td>3.969866</td>\n",
       "      <td>4.315866</td>\n",
       "      <td>4.112866</td>\n",
       "      <td>4.189866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-11 06:00:00</td>\n",
       "      <td>1.042866</td>\n",
       "      <td>3.257866</td>\n",
       "      <td>3.491866</td>\n",
       "      <td>1.999866</td>\n",
       "      <td>6.212866</td>\n",
       "      <td>3.969866</td>\n",
       "      <td>4.315866</td>\n",
       "      <td>4.112866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-12 06:00:00</td>\n",
       "      <td>2.364866</td>\n",
       "      <td>1.042866</td>\n",
       "      <td>3.257866</td>\n",
       "      <td>3.491866</td>\n",
       "      <td>1.999866</td>\n",
       "      <td>6.212866</td>\n",
       "      <td>3.969866</td>\n",
       "      <td>4.315866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-07-13 06:00:00</td>\n",
       "      <td>3.228866</td>\n",
       "      <td>2.364866</td>\n",
       "      <td>1.042866</td>\n",
       "      <td>3.257866</td>\n",
       "      <td>3.491866</td>\n",
       "      <td>1.999866</td>\n",
       "      <td>6.212866</td>\n",
       "      <td>3.969866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-07-14 06:00:00</td>\n",
       "      <td>3.668866</td>\n",
       "      <td>3.228866</td>\n",
       "      <td>2.364866</td>\n",
       "      <td>1.042866</td>\n",
       "      <td>3.257866</td>\n",
       "      <td>3.491866</td>\n",
       "      <td>1.999866</td>\n",
       "      <td>6.212866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-07-15 06:00:00</td>\n",
       "      <td>2.054866</td>\n",
       "      <td>3.668866</td>\n",
       "      <td>3.228866</td>\n",
       "      <td>2.364866</td>\n",
       "      <td>1.042866</td>\n",
       "      <td>3.257866</td>\n",
       "      <td>3.491866</td>\n",
       "      <td>1.999866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-07-16 06:00:00</td>\n",
       "      <td>1.773866</td>\n",
       "      <td>2.054866</td>\n",
       "      <td>3.668866</td>\n",
       "      <td>3.228866</td>\n",
       "      <td>2.364866</td>\n",
       "      <td>1.042866</td>\n",
       "      <td>3.257866</td>\n",
       "      <td>3.491866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-07-17 06:00:00</td>\n",
       "      <td>3.688866</td>\n",
       "      <td>1.773866</td>\n",
       "      <td>2.054866</td>\n",
       "      <td>3.668866</td>\n",
       "      <td>3.228866</td>\n",
       "      <td>2.364866</td>\n",
       "      <td>1.042866</td>\n",
       "      <td>3.257866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-07-18 06:00:00</td>\n",
       "      <td>1.377866</td>\n",
       "      <td>3.688866</td>\n",
       "      <td>1.773866</td>\n",
       "      <td>2.054866</td>\n",
       "      <td>3.668866</td>\n",
       "      <td>3.228866</td>\n",
       "      <td>2.364866</td>\n",
       "      <td>1.042866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-07-19 06:00:00</td>\n",
       "      <td>2.438866</td>\n",
       "      <td>1.377866</td>\n",
       "      <td>3.688866</td>\n",
       "      <td>1.773866</td>\n",
       "      <td>2.054866</td>\n",
       "      <td>3.668866</td>\n",
       "      <td>3.228866</td>\n",
       "      <td>2.364866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-07-20 06:00:00</td>\n",
       "      <td>0.561866</td>\n",
       "      <td>2.438866</td>\n",
       "      <td>1.377866</td>\n",
       "      <td>3.688866</td>\n",
       "      <td>1.773866</td>\n",
       "      <td>2.054866</td>\n",
       "      <td>3.668866</td>\n",
       "      <td>3.228866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-07-21 06:00:00</td>\n",
       "      <td>0.236866</td>\n",
       "      <td>0.561866</td>\n",
       "      <td>2.438866</td>\n",
       "      <td>1.377866</td>\n",
       "      <td>3.688866</td>\n",
       "      <td>1.773866</td>\n",
       "      <td>2.054866</td>\n",
       "      <td>3.668866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-07-22 06:00:00</td>\n",
       "      <td>1.461866</td>\n",
       "      <td>0.236866</td>\n",
       "      <td>0.561866</td>\n",
       "      <td>2.438866</td>\n",
       "      <td>1.377866</td>\n",
       "      <td>3.688866</td>\n",
       "      <td>1.773866</td>\n",
       "      <td>2.054866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-07-23 06:00:00</td>\n",
       "      <td>3.397866</td>\n",
       "      <td>1.461866</td>\n",
       "      <td>0.236866</td>\n",
       "      <td>0.561866</td>\n",
       "      <td>2.438866</td>\n",
       "      <td>1.377866</td>\n",
       "      <td>3.688866</td>\n",
       "      <td>1.773866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-07-24 06:00:00</td>\n",
       "      <td>0.524866</td>\n",
       "      <td>3.397866</td>\n",
       "      <td>1.461866</td>\n",
       "      <td>0.236866</td>\n",
       "      <td>0.561866</td>\n",
       "      <td>2.438866</td>\n",
       "      <td>1.377866</td>\n",
       "      <td>3.688866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-07-25 06:00:00</td>\n",
       "      <td>0.125866</td>\n",
       "      <td>0.524866</td>\n",
       "      <td>3.397866</td>\n",
       "      <td>1.461866</td>\n",
       "      <td>0.236866</td>\n",
       "      <td>0.561866</td>\n",
       "      <td>2.438866</td>\n",
       "      <td>1.377866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-07-26 06:00:00</td>\n",
       "      <td>0.975866</td>\n",
       "      <td>0.125866</td>\n",
       "      <td>0.524866</td>\n",
       "      <td>3.397866</td>\n",
       "      <td>1.461866</td>\n",
       "      <td>0.236866</td>\n",
       "      <td>0.561866</td>\n",
       "      <td>2.438866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-07-27 06:00:00</td>\n",
       "      <td>2.236866</td>\n",
       "      <td>0.975866</td>\n",
       "      <td>0.125866</td>\n",
       "      <td>0.524866</td>\n",
       "      <td>3.397866</td>\n",
       "      <td>1.461866</td>\n",
       "      <td>0.236866</td>\n",
       "      <td>0.561866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-07-28 06:00:00</td>\n",
       "      <td>1.494866</td>\n",
       "      <td>2.236866</td>\n",
       "      <td>0.975866</td>\n",
       "      <td>0.125866</td>\n",
       "      <td>0.524866</td>\n",
       "      <td>3.397866</td>\n",
       "      <td>1.461866</td>\n",
       "      <td>0.236866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019-07-29 06:00:00</td>\n",
       "      <td>2.462866</td>\n",
       "      <td>1.494866</td>\n",
       "      <td>2.236866</td>\n",
       "      <td>0.975866</td>\n",
       "      <td>0.125866</td>\n",
       "      <td>0.524866</td>\n",
       "      <td>3.397866</td>\n",
       "      <td>1.461866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2019-07-30 06:00:00</td>\n",
       "      <td>1.334866</td>\n",
       "      <td>2.462866</td>\n",
       "      <td>1.494866</td>\n",
       "      <td>2.236866</td>\n",
       "      <td>0.975866</td>\n",
       "      <td>0.125866</td>\n",
       "      <td>0.524866</td>\n",
       "      <td>3.397866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2019-07-31 06:00:00</td>\n",
       "      <td>0.560866</td>\n",
       "      <td>1.334866</td>\n",
       "      <td>2.462866</td>\n",
       "      <td>1.494866</td>\n",
       "      <td>2.236866</td>\n",
       "      <td>0.975866</td>\n",
       "      <td>0.125866</td>\n",
       "      <td>0.524866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2019-08-01 06:00:00</td>\n",
       "      <td>1.684943</td>\n",
       "      <td>0.560866</td>\n",
       "      <td>1.334866</td>\n",
       "      <td>2.462866</td>\n",
       "      <td>1.494866</td>\n",
       "      <td>2.236866</td>\n",
       "      <td>0.975866</td>\n",
       "      <td>0.125866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2019-08-02 06:00:00</td>\n",
       "      <td>2.424943</td>\n",
       "      <td>1.684943</td>\n",
       "      <td>0.560866</td>\n",
       "      <td>1.334866</td>\n",
       "      <td>2.462866</td>\n",
       "      <td>1.494866</td>\n",
       "      <td>2.236866</td>\n",
       "      <td>0.975866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2019-08-03 06:00:00</td>\n",
       "      <td>3.515943</td>\n",
       "      <td>2.424943</td>\n",
       "      <td>1.684943</td>\n",
       "      <td>0.560866</td>\n",
       "      <td>1.334866</td>\n",
       "      <td>2.462866</td>\n",
       "      <td>1.494866</td>\n",
       "      <td>2.236866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2019-08-04 06:00:00</td>\n",
       "      <td>1.617943</td>\n",
       "      <td>3.515943</td>\n",
       "      <td>2.424943</td>\n",
       "      <td>1.684943</td>\n",
       "      <td>0.560866</td>\n",
       "      <td>1.334866</td>\n",
       "      <td>2.462866</td>\n",
       "      <td>1.494866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019-08-05 06:00:00</td>\n",
       "      <td>2.535943</td>\n",
       "      <td>1.617943</td>\n",
       "      <td>3.515943</td>\n",
       "      <td>2.424943</td>\n",
       "      <td>1.684943</td>\n",
       "      <td>0.560866</td>\n",
       "      <td>1.334866</td>\n",
       "      <td>2.462866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2019-08-06 06:00:00</td>\n",
       "      <td>1.467943</td>\n",
       "      <td>2.535943</td>\n",
       "      <td>1.617943</td>\n",
       "      <td>3.515943</td>\n",
       "      <td>2.424943</td>\n",
       "      <td>1.684943</td>\n",
       "      <td>0.560866</td>\n",
       "      <td>1.334866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2020-01-24 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2020-01-25 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2020-01-26 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>2020-01-27 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2020-01-28 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2020-01-29 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>2020-01-30 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>2020-02-08 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>2020-02-09 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>2020-02-10 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>2020-02-11 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>2020-02-12 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>2020-02-13 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>2020-02-14 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>2020-02-15 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>2020-02-16 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>2020-02-17 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>2020-02-18 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>2020-02-19 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>2020-02-20 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>2020-02-21 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>2020-02-22 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>2020-02-23 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>2020-02-24 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>2020-02-25 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>2020-02-26 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>2020-02-27 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>2020-02-28 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>2020-02-29 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>2020-03-01 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date     Value   past_01   past_02   past_03   past_04  \\\n",
       "0    2019-07-08 06:00:00  1.999866  6.212866  3.969866  4.315866  4.112866   \n",
       "1    2019-07-09 06:00:00  3.491866  1.999866  6.212866  3.969866  4.315866   \n",
       "2    2019-07-10 06:00:00  3.257866  3.491866  1.999866  6.212866  3.969866   \n",
       "3    2019-07-11 06:00:00  1.042866  3.257866  3.491866  1.999866  6.212866   \n",
       "4    2019-07-12 06:00:00  2.364866  1.042866  3.257866  3.491866  1.999866   \n",
       "5    2019-07-13 06:00:00  3.228866  2.364866  1.042866  3.257866  3.491866   \n",
       "6    2019-07-14 06:00:00  3.668866  3.228866  2.364866  1.042866  3.257866   \n",
       "7    2019-07-15 06:00:00  2.054866  3.668866  3.228866  2.364866  1.042866   \n",
       "8    2019-07-16 06:00:00  1.773866  2.054866  3.668866  3.228866  2.364866   \n",
       "9    2019-07-17 06:00:00  3.688866  1.773866  2.054866  3.668866  3.228866   \n",
       "10   2019-07-18 06:00:00  1.377866  3.688866  1.773866  2.054866  3.668866   \n",
       "11   2019-07-19 06:00:00  2.438866  1.377866  3.688866  1.773866  2.054866   \n",
       "12   2019-07-20 06:00:00  0.561866  2.438866  1.377866  3.688866  1.773866   \n",
       "13   2019-07-21 06:00:00  0.236866  0.561866  2.438866  1.377866  3.688866   \n",
       "14   2019-07-22 06:00:00  1.461866  0.236866  0.561866  2.438866  1.377866   \n",
       "15   2019-07-23 06:00:00  3.397866  1.461866  0.236866  0.561866  2.438866   \n",
       "16   2019-07-24 06:00:00  0.524866  3.397866  1.461866  0.236866  0.561866   \n",
       "17   2019-07-25 06:00:00  0.125866  0.524866  3.397866  1.461866  0.236866   \n",
       "18   2019-07-26 06:00:00  0.975866  0.125866  0.524866  3.397866  1.461866   \n",
       "19   2019-07-27 06:00:00  2.236866  0.975866  0.125866  0.524866  3.397866   \n",
       "20   2019-07-28 06:00:00  1.494866  2.236866  0.975866  0.125866  0.524866   \n",
       "21   2019-07-29 06:00:00  2.462866  1.494866  2.236866  0.975866  0.125866   \n",
       "22   2019-07-30 06:00:00  1.334866  2.462866  1.494866  2.236866  0.975866   \n",
       "23   2019-07-31 06:00:00  0.560866  1.334866  2.462866  1.494866  2.236866   \n",
       "24   2019-08-01 06:00:00  1.684943  0.560866  1.334866  2.462866  1.494866   \n",
       "25   2019-08-02 06:00:00  2.424943  1.684943  0.560866  1.334866  2.462866   \n",
       "26   2019-08-03 06:00:00  3.515943  2.424943  1.684943  0.560866  1.334866   \n",
       "27   2019-08-04 06:00:00  1.617943  3.515943  2.424943  1.684943  0.560866   \n",
       "28   2019-08-05 06:00:00  2.535943  1.617943  3.515943  2.424943  1.684943   \n",
       "29   2019-08-06 06:00:00  1.467943  2.535943  1.617943  3.515943  2.424943   \n",
       "..                   ...       ...       ...       ...       ...       ...   \n",
       "200  2020-01-24 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "201  2020-01-25 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "202  2020-01-26 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "203  2020-01-27 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "204  2020-01-28 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "205  2020-01-29 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "206  2020-01-30 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "207  2020-02-08 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "208  2020-02-09 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "209  2020-02-10 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "210  2020-02-11 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "211  2020-02-12 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "212  2020-02-13 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "213  2020-02-14 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "214  2020-02-15 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "215  2020-02-16 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "216  2020-02-17 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "217  2020-02-18 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "218  2020-02-19 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "219  2020-02-20 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "220  2020-02-21 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "221  2020-02-22 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "222  2020-02-23 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "223  2020-02-24 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "224  2020-02-25 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "225  2020-02-26 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "226  2020-02-27 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "227  2020-02-28 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "228  2020-02-29 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "229  2020-03-01 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      past_05   past_06   past_07  \n",
       "0    4.189866  5.089866  2.393866  \n",
       "1    4.112866  4.189866  5.089866  \n",
       "2    4.315866  4.112866  4.189866  \n",
       "3    3.969866  4.315866  4.112866  \n",
       "4    6.212866  3.969866  4.315866  \n",
       "5    1.999866  6.212866  3.969866  \n",
       "6    3.491866  1.999866  6.212866  \n",
       "7    3.257866  3.491866  1.999866  \n",
       "8    1.042866  3.257866  3.491866  \n",
       "9    2.364866  1.042866  3.257866  \n",
       "10   3.228866  2.364866  1.042866  \n",
       "11   3.668866  3.228866  2.364866  \n",
       "12   2.054866  3.668866  3.228866  \n",
       "13   1.773866  2.054866  3.668866  \n",
       "14   3.688866  1.773866  2.054866  \n",
       "15   1.377866  3.688866  1.773866  \n",
       "16   2.438866  1.377866  3.688866  \n",
       "17   0.561866  2.438866  1.377866  \n",
       "18   0.236866  0.561866  2.438866  \n",
       "19   1.461866  0.236866  0.561866  \n",
       "20   3.397866  1.461866  0.236866  \n",
       "21   0.524866  3.397866  1.461866  \n",
       "22   0.125866  0.524866  3.397866  \n",
       "23   0.975866  0.125866  0.524866  \n",
       "24   2.236866  0.975866  0.125866  \n",
       "25   1.494866  2.236866  0.975866  \n",
       "26   2.462866  1.494866  2.236866  \n",
       "27   1.334866  2.462866  1.494866  \n",
       "28   0.560866  1.334866  2.462866  \n",
       "29   1.684943  0.560866  1.334866  \n",
       "..        ...       ...       ...  \n",
       "200  0.000000  0.000000  0.000000  \n",
       "201  0.000000  0.000000  0.000000  \n",
       "202  0.000000  0.000000  0.000000  \n",
       "203  0.000000  0.000000  0.000000  \n",
       "204  0.000000  0.000000  0.000000  \n",
       "205  0.000000  0.000000  0.000000  \n",
       "206  0.000000  0.000000  0.000000  \n",
       "207  0.000000  0.000000  0.000000  \n",
       "208  0.000000  0.000000  0.000000  \n",
       "209  0.000000  0.000000  0.000000  \n",
       "210  0.000000  0.000000  0.000000  \n",
       "211  0.000000  0.000000  0.000000  \n",
       "212  0.000000  0.000000  0.000000  \n",
       "213  0.000000  0.000000  0.000000  \n",
       "214  0.000000  0.000000  0.000000  \n",
       "215  0.000000  0.000000  0.000000  \n",
       "216  0.000000  0.000000  0.000000  \n",
       "217  0.000000  0.000000  0.000000  \n",
       "218  0.000000  0.000000  0.000000  \n",
       "219  0.000000  0.000000  0.000000  \n",
       "220  0.000000  0.000000  0.000000  \n",
       "221  0.000000  0.000000  0.000000  \n",
       "222  0.000000  0.000000  0.000000  \n",
       "223  0.000000  0.000000  0.000000  \n",
       "224  0.000000  0.000000  0.000000  \n",
       "225  0.000000  0.000000  0.000000  \n",
       "226  0.000000  0.000000  0.000000  \n",
       "227  0.000000  0.000000  0.000000  \n",
       "228  0.000000  0.000000  0.000000  \n",
       "229  0.000000  0.000000  0.000000  \n",
       "\n",
       "[230 rows x 9 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_0600_train.head(230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Value</th>\n",
       "      <th>past_01</th>\n",
       "      <th>past_02</th>\n",
       "      <th>past_03</th>\n",
       "      <th>past_04</th>\n",
       "      <th>past_05</th>\n",
       "      <th>past_06</th>\n",
       "      <th>past_07</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>2020-05-24 06:00:00</td>\n",
       "      <td>3.877000</td>\n",
       "      <td>4.496000</td>\n",
       "      <td>2.354000</td>\n",
       "      <td>5.057000</td>\n",
       "      <td>4.989000</td>\n",
       "      <td>3.971000</td>\n",
       "      <td>5.189000</td>\n",
       "      <td>0.855000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>2020-05-25 06:00:00</td>\n",
       "      <td>1.231000</td>\n",
       "      <td>3.877000</td>\n",
       "      <td>4.496000</td>\n",
       "      <td>2.354000</td>\n",
       "      <td>5.057000</td>\n",
       "      <td>4.989000</td>\n",
       "      <td>3.971000</td>\n",
       "      <td>5.189000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>2020-05-26 06:00:00</td>\n",
       "      <td>4.437000</td>\n",
       "      <td>1.231000</td>\n",
       "      <td>3.877000</td>\n",
       "      <td>4.496000</td>\n",
       "      <td>2.354000</td>\n",
       "      <td>5.057000</td>\n",
       "      <td>4.989000</td>\n",
       "      <td>3.971000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>2020-05-27 06:00:00</td>\n",
       "      <td>6.466000</td>\n",
       "      <td>4.437000</td>\n",
       "      <td>1.231000</td>\n",
       "      <td>3.877000</td>\n",
       "      <td>4.496000</td>\n",
       "      <td>2.354000</td>\n",
       "      <td>5.057000</td>\n",
       "      <td>4.989000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>2020-05-28 06:00:00</td>\n",
       "      <td>7.758000</td>\n",
       "      <td>6.466000</td>\n",
       "      <td>4.437000</td>\n",
       "      <td>1.231000</td>\n",
       "      <td>3.877000</td>\n",
       "      <td>4.496000</td>\n",
       "      <td>2.354000</td>\n",
       "      <td>5.057000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>2020-05-29 06:00:00</td>\n",
       "      <td>5.788000</td>\n",
       "      <td>7.758000</td>\n",
       "      <td>6.466000</td>\n",
       "      <td>4.437000</td>\n",
       "      <td>1.231000</td>\n",
       "      <td>3.877000</td>\n",
       "      <td>4.496000</td>\n",
       "      <td>2.354000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>2020-05-30 06:00:00</td>\n",
       "      <td>5.777000</td>\n",
       "      <td>5.788000</td>\n",
       "      <td>7.758000</td>\n",
       "      <td>6.466000</td>\n",
       "      <td>4.437000</td>\n",
       "      <td>1.231000</td>\n",
       "      <td>3.877000</td>\n",
       "      <td>4.496000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>2020-06-08 06:00:00</td>\n",
       "      <td>5.657000</td>\n",
       "      <td>2.936000</td>\n",
       "      <td>4.498000</td>\n",
       "      <td>3.863000</td>\n",
       "      <td>1.949000</td>\n",
       "      <td>1.068000</td>\n",
       "      <td>4.395000</td>\n",
       "      <td>1.641000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>2020-06-09 06:00:00</td>\n",
       "      <td>5.565000</td>\n",
       "      <td>5.657000</td>\n",
       "      <td>2.936000</td>\n",
       "      <td>4.498000</td>\n",
       "      <td>3.863000</td>\n",
       "      <td>1.949000</td>\n",
       "      <td>1.068000</td>\n",
       "      <td>4.395000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>2020-06-10 06:00:00</td>\n",
       "      <td>4.691000</td>\n",
       "      <td>5.565000</td>\n",
       "      <td>5.657000</td>\n",
       "      <td>2.936000</td>\n",
       "      <td>4.498000</td>\n",
       "      <td>3.863000</td>\n",
       "      <td>1.949000</td>\n",
       "      <td>1.068000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>2020-06-11 06:00:00</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>4.691000</td>\n",
       "      <td>5.565000</td>\n",
       "      <td>5.657000</td>\n",
       "      <td>2.936000</td>\n",
       "      <td>4.498000</td>\n",
       "      <td>3.863000</td>\n",
       "      <td>1.949000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>2020-06-12 06:00:00</td>\n",
       "      <td>5.453000</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>4.691000</td>\n",
       "      <td>5.565000</td>\n",
       "      <td>5.657000</td>\n",
       "      <td>2.936000</td>\n",
       "      <td>4.498000</td>\n",
       "      <td>3.863000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>2020-06-13 06:00:00</td>\n",
       "      <td>1.796000</td>\n",
       "      <td>5.453000</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>4.691000</td>\n",
       "      <td>5.565000</td>\n",
       "      <td>5.657000</td>\n",
       "      <td>2.936000</td>\n",
       "      <td>4.498000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>2020-06-14 06:00:00</td>\n",
       "      <td>0.617000</td>\n",
       "      <td>1.796000</td>\n",
       "      <td>5.453000</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>4.691000</td>\n",
       "      <td>5.565000</td>\n",
       "      <td>5.657000</td>\n",
       "      <td>2.936000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>2020-06-15 06:00:00</td>\n",
       "      <td>5.810000</td>\n",
       "      <td>0.617000</td>\n",
       "      <td>1.796000</td>\n",
       "      <td>5.453000</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>4.691000</td>\n",
       "      <td>5.565000</td>\n",
       "      <td>5.657000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>2020-06-16 06:00:00</td>\n",
       "      <td>2.370000</td>\n",
       "      <td>5.810000</td>\n",
       "      <td>0.617000</td>\n",
       "      <td>1.796000</td>\n",
       "      <td>5.453000</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>4.691000</td>\n",
       "      <td>5.565000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>2020-06-17 06:00:00</td>\n",
       "      <td>7.875000</td>\n",
       "      <td>2.370000</td>\n",
       "      <td>5.810000</td>\n",
       "      <td>0.617000</td>\n",
       "      <td>1.796000</td>\n",
       "      <td>5.453000</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>4.691000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>2020-06-18 06:00:00</td>\n",
       "      <td>7.995082</td>\n",
       "      <td>7.875000</td>\n",
       "      <td>2.370000</td>\n",
       "      <td>5.810000</td>\n",
       "      <td>0.617000</td>\n",
       "      <td>1.796000</td>\n",
       "      <td>5.453000</td>\n",
       "      <td>0.824000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>2020-06-19 06:00:00</td>\n",
       "      <td>2.064000</td>\n",
       "      <td>7.995082</td>\n",
       "      <td>7.875000</td>\n",
       "      <td>2.370000</td>\n",
       "      <td>5.810000</td>\n",
       "      <td>0.617000</td>\n",
       "      <td>1.796000</td>\n",
       "      <td>5.453000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>2020-06-20 06:00:00</td>\n",
       "      <td>5.586000</td>\n",
       "      <td>2.064000</td>\n",
       "      <td>7.995082</td>\n",
       "      <td>7.875000</td>\n",
       "      <td>2.370000</td>\n",
       "      <td>5.810000</td>\n",
       "      <td>0.617000</td>\n",
       "      <td>1.796000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>2020-06-21 06:00:00</td>\n",
       "      <td>2.831000</td>\n",
       "      <td>5.586000</td>\n",
       "      <td>2.064000</td>\n",
       "      <td>7.995082</td>\n",
       "      <td>7.875000</td>\n",
       "      <td>2.370000</td>\n",
       "      <td>5.810000</td>\n",
       "      <td>0.617000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>2020-06-22 06:00:00</td>\n",
       "      <td>5.288000</td>\n",
       "      <td>2.831000</td>\n",
       "      <td>5.586000</td>\n",
       "      <td>2.064000</td>\n",
       "      <td>7.995082</td>\n",
       "      <td>7.875000</td>\n",
       "      <td>2.370000</td>\n",
       "      <td>5.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>2020-06-23 06:00:00</td>\n",
       "      <td>5.556000</td>\n",
       "      <td>5.288000</td>\n",
       "      <td>2.831000</td>\n",
       "      <td>5.586000</td>\n",
       "      <td>2.064000</td>\n",
       "      <td>7.995082</td>\n",
       "      <td>7.875000</td>\n",
       "      <td>2.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>2020-06-24 06:00:00</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>5.556000</td>\n",
       "      <td>5.288000</td>\n",
       "      <td>2.831000</td>\n",
       "      <td>5.586000</td>\n",
       "      <td>2.064000</td>\n",
       "      <td>7.995082</td>\n",
       "      <td>7.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>2020-06-25 06:00:00</td>\n",
       "      <td>1.688000</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>5.556000</td>\n",
       "      <td>5.288000</td>\n",
       "      <td>2.831000</td>\n",
       "      <td>5.586000</td>\n",
       "      <td>2.064000</td>\n",
       "      <td>7.995082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>2020-06-26 06:00:00</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>1.688000</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>5.556000</td>\n",
       "      <td>5.288000</td>\n",
       "      <td>2.831000</td>\n",
       "      <td>5.586000</td>\n",
       "      <td>2.064000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>2020-06-27 06:00:00</td>\n",
       "      <td>4.167000</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>1.688000</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>5.556000</td>\n",
       "      <td>5.288000</td>\n",
       "      <td>2.831000</td>\n",
       "      <td>5.586000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>2020-06-28 06:00:00</td>\n",
       "      <td>3.968000</td>\n",
       "      <td>4.167000</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>1.688000</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>5.556000</td>\n",
       "      <td>5.288000</td>\n",
       "      <td>2.831000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2020-06-29 06:00:00</td>\n",
       "      <td>7.707000</td>\n",
       "      <td>3.968000</td>\n",
       "      <td>4.167000</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>1.688000</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>5.556000</td>\n",
       "      <td>5.288000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>2020-06-30 06:00:00</td>\n",
       "      <td>0.614000</td>\n",
       "      <td>7.707000</td>\n",
       "      <td>3.968000</td>\n",
       "      <td>4.167000</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>1.688000</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>5.556000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date     Value   past_01   past_02   past_03   past_04  \\\n",
       "305  2020-05-24 06:00:00  3.877000  4.496000  2.354000  5.057000  4.989000   \n",
       "306  2020-05-25 06:00:00  1.231000  3.877000  4.496000  2.354000  5.057000   \n",
       "307  2020-05-26 06:00:00  4.437000  1.231000  3.877000  4.496000  2.354000   \n",
       "308  2020-05-27 06:00:00  6.466000  4.437000  1.231000  3.877000  4.496000   \n",
       "309  2020-05-28 06:00:00  7.758000  6.466000  4.437000  1.231000  3.877000   \n",
       "310  2020-05-29 06:00:00  5.788000  7.758000  6.466000  4.437000  1.231000   \n",
       "311  2020-05-30 06:00:00  5.777000  5.788000  7.758000  6.466000  4.437000   \n",
       "312  2020-06-08 06:00:00  5.657000  2.936000  4.498000  3.863000  1.949000   \n",
       "313  2020-06-09 06:00:00  5.565000  5.657000  2.936000  4.498000  3.863000   \n",
       "314  2020-06-10 06:00:00  4.691000  5.565000  5.657000  2.936000  4.498000   \n",
       "315  2020-06-11 06:00:00  0.824000  4.691000  5.565000  5.657000  2.936000   \n",
       "316  2020-06-12 06:00:00  5.453000  0.824000  4.691000  5.565000  5.657000   \n",
       "317  2020-06-13 06:00:00  1.796000  5.453000  0.824000  4.691000  5.565000   \n",
       "318  2020-06-14 06:00:00  0.617000  1.796000  5.453000  0.824000  4.691000   \n",
       "319  2020-06-15 06:00:00  5.810000  0.617000  1.796000  5.453000  0.824000   \n",
       "320  2020-06-16 06:00:00  2.370000  5.810000  0.617000  1.796000  5.453000   \n",
       "321  2020-06-17 06:00:00  7.875000  2.370000  5.810000  0.617000  1.796000   \n",
       "322  2020-06-18 06:00:00  7.995082  7.875000  2.370000  5.810000  0.617000   \n",
       "323  2020-06-19 06:00:00  2.064000  7.995082  7.875000  2.370000  5.810000   \n",
       "324  2020-06-20 06:00:00  5.586000  2.064000  7.995082  7.875000  2.370000   \n",
       "325  2020-06-21 06:00:00  2.831000  5.586000  2.064000  7.995082  7.875000   \n",
       "326  2020-06-22 06:00:00  5.288000  2.831000  5.586000  2.064000  7.995082   \n",
       "327  2020-06-23 06:00:00  5.556000  5.288000  2.831000  5.586000  2.064000   \n",
       "328  2020-06-24 06:00:00  1.488000  5.556000  5.288000  2.831000  5.586000   \n",
       "329  2020-06-25 06:00:00  1.688000  1.488000  5.556000  5.288000  2.831000   \n",
       "330  2020-06-26 06:00:00  0.769000  1.688000  1.488000  5.556000  5.288000   \n",
       "331  2020-06-27 06:00:00  4.167000  0.769000  1.688000  1.488000  5.556000   \n",
       "332  2020-06-28 06:00:00  3.968000  4.167000  0.769000  1.688000  1.488000   \n",
       "333  2020-06-29 06:00:00  7.707000  3.968000  4.167000  0.769000  1.688000   \n",
       "334  2020-06-30 06:00:00  0.614000  7.707000  3.968000  4.167000  0.769000   \n",
       "\n",
       "      past_05   past_06   past_07  \n",
       "305  3.971000  5.189000  0.855000  \n",
       "306  4.989000  3.971000  5.189000  \n",
       "307  5.057000  4.989000  3.971000  \n",
       "308  2.354000  5.057000  4.989000  \n",
       "309  4.496000  2.354000  5.057000  \n",
       "310  3.877000  4.496000  2.354000  \n",
       "311  1.231000  3.877000  4.496000  \n",
       "312  1.068000  4.395000  1.641000  \n",
       "313  1.949000  1.068000  4.395000  \n",
       "314  3.863000  1.949000  1.068000  \n",
       "315  4.498000  3.863000  1.949000  \n",
       "316  2.936000  4.498000  3.863000  \n",
       "317  5.657000  2.936000  4.498000  \n",
       "318  5.565000  5.657000  2.936000  \n",
       "319  4.691000  5.565000  5.657000  \n",
       "320  0.824000  4.691000  5.565000  \n",
       "321  5.453000  0.824000  4.691000  \n",
       "322  1.796000  5.453000  0.824000  \n",
       "323  0.617000  1.796000  5.453000  \n",
       "324  5.810000  0.617000  1.796000  \n",
       "325  2.370000  5.810000  0.617000  \n",
       "326  7.875000  2.370000  5.810000  \n",
       "327  7.995082  7.875000  2.370000  \n",
       "328  2.064000  7.995082  7.875000  \n",
       "329  5.586000  2.064000  7.995082  \n",
       "330  2.831000  5.586000  2.064000  \n",
       "331  5.288000  2.831000  5.586000  \n",
       "332  5.556000  5.288000  2.831000  \n",
       "333  1.488000  5.556000  5.288000  \n",
       "334  1.688000  1.488000  5.556000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_0600_train.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Value</th>\n",
       "      <th>past_01</th>\n",
       "      <th>past_02</th>\n",
       "      <th>past_03</th>\n",
       "      <th>past_04</th>\n",
       "      <th>past_05</th>\n",
       "      <th>past_06</th>\n",
       "      <th>past_07</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-31 06:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-31 06:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-31 06:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.777</td>\n",
       "      <td>5.788</td>\n",
       "      <td>7.758</td>\n",
       "      <td>6.466</td>\n",
       "      <td>4.437</td>\n",
       "      <td>1.231</td>\n",
       "      <td>3.877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date  Value  past_01  past_02  past_03  past_04  past_05  \\\n",
       "0  2020-01-31 06:00:00    NaN    0.000    0.000    0.000    0.000    0.000   \n",
       "1  2020-03-31 06:00:00    NaN    0.270    0.287    0.164    0.010    0.073   \n",
       "2  2020-05-31 06:00:00    NaN    5.777    5.788    7.758    6.466    4.437   \n",
       "\n",
       "   past_06  past_07  \n",
       "0    0.000    0.000  \n",
       "1    0.111    0.076  \n",
       "2    1.231    3.877  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_0600_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0500 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0500 = pd.DataFrame()\n",
    "data_0500 = FUNCTION_1(data = data3, dataframe_new = data_0500, time = \"05:00:00\")\n",
    "data_0500_train = FUNCTION_2(data_0500, time=\"05:00:00\")[0]\n",
    "data_0500_test = FUNCTION_2(data_0500, time=\"05:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_0500_train[data_0500_train.columns[2:]].values\n",
    "X_test = data_0500_test[data_0500_test.columns[2:]].values\n",
    "\n",
    "y_train = data_0500_train[\"Value\"].values\n",
    "y_test = data_0500_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 0.0057\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 959us/step - loss: 0.0052\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 0.0050\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 826us/step - loss: 0.0050\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 848us/step - loss: 0.0050\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 800us/step - loss: 0.0049\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 0.0050\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 0.0049\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 0.0050\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 890us/step - loss: 0.0049\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 860us/step - loss: 0.0049\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 907us/step - loss: 0.0049\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 0.0049\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 0.0049\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 936us/step - loss: 0.0049\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 853us/step - loss: 0.0049\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 0.0049\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 896us/step - loss: 0.0049\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 885us/step - loss: 0.0049\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 878us/step - loss: 0.0048\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 0.0049\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 800us/step - loss: 0.0049\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 906us/step - loss: 0.0051\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 880us/step - loss: 0.0050\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 0.0048\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 0.0049\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 0.0049\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 850us/step - loss: 0.0048\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 0.0049\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 815us/step - loss: 0.0049\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 0.0048\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 850us/step - loss: 0.0049\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 0.0049\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 0.0048\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 869us/step - loss: 0.0049\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 0.0048\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 845us/step - loss: 0.0048\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 0.0048\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 865us/step - loss: 0.0048\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 0.0049\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 899us/step - loss: 0.0048\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 0.0048\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 0.0048\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 834us/step - loss: 0.0048\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 0.0047\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 0.0047\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 0.0047\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 0.0047\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 0.0047\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 0.0047\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 834us/step - loss: 0.0048\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 0.0046\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 0.0046\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 782us/step - loss: 0.0046\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 0.0046\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 0.0046\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 766us/step - loss: 0.0045\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 800us/step - loss: 0.0045\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 771us/step - loss: 0.0044\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 773us/step - loss: 0.0045\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 0.0045\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 834us/step - loss: 0.0044\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 781us/step - loss: 0.0045\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 0.0045\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 0.0044\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 0.0045\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 777us/step - loss: 0.0047\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 760us/step - loss: 0.0045\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 826us/step - loss: 0.0045\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 0.0045\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 0.0045\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 767us/step - loss: 0.0044\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 752us/step - loss: 0.0044\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 0.0044\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 0.0044\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 0.0044\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 760us/step - loss: 0.0044\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 0.0044\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 807us/step - loss: 0.0044\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 778us/step - loss: 0.0044\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 0.0044\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 778us/step - loss: 0.0044\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 0.0044\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 0.0045\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 0.0044\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 778us/step - loss: 0.0045\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 0.0044A: 0s - loss: 0.004\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 0.0045\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 0.0044\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 0.0045\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 0.0044\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 0.0045\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 0.0044\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 0.0045\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 0.0045\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 0.0044\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 798us/step - loss: 0.0044\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 0.0044\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 0.0044\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 0.0044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21aca1612b0>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0031]\n",
      " [-0.0031]\n",
      " [ 0.1362]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 0.0299\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 843us/step - loss: 0.0225\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 0.0202\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 0.0193\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 0.0188\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 870us/step - loss: 0.0190\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 0.0192\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 0.0190\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 0.0190\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 848us/step - loss: 0.0188\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 0.0188\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 0.0187\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 0.0189\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 0.0188\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 0.0191\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 0.0194\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 0.0194\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 0.0192\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 0.0188\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 0.0187\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 773us/step - loss: 0.0187\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 0.0189\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 834us/step - loss: 0.0190\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 0.0189\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 0.0190\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 0.0194\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 0.0192\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 768us/step - loss: 0.0193\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 0.0187\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 0.0194\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 0.0189\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 0.0187\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 771us/step - loss: 0.0189\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 0.0189\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 0.0195\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 782us/step - loss: 0.0193\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 0.0189\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 0.0189\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 786us/step - loss: 0.0186\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 834us/step - loss: 0.0187\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 843us/step - loss: 0.0188\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 0.0188\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 0.0186\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 0.0186\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 786us/step - loss: 0.0188\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 831us/step - loss: 0.0186\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 0.0186\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 0.0188\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 0.0186\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 0.0185\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 858us/step - loss: 0.0189\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 0.0197\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 0.0190\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 0.0185\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 0.0188\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 0.0186\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 0.0186\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 0.0185\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 0.0186\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 0.0187\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 862us/step - loss: 0.0185\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 781us/step - loss: 0.0186\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 0.0187\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 0.0184\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 0.0185\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 0.0187\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 0.0188\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 0.0187\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 0.0186\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 850us/step - loss: 0.0183\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 775us/step - loss: 0.0185\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 0.0184\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 0.0184\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 856us/step - loss: 0.0183\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 807us/step - loss: 0.0188\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 778us/step - loss: 0.0187\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 784us/step - loss: 0.0184\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 0.0183\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 0.0186\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 0.0186\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 850us/step - loss: 0.0183\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 0.0183\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 0.0187\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 0.0187 0s - loss: 0.019\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 0.0190\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 0.0182\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 0.0183\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 0.0188\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 0.0184\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 0.0185\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 0.0184\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 0.0182\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 780us/step - loss: 0.0184\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 0.0183\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 0.0183\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 0.0183\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 812us/step - loss: 0.0184\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 0.0185\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 0.0187\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 0.0184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21acaa54908>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0006]\n",
      " [-0.0006]\n",
      " [ 0.1693]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_0600_train[data_0600_train.columns[2:]].values\n",
    "X_test = data_0600_test[data_0600_test.columns[2:]].values\n",
    "\n",
    "y_train = data_0600_train[\"Value\"].values\n",
    "y_test = data_0600_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 2.6573\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 832us/step - loss: 1.8276\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 1.3528\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 1.1697\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 841us/step - loss: 1.0789\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 849us/step - loss: 1.0432\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 874us/step - loss: 1.0267\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 868us/step - loss: 1.0094\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 1.0132\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 841us/step - loss: 1.0040\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 874us/step - loss: 0.9997\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 834us/step - loss: 1.0024\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 0.9936\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 0.9959\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 852us/step - loss: 0.9966\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 845us/step - loss: 0.9902\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 848us/step - loss: 0.9864\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 0.9922\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 874us/step - loss: 0.9844\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 0.9861\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 0.9939\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 885us/step - loss: 0.9806\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 841us/step - loss: 0.9883\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 853us/step - loss: 0.9790\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 854us/step - loss: 0.9835\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 841us/step - loss: 0.9824\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 832us/step - loss: 0.9793\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 0.9814\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 0.9891\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 860us/step - loss: 0.9828\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 0.9850\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 0.9697\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 907us/step - loss: 0.9732\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 0.9721\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 956us/step - loss: 0.9726\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 907us/step - loss: 0.9750\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 866us/step - loss: 0.9758\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 0.9746\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 861us/step - loss: 0.9752\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 832us/step - loss: 0.9818\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 843us/step - loss: 0.9712\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 869us/step - loss: 0.9747\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 868us/step - loss: 1.0037\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 0.9638\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 850us/step - loss: 0.9744\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 841us/step - loss: 0.9599\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 958us/step - loss: 0.9682\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 999us/step - loss: 0.9679\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 874us/step - loss: 0.9657\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 912us/step - loss: 0.9637\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 843us/step - loss: 0.9630\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 0.9656\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 0.9562\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 0.9634 0s - loss: 1.17\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 934us/step - loss: 0.9614\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 907us/step - loss: 0.9676\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 0.9712\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 0.9603\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 800us/step - loss: 0.9581\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 810us/step - loss: 0.9577\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 0.9477\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 848us/step - loss: 0.9574\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 0.9538\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 0.9651\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 0.9707\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 961us/step - loss: 0.9742\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 0.9420\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 0.9532\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 832us/step - loss: 0.9561\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 854us/step - loss: 0.9432\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 0.9401\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 962us/step - loss: 0.9780\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.9613\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 870us/step - loss: 0.9598\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 0.9432\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 949us/step - loss: 0.9378\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 0.9399\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 0.9320\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 0.9607\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 0.9349\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 0.9244\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 0.9188\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 831us/step - loss: 0.9202\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 928us/step - loss: 0.9130\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 0.9058\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 0.9064\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 0.8933\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 921us/step - loss: 0.8900\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 852us/step - loss: 0.8929\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 0.8893\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 0.8938\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 859us/step - loss: 0.8943\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 928us/step - loss: 0.8792\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 945us/step - loss: 0.8694\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 0.8579\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 0.8679\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 818us/step - loss: 0.8658\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 866us/step - loss: 0.8519\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 866us/step - loss: 0.8661\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 0.9133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21acc2ed2b0>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0305]\n",
      " [0.1796]\n",
      " [3.7556]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 0.7396\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 0.6266\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 0.5579\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 898us/step - loss: 0.5346\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5311\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 923us/step - loss: 0.5254\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 877us/step - loss: 0.5228\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 0.5207\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 834us/step - loss: 0.5206\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 859us/step - loss: 0.5189\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 0.5192\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 872us/step - loss: 0.5207\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 0.5135\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 879us/step - loss: 0.5133\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5124\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5131\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5130\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 846us/step - loss: 0.5120\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 966us/step - loss: 0.5119\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 961us/step - loss: 0.5108\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 852us/step - loss: 0.5105\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 0.5103\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 0.5106\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5104\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5135\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 0.5096\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 923us/step - loss: 0.5159\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 0.5139\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 0.5160\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 979us/step - loss: 0.5091\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 0.5095\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 966us/step - loss: 0.5088\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5098\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 853us/step - loss: 0.5082\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 924us/step - loss: 0.5099\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 0.5091\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 942us/step - loss: 0.5095\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 975us/step - loss: 0.5105\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 0.5112\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 0.5093\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 841us/step - loss: 0.5112\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 868us/step - loss: 0.5089\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 0.5090\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 0.5098\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 855us/step - loss: 0.5117\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 0.5098\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 0.5101\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 0.5078\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 0.5065\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 864us/step - loss: 0.5089\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 0.5073\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 0.5083\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 775us/step - loss: 0.5091\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 0.5077\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 0.5079\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 0.5076\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 0.5122\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 0.5077\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 0.5085\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 0.5095\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 0.5085\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 0.5080\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 0.5102\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 0.5082\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 0.5059\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 0.5097\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 0.5139\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 834us/step - loss: 0.5062\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 0.5060\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 0.5090\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 852us/step - loss: 0.5057\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 0.5061\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 0.5054\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 0.5053\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 0.5053\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 832us/step - loss: 0.5078\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 834us/step - loss: 0.5054\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 0.5055\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 0.5047\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 0.5045\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 832us/step - loss: 0.5050\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 0.5084\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 0.5101\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 807us/step - loss: 0.5031\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 0.5058\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 0.5043\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 0.5018\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 0.5012\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 0.5026\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 0.5076\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 0.4992\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 0.4984\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 800us/step - loss: 0.4981\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 0.4958\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 0.4960\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 0.4970\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 853us/step - loss: 0.5032\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 0.4973\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 0.5013\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 815us/step - loss: 0.4897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21acdbc53c8>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.1000e-03]\n",
      " [1.3560e-01]\n",
      " [4.0402e+00]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0700 = pd.DataFrame()\n",
    "data_0700 = FUNCTION_1(data = data3, dataframe_new = data_0700, time = \"07:00:00\")\n",
    "data_0700_train = FUNCTION_2(data_0700, time=\"07:00:00\")[0]\n",
    "data_0700_test = FUNCTION_2(data_0700, time=\"07:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_0700_train[data_0700_train.columns[2:]].values\n",
    "X_test = data_0700_test[data_0700_test.columns[2:]].values\n",
    "\n",
    "y_train = data_0700_train[\"Value\"].values\n",
    "y_test = data_0700_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 67.5877\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 62.0228\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 55.1805\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 46.2454\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 35.9913\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 29.8977\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 881us/step - loss: 26.6750\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 24.5549\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 886us/step - loss: 22.8380\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 932us/step - loss: 21.4965\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 20.1352\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 19.0611\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 18.0519\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 906us/step - loss: 17.3548\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 16.9506\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 16.6003\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 16.4237\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 16.1783\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 15.9306\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 15.6094\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 15.5739\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 873us/step - loss: 15.3481\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 862us/step - loss: 15.2311\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 14.9576\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 866us/step - loss: 14.8978\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 859us/step - loss: 14.7571\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 14.6948\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 14.9379\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 858us/step - loss: 14.6314\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 876us/step - loss: 14.6171\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 14.6282\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 907us/step - loss: 14.4351\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 912us/step - loss: 14.2601\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 14.4358\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 14.2954\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 14.1759\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 14.1529\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 14.1501\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 848us/step - loss: 14.0661\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 810us/step - loss: 14.1135\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 849us/step - loss: 14.0524\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 859us/step - loss: 14.0565\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 920us/step - loss: 14.1004\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 14.0740\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 897us/step - loss: 13.9659\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 13.9897\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 979us/step - loss: 13.9553\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 13.9325\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 13.9084\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 14.0089\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 14.0594\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 13.9592\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 13.8393\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 13.8407\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 13.9002\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 13.7785\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 13.7741\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 13.7355\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 768us/step - loss: 13.7160\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 782us/step - loss: 13.7445\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 848us/step - loss: 13.7043\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 781us/step - loss: 13.7753\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 768us/step - loss: 13.8013\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 877us/step - loss: 13.6555\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 764us/step - loss: 13.7071\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 13.6945\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 933us/step - loss: 13.6249\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 871us/step - loss: 13.5987\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 777us/step - loss: 13.6596\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 13.6042\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 13.5729\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 988us/step - loss: 13.5440\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 873us/step - loss: 13.5944\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 730us/step - loss: 13.4880\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 742us/step - loss: 13.5877\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 810us/step - loss: 13.5634\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 13.4500\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 13.5428\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 751us/step - loss: 13.5796\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 718us/step - loss: 13.4620\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 711us/step - loss: 13.4985\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 718us/step - loss: 13.4358\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 735us/step - loss: 13.4647\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 716us/step - loss: 13.4224\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 692us/step - loss: 13.3939\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 707us/step - loss: 13.4070\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 698us/step - loss: 13.3794\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 711us/step - loss: 13.4109\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 859us/step - loss: 13.3991\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 864us/step - loss: 13.3346\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 863us/step - loss: 13.3292\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 758us/step - loss: 13.3014\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 755us/step - loss: 13.3694\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 735us/step - loss: 13.2780\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 13.4204\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 792us/step - loss: 13.3958\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 732us/step - loss: 13.4218\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 766us/step - loss: 13.2473\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 712us/step - loss: 13.2333\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 725us/step - loss: 13.2393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21a9cff72b0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0166]\n",
      " [ 8.6757]\n",
      " [13.6503]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 5.7302\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 5.2081\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 884us/step - loss: 4.7551\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 699us/step - loss: 4.3541\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 785us/step - loss: 4.0481\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 3.8111\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 3.6434\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 3.5187\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 3.4219\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 3.3289\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 776us/step - loss: 3.2209\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 3.0849\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 752us/step - loss: 2.9917\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 771us/step - loss: 2.9309\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 702us/step - loss: 2.9109\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 710us/step - loss: 2.8594\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 770us/step - loss: 2.8295\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 2.8035\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 2.7813\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 747us/step - loss: 2.7746\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 697us/step - loss: 2.7740\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 749us/step - loss: 2.7404\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 2.7285\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 759us/step - loss: 2.7156\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 2.7121\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 2.7086\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 2.6857\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 2.6835\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 709us/step - loss: 2.6723\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 750us/step - loss: 2.6491\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 735us/step - loss: 2.6499\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 705us/step - loss: 2.6826\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 2.6657\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 2.6331\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 2.6144\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 2.6051\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 2.5987\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 764us/step - loss: 2.5698\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 753us/step - loss: 2.6146\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 736us/step - loss: 2.5679\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 773us/step - loss: 2.5594\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 894us/step - loss: 2.5171\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 2.5925\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 754us/step - loss: 2.5761\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 2.5260\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 2.5181\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 2.5189\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 2.5278\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 2.5245\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 2.5640\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 2.4672\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 2.4752\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 694us/step - loss: 2.4907\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 730us/step - loss: 2.4583\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 723us/step - loss: 2.4584\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 747us/step - loss: 2.4789\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 771us/step - loss: 2.4567\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 769us/step - loss: 2.4909\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 2.4427\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 766us/step - loss: 2.4413\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 771us/step - loss: 2.4517\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 775us/step - loss: 2.4390\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 776us/step - loss: 2.4314\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 710us/step - loss: 2.4302\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 770us/step - loss: 2.4285\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 2.4248\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 745us/step - loss: 2.4240\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 695us/step - loss: 2.4134\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 701us/step - loss: 2.4083\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 714us/step - loss: 2.3981\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 723us/step - loss: 2.4019\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 2.3948\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 909us/step - loss: 2.4137\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 800us/step - loss: 2.4078\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 742us/step - loss: 2.3983\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 775us/step - loss: 2.3829\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 730us/step - loss: 2.3729\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 741us/step - loss: 2.3784\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 721us/step - loss: 2.3489\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 779us/step - loss: 2.3676\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 755us/step - loss: 2.4169\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 755us/step - loss: 2.3654\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 720us/step - loss: 2.3592\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 741us/step - loss: 2.3367\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 750us/step - loss: 2.3337\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 749us/step - loss: 2.3424\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 2.3358\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 722us/step - loss: 2.3404\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 738us/step - loss: 2.3155\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 745us/step - loss: 2.3150\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 716us/step - loss: 2.3119\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 727us/step - loss: 2.3037\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 749us/step - loss: 2.3439\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 735us/step - loss: 2.3239\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 731us/step - loss: 2.2993\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 770us/step - loss: 2.2915\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 716us/step - loss: 2.2800\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 708us/step - loss: 2.2821\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 722us/step - loss: 2.2670\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 704us/step - loss: 2.3211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21a9cff7ef0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0882]\n",
      " [ 8.1061]\n",
      " [14.4172]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0800 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0800 = pd.DataFrame()\n",
    "data_0800 = FUNCTION_1(data = data3, dataframe_new = data_0800, time = \"08:00:00\")\n",
    "data_0800_train = FUNCTION_2(data_0800, time=\"08:00:00\")[0]\n",
    "data_0800_test = FUNCTION_2(data_0800, time=\"08:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_0800_train[data_0800_train.columns[2:]].values\n",
    "X_test = data_0800_test[data_0800_test.columns[2:]].values\n",
    "\n",
    "y_train = data_0800_train[\"Value\"].values\n",
    "y_test = data_0800_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam',metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 438.8287 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 423.4493 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 771us/step - loss: 407.1670 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 859us/step - loss: 396.2032 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 362.7424 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 834us/step - loss: 348.1970 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 328.5002 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 314.2004 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 306.6079 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 309.3343 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 294.0994 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 1s 4ms/step - loss: 311.9262 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 771us/step - loss: 298.2767 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 275.9877 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 285.4863 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 781us/step - loss: 294.1152 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 319.9433 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 309.1423 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 783us/step - loss: 338.8820 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 807us/step - loss: 286.0686 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 902us/step - loss: 283.3706 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 774us/step - loss: 247.4849 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 878us/step - loss: 286.2699 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 863us/step - loss: 272.5693 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 307.2122 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 783us/step - loss: 266.5211 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 893us/step - loss: 271.4508 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 283.0289 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 950us/step - loss: 299.3926 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 879us/step - loss: 253.3178 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 917us/step - loss: 281.9255 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 267.4669 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 283.1140 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 259.4788 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 288.2776 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 707us/step - loss: 260.5269 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 902us/step - loss: 255.7423 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 875us/step - loss: 266.6137 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 730us/step - loss: 269.9084 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 926us/step - loss: 295.5146 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 741us/step - loss: 274.0339 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 728us/step - loss: 286.9898 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 745us/step - loss: 281.4129 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 902us/step - loss: 284.5040 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 273.6886 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 815us/step - loss: 294.6249 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 764us/step - loss: 267.4900 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 871us/step - loss: 278.8156 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 961us/step - loss: 292.6247 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 750us/step - loss: 264.8393 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 721us/step - loss: 259.3289 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 760us/step - loss: 267.0254 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 748us/step - loss: 270.1399 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 914us/step - loss: 266.6719 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 295.4652 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 783us/step - loss: 284.2682 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 750us/step - loss: 281.6912 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 950us/step - loss: 302.6783 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 709us/step - loss: 267.1554 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 760us/step - loss: 244.2389 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 770us/step - loss: 302.1555 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 738us/step - loss: 273.6854 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 750us/step - loss: 309.6079 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 783us/step - loss: 296.9285 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 767us/step - loss: 247.9582 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 732us/step - loss: 287.6382 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 756us/step - loss: 278.1347 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 742us/step - loss: 273.0078 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 783us/step - loss: 258.8084 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 723us/step - loss: 314.9420 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 712us/step - loss: 267.5503 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 737us/step - loss: 280.8286 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 756us/step - loss: 319.9836 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 729us/step - loss: 247.9106 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 735us/step - loss: 247.7986 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 831us/step - loss: 299.0708 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 765us/step - loss: 276.2357 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 281.7723 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 270.3913 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 274.0176 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 288.5055 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 991us/step - loss: 262.1176 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 268.8001 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 276.9949 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 262.4616 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 897us/step - loss: 277.7082 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 911us/step - loss: 278.8290 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 755us/step - loss: 268.3604 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 750us/step - loss: 325.1750 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 288.7747 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 735us/step - loss: 271.8669 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 718us/step - loss: 305.4488 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 254.4468 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 706us/step - loss: 265.2143 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 749us/step - loss: 293.7378 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 764us/step - loss: 281.8119 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 684us/step - loss: 278.0767 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 703us/step - loss: 304.0355 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 737us/step - loss: 270.6279 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 269.0416 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21acf4af978>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.2828]\n",
      " [24.1126]\n",
      " [25.4928]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 17.0274\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 16.4177\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 15.6674\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 14.6434\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 869us/step - loss: 13.6392\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 12.9138\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 880us/step - loss: 12.3988\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 11.9357\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 11.5794\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 684us/step - loss: 11.3060\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 869us/step - loss: 11.0761\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 10.8219\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 728us/step - loss: 10.5842\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 10.3868\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 10.2054\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 10.0854\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 9.9040\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 877us/step - loss: 9.8045\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 765us/step - loss: 9.7140\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 9.5612\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 698us/step - loss: 9.4436\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 712us/step - loss: 9.3467\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 735us/step - loss: 9.2474\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 708us/step - loss: 9.1489\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 9.0875\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 756us/step - loss: 8.9453\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 754us/step - loss: 8.8437\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 733us/step - loss: 8.7617\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 881us/step - loss: 8.6810\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 739us/step - loss: 8.6143\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 855us/step - loss: 8.5263\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 929us/step - loss: 8.4538\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 859us/step - loss: 8.4007\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 8.3530\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 8.2924\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 753us/step - loss: 8.1790\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 893us/step - loss: 8.1041\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 8.0376\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 690us/step - loss: 7.9854\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 768us/step - loss: 7.9204\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 776us/step - loss: 7.8953\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 718us/step - loss: 7.8765\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 907us/step - loss: 7.8363\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 695us/step - loss: 7.7632\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - ETA: 0s - loss: 7.653 - 0s 723us/step - loss: 7.7265\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 708us/step - loss: 7.7395\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 723us/step - loss: 7.7750\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 7.7141\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 924us/step - loss: 7.6764\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 734us/step - loss: 7.5735\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 718us/step - loss: 7.5663\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 7.5429\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 711us/step - loss: 7.5056\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 723us/step - loss: 7.5058\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 895us/step - loss: 7.4324\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 911us/step - loss: 7.4908\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 7.4407\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 7.4271\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 704us/step - loss: 7.4005\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 751us/step - loss: 7.4275\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 716us/step - loss: 7.3498\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 764us/step - loss: 7.3397\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 716us/step - loss: 7.3539\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 690us/step - loss: 7.3774\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 751us/step - loss: 7.3400\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 700us/step - loss: 7.3350\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 7.3044\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 725us/step - loss: 7.3109\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 7.2768\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 718us/step - loss: 7.2657\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 702us/step - loss: 7.2360\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 7.2389\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 753us/step - loss: 7.2287\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 698us/step - loss: 7.2631\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 704us/step - loss: 7.2623\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 739us/step - loss: 7.2095\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 7.2456\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 769us/step - loss: 7.2037\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 7.2042\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 731us/step - loss: 7.2531\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 752us/step - loss: 7.2195\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 704us/step - loss: 7.1828\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 692us/step - loss: 7.1605\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 715us/step - loss: 7.1765\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 713us/step - loss: 7.3180\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 701us/step - loss: 7.2818\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 728us/step - loss: 7.2136\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 729us/step - loss: 7.2871\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 884us/step - loss: 7.1354\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 723us/step - loss: 7.1755\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 740us/step - loss: 7.1490\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 7.1099\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 7.1081\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 740us/step - loss: 7.1839\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 881us/step - loss: 7.0810\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 693us/step - loss: 7.1053\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 697us/step - loss: 7.1195\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 720us/step - loss: 7.0882\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 776us/step - loss: 7.0938\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 689us/step - loss: 7.1406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21aa0ac1ac8>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.5016]\n",
      " [25.3863]\n",
      " [25.3148]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0900 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0900 = pd.DataFrame()\n",
    "data_0900 = FUNCTION_1(data = data3, dataframe_new = data_0900, time = \"09:00:00\")\n",
    "data_0900_train = FUNCTION_2(data_0900, time=\"09:00:00\")[0]\n",
    "data_0900_test = FUNCTION_2(data_0900, time=\"09:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_0900_train[data_0700_train.columns[2:]].values\n",
    "X_test = data_0900_test[data_0700_test.columns[2:]].values\n",
    "\n",
    "y_train = data_0900_train[\"Value\"].values\n",
    "y_test = data_0900_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 1457.0109 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 855us/step - loss: 1431.8474 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 1390.5458 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 1332.9587 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 1279.1371 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 1173.1728 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 784us/step - loss: 1139.5567 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 1101.7516 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 914us/step - loss: 1096.7043 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 863us/step - loss: 1069.4149 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 1066.3602 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 1029.4769 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 1064.9220 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 1076.4223 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 1053.0495 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 856us/step - loss: 1046.9638 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 923us/step - loss: 943.9422 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 921.5242 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 1020.9262 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 918.0379 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 997.2632 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 889us/step - loss: 893.1731 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 926.3209 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 919us/step - loss: 879.3537 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 933us/step - loss: 975.8843 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 982us/step - loss: 951.7513 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 974us/step - loss: 930.9905 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 938us/step - loss: 978.8609 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 965us/step - loss: 917.5570 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 974us/step - loss: 915.7848 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 941us/step - loss: 951.9853 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 981.4065 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 953.8949 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 985us/step - loss: 900.4727 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 911us/step - loss: 962.8855 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 866us/step - loss: 880.0113 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 875us/step - loss: 936.8720 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 867.3263 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 923us/step - loss: 924.2453 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 908us/step - loss: 919.7183 - accuracy: 0.0000e+00 0s - loss: 896.8143 - accuracy: 0.00\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 849us/step - loss: 989.6063 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 965us/step - loss: 876.7676 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 857us/step - loss: 934.4249 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 800us/step - loss: 823.1484 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 955.8288 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 875.7001 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 914us/step - loss: 928.5562 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 800us/step - loss: 820.6925 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 874us/step - loss: 881.4700 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 904us/step - loss: 911.6061 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 913us/step - loss: 928.2432 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 771us/step - loss: 818.8207 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 870us/step - loss: 878.0268 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 854us/step - loss: 952.9174 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 896us/step - loss: 870.2079 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 967.2332 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 944us/step - loss: 860.6349 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 893us/step - loss: 894.8495 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 845.0835 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 852.5714 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 893us/step - loss: 831.6852 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 903.5263 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 900us/step - loss: 831.0965 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 909us/step - loss: 887.2189 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 825.9030 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 891us/step - loss: 866.1503 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 803.0967 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 980us/step - loss: 919.3401 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 884.0556 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 899us/step - loss: 762.8401 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 950us/step - loss: 866.8596 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 855us/step - loss: 886.8087 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 901us/step - loss: 876.3090 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 881us/step - loss: 904.7556 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 992us/step - loss: 770.7710 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 812.2570 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 772us/step - loss: 880.9862 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 825.0209 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 881.6652 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 870.4757 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 875.5524 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 832.9104 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 882.3467 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 890.7359 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 869.8620 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 837.1814 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 888.6759 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 962.6450 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 778us/step - loss: 873.2822 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 851.1084 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 796.1446 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 927.5648 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 841us/step - loss: 923.4243 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 859.3871 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 903.4994 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 852us/step - loss: 804.7033 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 871.8928 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 785us/step - loss: 850.5742 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 886.9113 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 834.5882 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21acf6beb70>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.1194]\n",
      " [20.9075]\n",
      " [20.9939]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 33.8685\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 33.0021\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 31.9884\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 30.9793\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 30.1008\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 29.4014\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 28.7300\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 27.9879\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 27.4114\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 984us/step - loss: 26.7755\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 874us/step - loss: 26.1556\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 25.6413\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 25.0348\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 881us/step - loss: 24.4567\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 807us/step - loss: 23.8958\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 956us/step - loss: 23.2550\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 22.8567\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 858us/step - loss: 22.5135\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 22.1965\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 925us/step - loss: 21.9060\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 21.6293\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 21.3749\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 975us/step - loss: 21.1244\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 928us/step - loss: 20.8896\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 20.6670: 0s - loss: 21.\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 20.4549\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 907us/step - loss: 20.2520\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 20.0664\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 19.8821\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 945us/step - loss: 19.7108\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 920us/step - loss: 19.5421\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 968us/step - loss: 19.3761\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 19.2081\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 942us/step - loss: 19.0430\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 882us/step - loss: 18.8851\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 18.7383\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 18.5961\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 887us/step - loss: 18.4615\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 979us/step - loss: 18.32950s - loss: 18.06\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 18.2127\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 18.0895\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 848us/step - loss: 17.9752\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 960us/step - loss: 17.8700\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 868us/step - loss: 17.7619\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 17.6559\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 17.5485\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 17.4504\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 861us/step - loss: 17.3456\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 980us/step - loss: 17.2401\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 967us/step - loss: 17.1498\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 17.0486\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 902us/step - loss: 16.9521\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 16.8802\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 16.7726\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 874us/step - loss: 16.6771\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 857us/step - loss: 16.6078\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 16.5300\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 774us/step - loss: 16.4525\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 800us/step - loss: 16.3779\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 874us/step - loss: 16.3169\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 16.2267\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 16.1261\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 831us/step - loss: 16.0746\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 16.0538\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 810us/step - loss: 15.9301\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 15.8737\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 771us/step - loss: 15.7822\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 15.7135\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 15.6350\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 15.5465\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 15.4769\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 15.3933\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 15.3201\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 800us/step - loss: 15.2350\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 771us/step - loss: 15.1508\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 15.0979\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 15.0455\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 14.9664\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 786us/step - loss: 14.8455\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 14.8585\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 14.7599\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 781us/step - loss: 14.6669\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 14.6971\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 14.6349\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 14.5891\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 782us/step - loss: 14.5467\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 845us/step - loss: 14.4262\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 14.5782\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 831us/step - loss: 14.3303\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 783us/step - loss: 14.3818\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 14.3219\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 774us/step - loss: 14.2709\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 14.19140s - loss: 13.92\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 14.1426\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 14.0657\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 941us/step - loss: 14.0347\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 13.9673\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 14.0912\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 13.9529\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 13.8837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21aa4ce7fd0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23.3768]\n",
      " [35.9757]\n",
      " [35.9742]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1000 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1000 = pd.DataFrame()\n",
    "data_1000 = FUNCTION_1(data = data3, dataframe_new = data_1000, time = \"10:00:00\")\n",
    "data_1000_train = FUNCTION_2(data_1000, time=\"10:00:00\")[0]\n",
    "data_1000_test = FUNCTION_2(data_1000, time=\"10:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_1000_train[data_1000_train.columns[2:]].values\n",
    "X_test = data_1000_test[data_1000_test.columns[2:]].values\n",
    "\n",
    "y_train = data_1000_train[\"Value\"].values\n",
    "y_test = data_1000_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 2974.0869\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 2930.6031\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 2871.2639\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 777us/step - loss: 2792.8774\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 2708.4373\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 2594.0499\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 2448.6425\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 853us/step - loss: 2354.2365\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 2291.5063\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 2230.2535\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 2174.1774\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 2115.6657\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 834us/step - loss: 2068.0478\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 815us/step - loss: 2026.8372\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 1988.2038\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 1950.9771\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 1914.6448\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 1875.7034\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 1824.8352\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 1785.3313\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 1752.2652\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 831us/step - loss: 1720.6440\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 1689.4501\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 1659.9497\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 1631.2394\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 1602.6937\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 841us/step - loss: 1575.6351\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 1548.9352\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 767us/step - loss: 1522.8852\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 1497.6961\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 1472.6783\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 1448.8215\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 1424.8278\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 1402.1910\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 850us/step - loss: 1379.7555\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 1357.4951\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 826us/step - loss: 1335.7710\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 1315.0642\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 1294.5960\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 1274.2372\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 834us/step - loss: 1254.9641\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 1235.4449\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 845us/step - loss: 1216.5586\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 1198.6374\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 1180.4823\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 1162.8221\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 1145.9826\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 1128.9580\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 1112.7988\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 1096.7198\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 1081.2218\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 1065.6909\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 810us/step - loss: 1050.8736\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 1036.4305\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 1022.0515\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 1008.1850\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 994.5781\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 981.5022\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 900us/step - loss: 968.0618\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 955.7327\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 943.3567\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 775us/step - loss: 931.5401\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 919.2614\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 786us/step - loss: 908.2315\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 848us/step - loss: 896.8023\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 885.8465\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 750us/step - loss: 875.5927\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 864.7478\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 854.7202\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 810us/step - loss: 844.8810\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 775us/step - loss: 835.2372\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 825.9328\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 816.8191\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 807.8783\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 779us/step - loss: 799.3550\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 790.8667\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 807us/step - loss: 782.5577\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 774.8039\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 766.8265\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 800us/step - loss: 759.2115\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 752.0789\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 745.0719\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 779us/step - loss: 737.7792\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 731.3199\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 724.6134\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 762us/step - loss: 718.2319\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 712.2116\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 706.1893\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 781us/step - loss: 700.3106\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 694.7277\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 689.4135\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 683.8574\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 679.0500\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 774us/step - loss: 673.6706\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 669.2262\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 664.4003\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 659.9112\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 655.5864\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 651.3969\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 647.2320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21aa54e3a58>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39.1415]\n",
      " [39.1429]\n",
      " [39.1367]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 48.8971\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 810us/step - loss: 48.4443\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 834us/step - loss: 47.9143\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 785us/step - loss: 47.3642\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 46.4760\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 45.7036\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 44.8426\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 43.9402\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 43.4394\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 42.9317\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 41.8583\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 785us/step - loss: 40.4041\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 39.4586\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 38.7474\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 782us/step - loss: 38.1342\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 37.5387\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 36.9196\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 36.4091\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 35.9811\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 770us/step - loss: 35.5930\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 845us/step - loss: 35.2282\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 34.8741\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 34.5298\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 34.1920\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 773us/step - loss: 33.8639\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 33.5444\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 33.2300\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 32.9084\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 761us/step - loss: 32.60970s - loss: 3\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 32.3019\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 769us/step - loss: 32.0158\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 31.7293\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 31.4469\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 31.1720\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 782us/step - loss: 30.9058\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 30.6322\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 30.3646\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 30.0928\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 784us/step - loss: 29.8297\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 29.5655\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 29.3108\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 29.0632\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 769us/step - loss: 28.8190\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 786us/step - loss: 28.5831\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 780us/step - loss: 28.3645\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 28.1417\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 27.9272\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 27.7143\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 27.5026\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 781us/step - loss: 27.2883\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 27.0861\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 26.8774\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 775us/step - loss: 26.6714\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 26.4735\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 26.2763\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 26.0845\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 784us/step - loss: 25.8954\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 25.7091\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 25.5293\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 779us/step - loss: 25.3553\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 25.1933\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 25.0257\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 24.8761\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 785us/step - loss: 24.7254\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 782us/step - loss: 24.5783\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 24.4255\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 772us/step - loss: 24.2785\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 24.1366\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 23.9952\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 23.8557\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 23.7180\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 23.5879\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 23.4567\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 23.3363\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 23.2063\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 23.0924\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 826us/step - loss: 22.9726\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 834us/step - loss: 22.8613\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 22.7565\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 767us/step - loss: 22.6428\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 22.5392\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 22.4402\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 22.3289\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 22.2237\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 22.1253\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 22.0274\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 766us/step - loss: 21.9314\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 21.8381\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 21.7496\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 21.6601\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 21.5738\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 779us/step - loss: 21.4931\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 21.4123\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 21.3376\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 856us/step - loss: 21.2581\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 820us/step - loss: 21.1885\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 21.1062\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 21.0371\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 20.9696\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 810us/step - loss: 20.9064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21aa6e01898>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42.2571]\n",
      " [42.2581]\n",
      " [42.2541]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1100 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1100 = pd.DataFrame()\n",
    "data_1100 = FUNCTION_1(data = data3, dataframe_new = data_1100, time = \"11:00:00\")\n",
    "data_1100_train = FUNCTION_2(data_1100, time=\"11:00:00\")[0]\n",
    "data_1100_test = FUNCTION_2(data_1100, time=\"11:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_1100_train[data_1100_train.columns[2:]].values\n",
    "X_test = data_1100_test[data_1100_test.columns[2:]].values\n",
    "\n",
    "y_train = data_1100_train[\"Value\"].values\n",
    "y_test = data_1100_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4178.8695\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 4130.6889\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 4074.0829\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 810us/step - loss: 4005.6233\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 786us/step - loss: 3899.1156\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 777us/step - loss: 3716.3829\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 868us/step - loss: 3559.9676\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 926us/step - loss: 3463.8852\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 3378.3070\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 3282.1219\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 3187.5879\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 3121.2070\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 947us/step - loss: 3071.2101\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 866us/step - loss: 3019.9811\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 989us/step - loss: 2959.9164\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 958us/step - loss: 2903.4776\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 979us/step - loss: 2847.2268\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 2780.9354\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 2714.9586\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2669.6356\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 2627.6351\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 987us/step - loss: 2586.48450s - loss: 2\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2547.2981\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2508.7825\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 901us/step - loss: 2472.4400\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 2435.6605\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2401.2383\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2366.2607\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 911us/step - loss: 2332.9849\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 2299.8253\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 2267.4988\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 2236.0829\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 2204.8061\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 2174.3806\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 841us/step - loss: 2144.6621\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 2114.9161\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 845us/step - loss: 2086.8692\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 2057.8445\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 834us/step - loss: 2030.4789\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 2003.1102\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 1976.0332\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 1949.8339\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 1924.0211\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 834us/step - loss: 1898.5067\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 1873.3299\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 852us/step - loss: 1849.2125\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 1824.3586\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 815us/step - loss: 1800.6160\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 867us/step - loss: 1777.6516\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 1754.6218\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 843us/step - loss: 1731.6824\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 1709.6925\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 872us/step - loss: 1687.8609\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 1666.5859\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 777us/step - loss: 1645.1001\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 1624.2952\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 1604.1979\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 1584.2848\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 784us/step - loss: 1564.0964\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 1545.0447\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 1525.9281\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 1507.1833\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 1488.8743\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 1470.6694\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 1452.8410\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 1435.5035\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 1417.2491\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 1389.2291\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 1361.8999\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 807us/step - loss: 1341.4919\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 1322.4218\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 826us/step - loss: 1304.0244\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 1286.8152\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 1270.0714\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 846us/step - loss: 1253.5707\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 1238.0943\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 1222.6532\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 1208.1006\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 810us/step - loss: 1193.1715\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 1179.5591\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 1165.4425\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 1152.4905\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 1139.1375\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 782us/step - loss: 1126.4293\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 1114.1330\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 1101.8823\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 1090.0747\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 831us/step - loss: 1078.5202\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 1067.2994\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 1056.2811\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 1045.6602\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 784us/step - loss: 1035.0226\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 1024.9052\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 845us/step - loss: 1014.8466\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 1005.2214\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 995.7074\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 986.4683\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 977.3271\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 968.6449\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 960.2758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21aa76d2780>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42.8866]\n",
      " [42.8868]\n",
      " [42.8863]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 58.5006\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 58.2584\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 57.8453\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 872us/step - loss: 57.1876\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 56.3733\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 55.2483\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 54.1225\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 53.2300\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 52.4381\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 51.1955\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 875us/step - loss: 49.8796\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 815us/step - loss: 49.1181\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 48.4991\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 47.8456\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 849us/step - loss: 47.2734\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 46.7476\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 46.3014\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 45.8858\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 45.4728\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 45.0763\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 44.6765\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 44.2799\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 43.8931\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 937us/step - loss: 43.5030\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 43.1241\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 966us/step - loss: 42.7430\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 932us/step - loss: 42.3766\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 42.0120\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 41.6560\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 865us/step - loss: 41.3120\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 40.9679\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 998us/step - loss: 40.6462\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 980us/step - loss: 40.3162\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 40.0017\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 863us/step - loss: 39.6799\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 39.3656\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 39.0447\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 38.7268\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 38.4151\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 38.1080\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 37.8000\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 37.4958\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 37.1990\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 36.9120\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 36.6248\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 36.3362\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 832us/step - loss: 36.0609\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 35.7912\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 35.5271\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 815us/step - loss: 35.2571\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 34.9945\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 34.7285\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 34.4612\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 34.2048\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 33.9484\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 33.7045\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 33.4689\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 33.2362\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 834us/step - loss: 32.9925\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 777us/step - loss: 32.7620\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 32.5246\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 32.2901\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 774us/step - loss: 32.0751\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 879us/step - loss: 31.8536\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 31.6449\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 31.4331\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 846us/step - loss: 31.2242\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 31.0225\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 774us/step - loss: 30.8290\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 30.6352\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 30.4470\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 831us/step - loss: 30.2621\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 30.0764\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 922us/step - loss: 29.8837\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 29.7035\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 29.5136\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 29.3352\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 29.1503\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 28.9786\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 28.7942\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 902us/step - loss: 28.6264\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 28.4697\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 831us/step - loss: 28.3101\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 28.1558\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 28.0157\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 27.8604\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 780us/step - loss: 27.7138\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 848us/step - loss: 27.5617\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 27.4134\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 27.2693\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 781us/step - loss: 27.1288\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 26.9822\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 26.8550\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 26.7205\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 26.5924\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 844us/step - loss: 26.4581\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 26.3294\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 869us/step - loss: 26.2075\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 26.0809\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 25.9570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21aa8ed5080>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45.3622]\n",
      " [45.3623]\n",
      " [45.3619]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1200 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1200 = pd.DataFrame()\n",
    "data_1200 = FUNCTION_1(data = data3, dataframe_new = data_1200, time = \"12:00:00\")\n",
    "data_1200_train = FUNCTION_2(data_1200, time=\"12:00:00\")[0]\n",
    "data_1200_test = FUNCTION_2(data_1200, time=\"12:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_1200_train[data_1200_train.columns[2:]].values\n",
    "X_test = data_1200_test[data_1200_test.columns[2:]].values\n",
    "\n",
    "y_train = data_1200_train[\"Value\"].values\n",
    "y_test = data_1200_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4548.4982\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 4511.6351\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 832us/step - loss: 4453.7086\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 4340.7116\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 4204.0079\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 4061.5683\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 3974.3205\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - ETA: 0s - loss: 3897.01 - 0s 796us/step - loss: 3913.0960\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 868us/step - loss: 3865.0547\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 826us/step - loss: 3806.3278\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 3718.5762\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 3664.5428\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 3606.3826\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 3545.4010\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 3481.8614\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 841us/step - loss: 3429.7788\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 3348.0020\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 3218.8681\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 3094.3066\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 3025.8354\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 2970.3542\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 2918.8113\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 831us/step - loss: 2870.2652\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 2824.2002\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 2779.5643\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 2736.7478\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 2695.5232\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 2654.2390\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 800us/step - loss: 2615.9698\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 2576.3628\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 2539.7522\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 2503.0744\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 2466.8640\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 935us/step - loss: 2432.2424\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 2397.4317\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 2364.2287\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 2331.1553\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 2298.3739\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 2266.8951\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 2235.8201\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 2205.0651\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 2175.1949\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 2145.6542\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 2116.5846\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 2088.2747\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 810us/step - loss: 2060.4238\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 2032.7824\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 2005.7539\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 1979.2565\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 1953.4341\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 951us/step - loss: 1927.7439\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 1902.4999\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 1877.9198\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 773us/step - loss: 1853.5724\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 1829.8531\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 1806.1118\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 1783.5051\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 1760.5198\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 1738.4886\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 849us/step - loss: 1716.7700\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 1694.8755\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 1674.0503\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 1653.3358\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 1632.7785\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 1613.3048\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 1592.9678\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 1573.8629\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 1554.8066\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 1536.4473\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 1518.0168\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 779us/step - loss: 1500.0781\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 1482.4773\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 1464.6239\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 1448.0855\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 772us/step - loss: 1431.3816\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 1414.9719\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 1398.7710\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 834us/step - loss: 1383.0030\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 1367.3170\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 768us/step - loss: 1352.4010\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 1337.2267\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 1322.7899\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 784us/step - loss: 1308.3349\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 779us/step - loss: 1294.0507\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 1280.3918\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 1266.8831\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 1253.7271\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 862us/step - loss: 1240.3793\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 1227.7701\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 784us/step - loss: 1215.3229\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 1202.7874\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 1190.9869\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 767us/step - loss: 1179.0456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 1167.5923\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 1156.4524\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 1145.1882\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 1134.3682\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 1123.7559\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 1113.2345\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 784us/step - loss: 1103.3096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21aaa821940>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43.2143]\n",
      " [43.2145]\n",
      " [43.2142]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 62.0106\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 61.5112\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 60.7714\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 59.8648\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 59.1452\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 58.5730\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 826us/step - loss: 57.6620\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 56.6585\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 800us/step - loss: 55.7755\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 807us/step - loss: 55.1574\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 54.6701\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 54.0600\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 780us/step - loss: 53.3735\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 52.9435\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 52.5386\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 52.1517\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 51.7711\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 51.4060\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 51.0539\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 758us/step - loss: 50.7162\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 977us/step - loss: 50.3771\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 777us/step - loss: 50.0508\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 751us/step - loss: 49.7211\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 692us/step - loss: 49.3361\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 48.9364\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 720us/step - loss: 48.5733\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 728us/step - loss: 48.2200\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 742us/step - loss: 47.8744\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 705us/step - loss: 47.5384\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 841us/step - loss: 47.2026\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 973us/step - loss: 46.8675\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 969us/step - loss: 46.5495\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 46.2276\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 45.9146\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 45.5843\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 45.1461\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 44.6857\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 938us/step - loss: 44.3312\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 43.9243\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 852us/step - loss: 43.5526\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 43.2083\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 42.8745\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 42.5646\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 42.2507\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 41.9455\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 41.6424\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 41.3460\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 772us/step - loss: 41.0518\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 40.7637\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 843us/step - loss: 40.4740\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 752us/step - loss: 40.1794\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - ETA: 0s - loss: 40.36 - 0s 768us/step - loss: 39.8024\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 782us/step - loss: 39.4439\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 854us/step - loss: 39.1181\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 38.8158\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 769us/step - loss: 38.5163\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 826us/step - loss: 38.2296\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 775us/step - loss: 37.9463\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 776us/step - loss: 37.6660\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 37.3972\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 37.1273\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 744us/step - loss: 36.8592\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 36.5945\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 36.3329\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 36.0755\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 35.8244\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 35.5792\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 782us/step - loss: 35.3398\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 35.0872\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 34.8441\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 34.6144\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 34.3747\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 34.1302\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 779us/step - loss: 33.9052\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 786us/step - loss: 33.6863\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 33.4627\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 33.2493\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 33.0286\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 32.8214\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 800us/step - loss: 32.6098\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 876us/step - loss: 32.4003\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 32.1947\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 31.9899\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 810us/step - loss: 31.8002\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 31.6088\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 31.4168\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 31.2410\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 826us/step - loss: 31.0636\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 784us/step - loss: 30.8846\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 778us/step - loss: 30.7222\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 30.5548\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 30.3905\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 30.2211\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 780us/step - loss: 30.0650\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 29.8930\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 799us/step - loss: 29.7285\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 769us/step - loss: 29.5705\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 29.4083\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 29.2429\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 29.0870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21aab14fe48>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42.7186]\n",
      " [42.7187]\n",
      " [42.7186]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1300 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1300 = pd.DataFrame()\n",
    "data_1300 = FUNCTION_1(data = data3, dataframe_new = data_1300, time = \"13:00:00\")\n",
    "data_1300_train = FUNCTION_2(data_1300, time=\"13:00:00\")[0]\n",
    "data_1300_test = FUNCTION_2(data_1300, time=\"13:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_1300_train[data_1300_train.columns[2:]].values\n",
    "X_test = data_1300_test[data_0800_test.columns[2:]].values\n",
    "\n",
    "y_train = data_1300_train[\"Value\"].values\n",
    "y_test = data_1300_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4199.2266\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 4176.9597\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 4131.5859\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 4057.6776\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 857us/step - loss: 3968.6851\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 3834.2899\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 772us/step - loss: 3687.5963\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 3603.2185\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 749us/step - loss: 3539.6462\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 704us/step - loss: 3466.3812\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 888us/step - loss: 3412.6000\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 3362.3022\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 807us/step - loss: 3309.2419\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 3244.1862\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 846us/step - loss: 3172.7032\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 3081.4774\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 831us/step - loss: 3012.2886\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 2930.4591\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 2853.9243\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 2801.7166\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 2753.0967\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 2707.3998\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 2663.6359\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 2622.0932\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 2581.5759\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 2542.5227\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 2504.8231\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 2467.5498\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 2431.9763\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 815us/step - loss: 2396.7936\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 775us/step - loss: 2362.5378\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 878us/step - loss: 2329.2997\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 2296.3090\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 781us/step - loss: 2264.3040\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 2232.8687\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 2201.8967\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 2171.9702\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 846us/step - loss: 2142.2373\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 2113.3147\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 2084.8682\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 2056.6790\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 2029.3079\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 852us/step - loss: 2002.2565\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 1975.9109\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 1949.9297\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 1924.4174\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 1899.0406\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 841us/step - loss: 1874.5800\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 810us/step - loss: 1850.1416\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 762us/step - loss: 1826.3177\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 1802.4013\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 1776.6273\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 1734.2682\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 1694.5087\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 807us/step - loss: 1667.8651\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 780us/step - loss: 1643.6382\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 1619.5172\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 777us/step - loss: 1596.5746\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 1574.5824\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 785us/step - loss: 1553.0396\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 1532.0600\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 1512.1748\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 773us/step - loss: 1491.6942\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 1472.8333\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 807us/step - loss: 1453.6104\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 1435.3339\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 1417.2566\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 849us/step - loss: 1399.5796\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 834us/step - loss: 1382.5085\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 1365.5918\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 1348.9254\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 1333.0002\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 1317.1385\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 1301.7955\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 853us/step - loss: 1286.4978\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 1271.7946\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 1257.2856\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 1243.0508\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 769us/step - loss: 1229.2068\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 807us/step - loss: 1215.9946\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 832us/step - loss: 1202.3878\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 1189.5035\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 1176.8642\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 1164.3328\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 1152.2528\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 779us/step - loss: 1140.5379\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 1128.5066\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 1117.5985\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 1106.5775\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 781us/step - loss: 1095.4156\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 1084.9050\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 1074.7228\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 960us/step - loss: 1064.3672\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 850us/step - loss: 1054.4847\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 781us/step - loss: 1045.0236\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 1035.5153\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 1026.3075\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 1017.3729\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 1008.4537\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 1000.1596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21aac9da6a0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43.3089]\n",
      " [43.3091]\n",
      " [43.309 ]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 59.3676\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 59.0736\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 815us/step - loss: 58.7185\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 58.1162\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 57.0433\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 854us/step - loss: 55.4687\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 54.0082\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 52.8305\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 859us/step - loss: 52.2292\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 51.5260\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 50.6723\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 49.7110\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 826us/step - loss: 49.0557\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 48.5895\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 48.0745\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 800us/step - loss: 47.4110\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 46.6632\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 46.1342\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 45.6247\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 45.0977\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 44.6617\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 763us/step - loss: 44.2410\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 43.8384\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 774us/step - loss: 43.4464\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 43.0635\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 42.7006\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 810us/step - loss: 42.3473\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 42.0004\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 41.6615\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 41.3308\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 41.0002\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 40.6834\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 40.3732\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 40.0578\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 39.7580\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 759us/step - loss: 39.4546\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 39.1571\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 38.8539\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 38.5570\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 784us/step - loss: 38.2680\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 37.9794\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 37.6979\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 37.4168\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 865us/step - loss: 37.1417\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 36.8683\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 36.6050\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 36.3397\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 36.0886\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 35.8279\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 35.5686\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 35.3132\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 35.0584\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 34.8027\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 946us/step - loss: 34.5502\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 942us/step - loss: 34.3027\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 909us/step - loss: 34.0594\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 929us/step - loss: 33.8179\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 856us/step - loss: 33.5747\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 33.3367\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 33.0966\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 32.8573\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 32.6195\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 32.3802\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 32.1415\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 31.9163\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 31.6934\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 31.4906\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 31.2872\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 31.0805\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 30.8838\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 30.6992\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 30.5135\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 30.3253\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 30.1427\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 841us/step - loss: 29.9590\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 832us/step - loss: 29.7739\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 29.5921\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 772us/step - loss: 29.4227\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 29.2477\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 29.0891\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 834us/step - loss: 28.9181\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 898us/step - loss: 28.7546\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 913us/step - loss: 28.5998\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 782us/step - loss: 28.4311\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 860us/step - loss: 28.2772\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 877us/step - loss: 28.1187\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 27.9687\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 27.8121\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 27.6596\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 815us/step - loss: 27.5057\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 27.3595\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 27.2105\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 27.0616\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 815us/step - loss: 26.9101\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 26.7606\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 788us/step - loss: 26.6245\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 26.4865\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 800us/step - loss: 26.3416\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 26.2138\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 26.0777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21aae241198>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46.4566]\n",
      " [46.4567]\n",
      " [46.4567]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1400 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1400 = pd.DataFrame()\n",
    "data_1400 = FUNCTION_1(data = data3, dataframe_new = data_1400, time = \"14:00:00\")\n",
    "data_1400_train = FUNCTION_2(data_1400, time=\"14:00:00\")[0]\n",
    "data_1400_test = FUNCTION_2(data_1400, time=\"14:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_1400_train[data_1400_train.columns[2:]].values\n",
    "X_test = data_1400_test[data_1400_test.columns[2:]].values\n",
    "\n",
    "y_train = data_1400_train[\"Value\"].values\n",
    "y_test = data_1400_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 3435.6294\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 858us/step - loss: 3381.5992\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 3307.8158\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 826us/step - loss: 3217.2979\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 3097.7365\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 2975.2462\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 2877.0938\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 2774.0163\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 2716.0351\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 2676.53720s - loss: 2842.\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 2639.9430\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 810us/step - loss: 2605.4283\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 831us/step - loss: 2572.1647\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 2538.3198\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 2479.2958\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 2414.2422\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 2375.2169\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 2339.0286\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 2305.3074\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 2272.8164\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 2241.7929\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 2211.0640\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 807us/step - loss: 2181.9344\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 807us/step - loss: 2152.3901\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 2124.4923\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 2096.1760\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 815us/step - loss: 2066.2251\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 2019.6799\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 1979.5016\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 848us/step - loss: 1949.2368\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 846us/step - loss: 1920.9800\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 1893.2268\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 1866.6964\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 807us/step - loss: 1840.9792\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 1815.9233\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 1791.3312\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 1767.6127\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 1744.1158\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 1720.8599\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 1698.5021\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 1676.5208\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 848us/step - loss: 1655.1428\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 1633.4682\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 857us/step - loss: 1612.9478\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 1592.3880\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 769us/step - loss: 1572.5701\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 1552.5588\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 1533.2362\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 864us/step - loss: 1514.5898\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 845us/step - loss: 1495.5276\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 826us/step - loss: 1477.3194\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 1459.4118\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 1441.7763\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 1424.0651\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 1407.4189\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 1390.2090\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 781us/step - loss: 1373.8032\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 1357.7606\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 1341.5170\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 1326.2609\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 1308.6927\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 810us/step - loss: 1287.3149\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 832us/step - loss: 1267.6999\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 1249.7448\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 1232.5047\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 1216.1923\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 1200.3495\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 1185.5031\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 1170.3101\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 848us/step - loss: 1156.0452\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 1142.0627\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 1128.7670\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 1115.3154\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 861us/step - loss: 1102.6325\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 1089.7308\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 1078.0163\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 1065.6726\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 1053.9774\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 1042.5447\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 1031.5506\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 779us/step - loss: 1020.5885\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 1010.1243\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 832us/step - loss: 999.6469\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 773us/step - loss: 989.4554\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 979.8026\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 831us/step - loss: 970.0094\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 960.5996\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 951.3463\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 942.6017\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 933.7196\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 925.1896\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 916.5270\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 908.6923\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 778us/step - loss: 900.6228\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 892.9602\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 885.1977\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 878.1205\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 870.6970\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 863.6913\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 918us/step - loss: 856.7262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21aafb1be10>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38.5009]\n",
      " [38.5011]\n",
      " [38.5011]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 52.6399\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 888us/step - loss: 52.2433\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 826us/step - loss: 51.8232\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 51.0655\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 49.8107\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 48.8537\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 859us/step - loss: 47.9317\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 859us/step - loss: 46.7991\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 46.1087\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 859us/step - loss: 45.5923\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 44.8299\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 44.4091\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 44.0117\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 43.5906\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 858us/step - loss: 42.9653\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 42.3689\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 41.9490\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 41.4891\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 40.8290\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 40.4022\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 960us/step - loss: 39.9468\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 39.3502\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 38.9403\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 38.5759\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 979us/step - loss: 38.2029\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 37.8117\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 37.3183\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 36.8993\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 36.5290\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 36.1729\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 35.8169\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 973us/step - loss: 35.4841\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 35.1559\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 884us/step - loss: 34.8359\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 946us/step - loss: 34.5289\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 843us/step - loss: 34.2271\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 921us/step - loss: 33.9335\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 33.6392\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 905us/step - loss: 33.3666\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 972us/step - loss: 33.0945\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 952us/step - loss: 32.8339\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 32.5733\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 868us/step - loss: 32.3117\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 32.0610\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 31.8148\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 31.5679\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 31.3281\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 31.0876\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 30.8590\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 826us/step - loss: 30.6259\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 30.3953\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 826us/step - loss: 30.1706\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 29.9537\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 29.7464\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 29.5214\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 29.3283\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 29.1263\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 28.9238\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 28.7317\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 28.5379\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 28.3399\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 853us/step - loss: 28.1499\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 783us/step - loss: 27.9683\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 27.7894\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 27.6037\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 27.4308\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 856us/step - loss: 27.2535\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 27.0862\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 859us/step - loss: 26.9220\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 848us/step - loss: 26.7653\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 26.6066\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 784us/step - loss: 26.4520\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 841us/step - loss: 26.2954\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 26.1444\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 25.9907\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 25.8377\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 25.6933\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 25.5476\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 856us/step - loss: 25.3952\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 25.2563\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 860us/step - loss: 25.1129\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 921us/step - loss: 24.9784\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 740us/step - loss: 24.8480\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 757us/step - loss: 24.7133\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 693us/step - loss: 24.5824\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 725us/step - loss: 24.4482\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 768us/step - loss: 24.3197\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 767us/step - loss: 24.1962\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 24.0768\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 23.9501\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 757us/step - loss: 23.8354\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 749us/step - loss: 23.7231\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 23.6153\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 689us/step - loss: 23.5099\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 761us/step - loss: 23.4061\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 721us/step - loss: 23.3062\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 23.2124\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 778us/step - loss: 23.1218\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 23.0382\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 776us/step - loss: 22.9552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21ab1409c88>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44.5503]\n",
      " [44.5505]\n",
      " [44.5505]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1500 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1500 = pd.DataFrame()\n",
    "data_1500 = FUNCTION_1(data = data3, dataframe_new = data_1500, time = \"15:00:00\")\n",
    "data_1500_train = FUNCTION_2(data_1500, time=\"15:00:00\")[0]\n",
    "data_1500_test = FUNCTION_2(data_1500, time=\"15:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_1500_train[data_1500_train.columns[2:]].values\n",
    "X_test = data_1500_test[data_1500_test.columns[2:]].values\n",
    "\n",
    "y_train = data_1500_train[\"Value\"].values\n",
    "y_test = data_1500_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 1ms/step - loss: 2098.1475\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 2012.1106\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 772us/step - loss: 1940.6077\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 759us/step - loss: 1883.6419\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 739us/step - loss: 1835.1512\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 705us/step - loss: 1774.6309\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 761us/step - loss: 1694.4633\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 711us/step - loss: 1635.3293\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 735us/step - loss: 1597.0690\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 1548.6661\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 774us/step - loss: 1485.1232\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 786us/step - loss: 1442.6908\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 759us/step - loss: 1409.7381\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 696us/step - loss: 1380.7133\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 1352.8107\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 723us/step - loss: 1326.5226\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 718us/step - loss: 1300.4212\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 807us/step - loss: 1271.4732\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 770us/step - loss: 1237.2350\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 733us/step - loss: 1209.5884\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 700us/step - loss: 1185.1780\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 716us/step - loss: 1161.6401\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 923us/step - loss: 1139.3379\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 1117.8054\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 735us/step - loss: 1097.1930\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 724us/step - loss: 1076.8560\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 878us/step - loss: 1057.8453\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 739us/step - loss: 1038.4450\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 776us/step - loss: 1020.3117\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 738us/step - loss: 1002.8858\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 985.2611\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 735us/step - loss: 968.4586\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 701us/step - loss: 952.1885\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 731us/step - loss: 936.3373\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 719us/step - loss: 921.0328\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 905.9351\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 719us/step - loss: 891.3958\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 869us/step - loss: 877.2646\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 717us/step - loss: 863.0957\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 693us/step - loss: 849.9841\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 707us/step - loss: 837.0659\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 728us/step - loss: 824.2742\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 812.0641\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 681us/step - loss: 800.2403\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 735us/step - loss: 788.2975\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 705us/step - loss: 776.9874\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 699us/step - loss: 766.3476\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 720us/step - loss: 755.4385\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 700us/step - loss: 745.2439\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 728us/step - loss: 735.2152\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 700us/step - loss: 725.3380\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 735us/step - loss: 715.9471\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 725us/step - loss: 706.9742\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 715us/step - loss: 697.9717\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 717us/step - loss: 689.1804\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 703us/step - loss: 680.8961\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 721us/step - loss: 673.0477\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 713us/step - loss: 664.9406\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 770us/step - loss: 657.3708\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 725us/step - loss: 649.8976\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 700us/step - loss: 642.9777\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 714us/step - loss: 636.0232\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 754us/step - loss: 629.5470\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 720us/step - loss: 622.7029\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 709us/step - loss: 616.4595\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 742us/step - loss: 610.8997\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 736us/step - loss: 604.7202\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 875us/step - loss: 599.0562\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 696us/step - loss: 593.5535\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 710us/step - loss: 588.4267\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 696us/step - loss: 583.2549\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 578.5240\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 942us/step - loss: 573.7519\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 569.0977\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 775us/step - loss: 564.6696\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 767us/step - loss: 560.5303\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 815us/step - loss: 556.4866\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 781us/step - loss: 552.3624\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 735us/step - loss: 548.8346\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 728us/step - loss: 545.1077\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 730us/step - loss: 541.7177\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 739us/step - loss: 538.1879\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 780us/step - loss: 535.2109\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 531.8445\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 952us/step - loss: 529.0524\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 712us/step - loss: 526.2093\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 733us/step - loss: 523.4482\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 732us/step - loss: 520.8971\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 746us/step - loss: 518.2745\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 905us/step - loss: 516.0274\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 758us/step - loss: 513.6432\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 738us/step - loss: 511.4267\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 728us/step - loss: 509.3471\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 854us/step - loss: 507.4879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 772us/step - loss: 505.4058\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 740us/step - loss: 503.6237\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 874us/step - loss: 501.9937\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 899us/step - loss: 500.1528\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 711us/step - loss: 498.1965\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 493.6845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21ab1cb1b00>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33.2585]\n",
      " [36.6509]\n",
      " [36.6828]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 41.3920\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 771us/step - loss: 40.9250\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 40.5605\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 40.0635\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 39.4427\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 38.7474\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 37.9772\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 37.2137\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 36.5205\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 35.7599: 0s - loss: 36.\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 34.7361\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 33.9766\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 33.2736\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 890us/step - loss: 32.6204\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 32.1341\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 911us/step - loss: 31.6844\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 947us/step - loss: 31.2675\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 30.8707\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 30.4859\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 856us/step - loss: 30.1186\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 851us/step - loss: 29.7609\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 941us/step - loss: 29.4111\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 771us/step - loss: 29.0713\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 722us/step - loss: 28.7464\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 874us/step - loss: 28.4319\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 28.1342\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 716us/step - loss: 27.8301\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 884us/step - loss: 27.5447\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 710us/step - loss: 27.2723\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 933us/step - loss: 27.0120\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 850us/step - loss: 26.7615\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 760us/step - loss: 26.5144\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 707us/step - loss: 26.2813\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 689us/step - loss: 26.0468\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 957us/step - loss: 25.8250\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 777us/step - loss: 25.6101\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 776us/step - loss: 25.3957\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 764us/step - loss: 25.2034\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 717us/step - loss: 24.9990\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 721us/step - loss: 24.8077\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 24.6113\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 734us/step - loss: 24.4242\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 764us/step - loss: 24.2364\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 892us/step - loss: 24.05110s - loss: 2\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 760us/step - loss: 23.8737\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 691us/step - loss: 23.6998\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 736us/step - loss: 23.5295\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 23.3562\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 724us/step - loss: 23.1893\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 712us/step - loss: 23.0158\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 780us/step - loss: 22.8459\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 884us/step - loss: 22.6800\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 695us/step - loss: 22.5112\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 723us/step - loss: 22.3441\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 731us/step - loss: 22.1840\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 694us/step - loss: 22.0362\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 756us/step - loss: 21.8899\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 684us/step - loss: 21.7503\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 21.6121\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 897us/step - loss: 21.4819\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 689us/step - loss: 21.3546\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 734us/step - loss: 21.2302\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 910us/step - loss: 21.1045\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 692us/step - loss: 20.9716\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 715us/step - loss: 20.8553\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 20.7306\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 772us/step - loss: 20.6148\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 20.5045\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 907us/step - loss: 20.3989\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 20.2854\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 962us/step - loss: 20.1804\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 857us/step - loss: 20.0846\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 897us/step - loss: 19.9935\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 869us/step - loss: 19.9005\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 19.8146\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 967us/step - loss: 19.7269\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 863us/step - loss: 19.65270s - loss:\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 19.5636\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 19.4979\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 19.4235\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 19.3545\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 832us/step - loss: 19.2862\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 19.2276\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 866us/step - loss: 19.1718\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 19.1181\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 19.0656\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 19.0181\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 895us/step - loss: 18.9762\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 928us/step - loss: 18.9310\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 945us/step - loss: 18.8828\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 849us/step - loss: 18.8399\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 891us/step - loss: 18.7957\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 777us/step - loss: 18.7500\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 871us/step - loss: 18.7095\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 887us/step - loss: 18.6599\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 838us/step - loss: 18.6195\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 18.5765\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 18.5384\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 18.5044\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 18.4707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21ab35ff4a8>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37.7606]\n",
      " [37.761 ]\n",
      " [37.7611]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1600 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1600 = pd.DataFrame()\n",
    "data_1600 = FUNCTION_1(data = data3, dataframe_new = data_1600, time = \"16:00:00\")\n",
    "data_1600_train = FUNCTION_2(data_1600, time=\"16:00:00\")[0]\n",
    "data_1600_test = FUNCTION_2(data_1600, time=\"16:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_1600_train[data_0800_train.columns[2:]].values\n",
    "X_test = data_1600_test[data_0800_test.columns[2:]].values\n",
    "\n",
    "y_train = data_1600_train[\"Value\"].values\n",
    "y_test = data_1600_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 875.1754\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 846us/step - loss: 855.7255 0s - loss: 751.01\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 852us/step - loss: 828.3828\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 862us/step - loss: 793.4691\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 853us/step - loss: 764.5998\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 852us/step - loss: 725.7843\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 680.8508\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 865us/step - loss: 640.6271\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 863us/step - loss: 603.0067\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 848us/step - loss: 571.0104\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 860us/step - loss: 549.0108\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 524.2411\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 496.4420\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 471.4729\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 851us/step - loss: 455.7397\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 442.1614\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 874us/step - loss: 430.2612\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 418.9650 0s - loss: 413.13\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 846us/step - loss: 408.7888\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 848us/step - loss: 399.2917\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 867us/step - loss: 390.5303\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 855us/step - loss: 382.0893\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 841us/step - loss: 374.3684\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 850us/step - loss: 367.1808\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 841us/step - loss: 360.0897\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 810us/step - loss: 353.8638\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 857us/step - loss: 347.6816\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 341.4583\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 335.2457\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 328.5629\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 879us/step - loss: 321.2370\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 868us/step - loss: 315.4575\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 308.1439\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 303.2026\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 852us/step - loss: 296.5543\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 862us/step - loss: 290.4146\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 952us/step - loss: 285.1849\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 873us/step - loss: 280.3645\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 902us/step - loss: 275.9992\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 881us/step - loss: 271.2322\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 267.2261\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 263.1741\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 972us/step - loss: 259.1265\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 255.2948\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 252.1877\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 248.6226\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 244.6924\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 241.5110\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 238.1801\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 235.2762\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 879us/step - loss: 232.7920\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 230.1604\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 226.8066\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 890us/step - loss: 224.2309\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 221.6899\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 219.2729\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 218.2756\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 215.5640\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 214.5142\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 907us/step - loss: 210.7211\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 208.5556\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 207.2399\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 841us/step - loss: 205.1061\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 886us/step - loss: 203.4313\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 920us/step - loss: 202.7051\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 859us/step - loss: 201.1370\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 199.1090\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 886us/step - loss: 197.7509\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 871us/step - loss: 196.3983\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 195.5663\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 193.9602\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 193.2493\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 192.4637\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 947us/step - loss: 190.9519\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 190.0448\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 189.0721\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 992us/step - loss: 188.8289\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 188.0749\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 186.3700\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 862us/step - loss: 186.3824\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 904us/step - loss: 184.9778\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 184.4945\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 979us/step - loss: 183.3712\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 183.0907\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 182.2078\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 857us/step - loss: 182.2200\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 181.4838\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 180.4996\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 859us/step - loss: 180.0706\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 945us/step - loss: 180.6776\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 181.3533\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 950us/step - loss: 178.8834\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 949us/step - loss: 178.2464\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 177.2316\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 842us/step - loss: 176.7399\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 862us/step - loss: 176.5537\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 896us/step - loss: 176.2372\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 831us/step - loss: 175.9489\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 175.1574\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 175.1735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21ab4ee16d8>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13.18  ]\n",
      " [31.3982]\n",
      " [31.4061]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 25.4899\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 775us/step - loss: 24.9346\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 845us/step - loss: 24.3562\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 23.6082\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 859us/step - loss: 22.6991\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 21.8357\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 875us/step - loss: 21.1983\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 20.6896\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 20.0775\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 19.5938\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 19.2623\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 845us/step - loss: 18.9772\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 826us/step - loss: 18.6730\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 18.3094\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 18.0039\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 854us/step - loss: 17.7336\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 17.4596\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 17.0287\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 874us/step - loss: 16.7151\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 852us/step - loss: 16.5027\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 815us/step - loss: 16.3011\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 16.1176\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 15.9565\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 815us/step - loss: 15.8159\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 15.6948\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 778us/step - loss: 15.5764\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 868us/step - loss: 15.4676\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 15.3640\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 15.2639\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 879us/step - loss: 15.1789\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 907us/step - loss: 15.0944\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 904us/step - loss: 15.0250\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 14.9476\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 882us/step - loss: 14.8460\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 14.6628\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 14.5164\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 14.3088\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 14.2016\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 14.0692\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 13.9610\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 13.8272\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 864us/step - loss: 13.7077\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 13.5943\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 853us/step - loss: 13.4849\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 13.3821\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 13.2833\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 13.1801\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 13.0732\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 807us/step - loss: 12.9656\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 834us/step - loss: 12.9322\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 810us/step - loss: 12.8648\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 763us/step - loss: 12.7141\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 12.6428\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 861us/step - loss: 12.5426\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 848us/step - loss: 12.4711\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 894us/step - loss: 12.3741\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 905us/step - loss: 12.3287\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 961us/step - loss: 12.2661\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 12.1780\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 902us/step - loss: 12.1130\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 12.0345\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 912us/step - loss: 11.9746\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 935us/step - loss: 11.9362\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 930us/step - loss: 11.8502\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 948us/step - loss: 11.8252\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 900us/step - loss: 11.8555\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 899us/step - loss: 11.7518\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 928us/step - loss: 11.7175\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 11.6501\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 11.5904\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 810us/step - loss: 11.6214\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 11.5108\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 892us/step - loss: 11.5209\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 776us/step - loss: 11.4544\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 11.4318\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 771us/step - loss: 11.3755\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 826us/step - loss: 11.3203\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 11.3557\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 939us/step - loss: 11.2596\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 941us/step - loss: 11.2199\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 11.2177\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 11.1623\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 907us/step - loss: 11.1680\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 11.16220s - loss: 11.\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 908us/step - loss: 11.0731\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 11.0420\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 11.0568\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 10.9910\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 10.9435\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 10.9748\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 923us/step - loss: 10.9292\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 10.9265\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 10.9647\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 10.9140\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 10.8022\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 959us/step - loss: 10.7824\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 10.7199\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 929us/step - loss: 10.7106\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 775us/step - loss: 10.7114\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 10.6467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21ab5822080>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.7368]\n",
      " [31.0443]\n",
      " [31.0036]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1700 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1700 = pd.DataFrame()\n",
    "data_1700 = FUNCTION_1(data = data3, dataframe_new = data_1700, time = \"17:00:00\")\n",
    "data_1700_train = FUNCTION_2(data_1700, time=\"17:00:00\")[0]\n",
    "data_1700_test = FUNCTION_2(data_1700, time=\"17:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_1700_train[data_1700_train.columns[2:]].values\n",
    "X_test = data_1700_test[data_0800_test.columns[2:]].values\n",
    "\n",
    "y_train = data_1700_train[\"Value\"].values\n",
    "y_test = data_1700_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 222.7215\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 725us/step - loss: 209.0449\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 730us/step - loss: 192.7411\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 768us/step - loss: 176.1776\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 747us/step - loss: 153.6161\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 945us/step - loss: 136.2905\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 126.6463\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 120.3711\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 114.5664\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 108.5246\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 101.2032\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 700us/step - loss: 95.7953\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 751us/step - loss: 91.8024\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 741us/step - loss: 88.2412\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 698us/step - loss: 84.9126\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 749us/step - loss: 82.0633\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 764us/step - loss: 79.2624\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 713us/step - loss: 76.7966\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 748us/step - loss: 74.12560s - loss: 69.06\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 703us/step - loss: 70.9563\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 726us/step - loss: 67.8068\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 685us/step - loss: 65.3728\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 63.8097\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 62.5831\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 61.1226\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 711us/step - loss: 59.8541\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 58.8472\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 728us/step - loss: 57.7435\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 843us/step - loss: 56.8869\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 55.8932\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 55.2635\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 54.6827\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 54.3757\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 53.4977\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 52.7467\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 52.4409: 0s - loss:\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 52.0131\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 51.4447\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 50.9757\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 50.7771\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 50.5489\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 50.1306\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 49.5812\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 49.5874\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 49.2365\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 907us/step - loss: 48.6451\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 907us/step - loss: 48.8055\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 48.4285\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 954us/step - loss: 48.1522\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 48.5388\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 48.2851\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 48.0607\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 972us/step - loss: 47.2194\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 47.8419\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 879us/step - loss: 47.8187\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 46.8525\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 752us/step - loss: 46.9911\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 718us/step - loss: 46.5760\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 983us/step - loss: 46.6510\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 46.2127\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 746us/step - loss: 46.0942\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 962us/step - loss: 45.8054\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 907us/step - loss: 46.4356\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 45.9820\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 45.7967\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 45.8009\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 998us/step - loss: 45.6623\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 45.5757\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 861us/step - loss: 45.9216\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 46.1341\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 47.3297\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 45.5231\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 846us/step - loss: 45.0953\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 859us/step - loss: 45.2135\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 848us/step - loss: 45.0537\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 44.7613\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 862us/step - loss: 44.6632\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 44.7549\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 44.6147\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 872us/step - loss: 44.8719\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 859us/step - loss: 44.5488\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 907us/step - loss: 45.0551\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 933us/step - loss: 44.3413\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 44.8705\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 44.5005\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 920us/step - loss: 44.6919\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 952us/step - loss: 44.4264\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 45.0050\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 970us/step - loss: 44.3043\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 45.15560s - loss: 48.\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 44.2882\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 44.1214\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 944us/step - loss: 44.1984\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 848us/step - loss: 44.1086\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 780us/step - loss: 43.7195\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 791us/step - loss: 43.9358\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 44.0156\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 43.8833\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 44.0807\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 43.7897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21ab70f5ac8>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.6404]\n",
      " [18.1564]\n",
      " [20.6641]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 11.4785\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 10.9474\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 10.4470\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 862us/step - loss: 9.9867\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 9.4888\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 8.9761\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 8.6447\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 8.3762\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 8.1475\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 7.9332\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 7.7216\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 7.4942\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 7.3026\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 7.1690\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 853us/step - loss: 7.0251\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 6.9108\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 6.7999\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 6.6983\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 6.5800\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 6.4873\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 6.3934\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 6.3051\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 849us/step - loss: 6.2461\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 6.1658\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 6.1072\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 826us/step - loss: 6.0577\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 834us/step - loss: 5.9890\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 5.9251\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 5.8716\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 810us/step - loss: 5.8247\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 5.7622\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 5.7214\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 826us/step - loss: 5.6709\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 5.6230\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 5.6067\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 5.5514\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 5.5083\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 5.4792\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 5.4396\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 5.4356\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 876us/step - loss: 5.3867\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 781us/step - loss: 5.3960\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 5.3247\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 5.2808\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 5.2789\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 907us/step - loss: 5.2124\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 5.1967\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 5.1769\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 5.1295\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 5.1057\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 5.0889\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 902us/step - loss: 5.0964\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 5.1078\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 895us/step - loss: 5.0876\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 5.0606\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 907us/step - loss: 5.0209\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 859us/step - loss: 5.0299\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 940us/step - loss: 4.9954\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 933us/step - loss: 4.9599\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 4.9631\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.9982\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 907us/step - loss: 4.9577\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 936us/step - loss: 4.9123\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 845us/step - loss: 4.9060\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.8868\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 913us/step - loss: 4.8818\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 4.8680\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 961us/step - loss: 4.8607\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 846us/step - loss: 4.8750\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 4.8477\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 4.8496\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 4.8060\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 800us/step - loss: 4.8262\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 867us/step - loss: 4.8146\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 4.7900\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 939us/step - loss: 4.7966\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 895us/step - loss: 4.7829\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 872us/step - loss: 4.7808\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 4.7733\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 4.7657\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 4.7632\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 4.7943\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 826us/step - loss: 4.7717\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 4.7954\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 4.7478\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 4.7356\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 4.7285\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 4.7347\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 4.7207\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 4.7152\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 4.8016\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 4.7331\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 4.7202\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 869us/step - loss: 4.7179\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 854us/step - loss: 4.6914 0s - loss: 4.687\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 4.7262\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 804us/step - loss: 4.7076\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 4.7107\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 4.6937\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 845us/step - loss: 4.7156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21ab99ac1d0>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.6508]\n",
      " [20.7537]\n",
      " [21.33  ]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1800 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1800 = pd.DataFrame()\n",
    "data_1800 = FUNCTION_1(data = data3, dataframe_new = data_1800, time = \"18:00:00\")\n",
    "data_1800_train = FUNCTION_2(data_1800, time=\"18:00:00\")[0]\n",
    "data_1800_test = FUNCTION_2(data_1800, time=\"18:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_1800_train[data_1800_train.columns[2:]].values\n",
    "X_test = data_1800_test[data_1800_test.columns[2:]].values\n",
    "\n",
    "y_train = data_1800_train[\"Value\"].values\n",
    "y_test = data_1800_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 30.0496\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 24.2026\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 951us/step - loss: 19.2725\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 859us/step - loss: 15.9834\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 909us/step - loss: 13.3231\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 884us/step - loss: 11.1035\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 9.1778\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 8.1053\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 7.3998\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 7.0196\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 6.7740\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 6.6249\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 6.5232\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 845us/step - loss: 6.4461\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 6.3928\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 6.3639\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 6.3154\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 6.2956\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 6.2846\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 6.2317\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 6.1968\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 6.1732\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 856us/step - loss: 6.1322\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 6.1374\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 6.1483\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 826us/step - loss: 6.1054\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 6.1019\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 852us/step - loss: 6.1078\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 6.0617\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 826us/step - loss: 6.0495\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 6.0529\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 852us/step - loss: 6.0576\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 6.0092\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 848us/step - loss: 6.0021\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 6.0000\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 6.0199\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 5.9967\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 846us/step - loss: 5.9538\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 5.9897 0s - loss: 5.8\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 843us/step - loss: 5.9300\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 5.9632\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 5.9435\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 5.9186\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 5.8960\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 5.8898\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 849us/step - loss: 5.9158\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 851us/step - loss: 5.8847\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 784us/step - loss: 5.8779\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 852us/step - loss: 5.8784\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 850us/step - loss: 5.8675\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 5.8606\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 848us/step - loss: 5.8372\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 5.8248\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 5.8570\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 5.8414\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 5.8295\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 5.8139\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 5.8266\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 5.8086\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 5.8533\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 832us/step - loss: 5.8168\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 5.7841\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 5.8979\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 5.7700\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 5.7554\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 5.7704\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 5.7459\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 779us/step - loss: 5.7462\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 5.7794\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 5.7531\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 5.7589\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 5.7004\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 5.7061\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 5.7533\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 5.6796\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 845us/step - loss: 5.6931\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 5.6530\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 5.6813\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 871us/step - loss: 5.7914\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 841us/step - loss: 5.6591\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 5.6476\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 5.6487\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 5.6373\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 5.6236\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 5.6044\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 5.6105\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 5.5681\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 858us/step - loss: 5.5728\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 5.5919\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 871us/step - loss: 5.5668\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 5.5657\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 5.5677\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 826us/step - loss: 5.5142\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 5.5145\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 5.5191\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 5.6071\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 1ms/step - loss: 5.5447\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 5.5233\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 832us/step - loss: 5.5006\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 873us/step - loss: 5.5721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21aba2b9208>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.022 ]\n",
      " [5.2969]\n",
      " [8.2823]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 2.9199\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 2.6436\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 2.3438\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 2.0474\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 815us/step - loss: 1.8321\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 1.7204\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 1.6404\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 1.5976\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 1.5636\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 1.5478\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 1.5408\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 1.5252\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 784us/step - loss: 1.5185\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 1.5270\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 1.5078\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 1.5082\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 1.5101\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 1.5035\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 1.5058\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 1.4977\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 841us/step - loss: 1.4986\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 1.4960\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - ETA: 0s - loss: 1.526 - 0s 793us/step - loss: 1.4941\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 800us/step - loss: 1.4882\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 1.4839\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 896us/step - loss: 1.4851\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 869us/step - loss: 1.4821\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 834us/step - loss: 1.4788\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 852us/step - loss: 1.4797\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 1.4825\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 1.4770\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 1.4689\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 1.4676 0s - loss: 1.5\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 843us/step - loss: 1.4630\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 1.4623\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 1.4590 0s - loss: 1.405\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 1.4721\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 780us/step - loss: 1.4721\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 1.4550 0s - loss: 1.35\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 1.4590\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 1.4518\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 1.4485 0s - loss: 1.46\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 800us/step - loss: 1.4469\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 1.4445\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 1.4483\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 1.4386\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 1.4496\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 1.4449\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 1.4399\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 1.4356\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 826us/step - loss: 1.4406\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 1.4374\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 1.4364\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 757us/step - loss: 1.4404\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 909us/step - loss: 1.4292\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 783us/step - loss: 1.4332\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 1.4304\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 1.4250\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 776us/step - loss: 1.4373\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 1.4239\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 1.4214\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 1.4248\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 1.4297\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 1.4234\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 1.4238\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 1.4153\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 1.4192\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 1.4146\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 1.4138\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 1.4105\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 800us/step - loss: 1.4202\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 1.4125\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 779us/step - loss: 1.4153\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 1.4112\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 1.4198\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 1.4175\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 1.4172\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 765us/step - loss: 1.4129\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 1.4176\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 781us/step - loss: 1.4120\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 1.4019\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 1.4003\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 934us/step - loss: 1.3997\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 1.4004\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 911us/step - loss: 1.3929\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 1.3923\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 1.3934\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 1.3895\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 1.3954\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 1.4008\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 859us/step - loss: 1.3883\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 907us/step - loss: 1.4067\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 850us/step - loss: 1.3895\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 1.3945\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 1.3851\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 907us/step - loss: 1.3857\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 859us/step - loss: 1.3945\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 1.3843\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 1.3841\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 1.3771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21ababac278>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04  ]\n",
      " [5.4581]\n",
      " [9.3619]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1900 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1900 = pd.DataFrame()\n",
    "data_1900 = FUNCTION_1(data = data3, dataframe_new = data_1900, time = \"19:00:00\")\n",
    "data_1900_train = FUNCTION_2(data_1900, time=\"19:00:00\")[0]\n",
    "data_1900_test = FUNCTION_2(data_1900, time=\"19:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_1900_train[data_1900_train.columns[2:]].values\n",
    "X_test = data_1900_test[data_1900_test.columns[2:]].values\n",
    "\n",
    "y_train = data_1900_train[\"Value\"].values\n",
    "y_test = data_1900_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 0.6164\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 859us/step - loss: 0.3784\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 916us/step - loss: 0.2615\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 0.1979\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 871us/step - loss: 0.1669\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 807us/step - loss: 0.1547\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 0.1538\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 0.1527\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 0.1518\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 0.1510\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 0.1514\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 0.1507\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 0.1515\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 862us/step - loss: 0.1527\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 0.1495\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 0.1492\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 0.1497\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 871us/step - loss: 0.1502\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 0.1496\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 0.1501\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 0.1477\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 0.1476\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 0.1525\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 0.1471\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 0.1483\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 864us/step - loss: 0.1468\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 0.1471\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 0.1463\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 0.1467\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 0.1479\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 850us/step - loss: 0.1457\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 0.1470\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 870us/step - loss: 0.1465\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 848us/step - loss: 0.1465\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 0.1455\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 0.1465\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 0.1452\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 0.1470\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 0.1457\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 0.1459\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 783us/step - loss: 0.1454\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 0.1466\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 0.1462\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 0.1458\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 0.1460\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 815us/step - loss: 0.1451\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 846us/step - loss: 0.1446\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 0.1443\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 0.1442\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 0.1447\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 0.1445\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 0.1452\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 0.1442\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 856us/step - loss: 0.1456\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 0.1441\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 785us/step - loss: 0.1443\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 0.1445\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 0.1441\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 0.1441\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 0.1437\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 0.1457\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 0.1437\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 0.1445\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 0.1444\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 0.1434\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 757us/step - loss: 0.1441\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 0.1447\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 0.1482\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 0.1463\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 775us/step - loss: 0.1438\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 856us/step - loss: 0.1436\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 807us/step - loss: 0.1432\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 778us/step - loss: 0.1432\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 854us/step - loss: 0.1441\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 0.1433\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 0.1439\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 781us/step - loss: 0.1433 0s - loss: 0.1\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 872us/step - loss: 0.1440\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 800us/step - loss: 0.1450\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 850us/step - loss: 0.1432\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 0.1435\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 0.1433\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 0.1443\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 0.1436\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 0.1430\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 0.1453\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 0.1440\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 0.1430\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 832us/step - loss: 0.1433\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 0.1440\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 0.1434\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 0.1430\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 815us/step - loss: 0.1426\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 845us/step - loss: 0.1429\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 0.1425\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 869us/step - loss: 0.1432\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 902us/step - loss: 0.1434 0s - loss: 0.1\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.1438\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 940us/step - loss: 0.1426\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 956us/step - loss: 0.1422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21abc499e10>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0052]\n",
      " [ 0.0224]\n",
      " [ 1.4061]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 33.8842 - accuracy: 0.0000e+00A: 0s - loss: 32.5713 - accuracy: 0.0000e+\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 810us/step - loss: 33.2978 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 32.3279 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 872us/step - loss: 31.8180 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 767us/step - loss: 30.9350 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 30.7824 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 772us/step - loss: 29.9631 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 29.8694 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 851us/step - loss: 29.1286 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 887us/step - loss: 28.9155 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 28.5629 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 28.3317 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 27.5259 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 26.9927 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 27.2761 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 917us/step - loss: 26.9529 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 866us/step - loss: 26.4531 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 26.3017 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 26.3977 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 858us/step - loss: 26.1099 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 26.1225 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 994us/step - loss: 25.3675 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 26.2216 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 25.5329 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 24.9698 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 25.2962 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 713us/step - loss: 24.7883 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 745us/step - loss: 25.4960 - accuracy: 0.0000e+00 0s - loss: 24.8839 - accuracy: 0.0000e\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 24.1614 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 24.6254 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 23.8031 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 763us/step - loss: 24.7397 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 894us/step - loss: 23.2709 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 24.2051 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 741us/step - loss: 24.3321 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 24.3549 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 720us/step - loss: 24.8198 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 734us/step - loss: 24.8420 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 768us/step - loss: 24.6074 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 855us/step - loss: 24.1556 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 706us/step - loss: 24.7908 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 746us/step - loss: 22.6716 - accuracy: 0.0000e+00 0s - loss: 22.2359 - accuracy: 0.0000e\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 776us/step - loss: 23.4526 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 758us/step - loss: 23.7163 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 737us/step - loss: 25.3655 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 745us/step - loss: 24.2077 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 745us/step - loss: 22.6450 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 764us/step - loss: 22.8740 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 705us/step - loss: 23.5120 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 781us/step - loss: 24.9437 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 22.7047 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 902us/step - loss: 24.9186 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 845us/step - loss: 23.6667 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 985us/step - loss: 23.9514 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 810us/step - loss: 24.8672 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 752us/step - loss: 23.4082 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 755us/step - loss: 23.6506 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 709us/step - loss: 24.6793 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 728us/step - loss: 25.0019 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 714us/step - loss: 23.4701 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 725us/step - loss: 22.8708 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 24.8856 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 25.0528 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 24.2231 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 23.0435 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 23.8122 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 760us/step - loss: 22.6864 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 719us/step - loss: 23.0003 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 750us/step - loss: 24.9182 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 777us/step - loss: 24.2882 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 23.7592 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 719us/step - loss: 22.5721 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 708us/step - loss: 23.3683 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 894us/step - loss: 22.9043 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 822us/step - loss: 22.1216 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 718us/step - loss: 23.9721 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 24.2564 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 853us/step - loss: 24.3224 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 718us/step - loss: 23.1876 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 709us/step - loss: 23.5226 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 716us/step - loss: 22.2989 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 947us/step - loss: 23.4162 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 750us/step - loss: 23.1717 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 749us/step - loss: 24.5572 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 745us/step - loss: 23.9062 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 733us/step - loss: 23.4179 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 707us/step - loss: 24.8838 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 733us/step - loss: 23.5248 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 882us/step - loss: 23.5262 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 23.0420 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 24.0462 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 23.6913 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 23.1482 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 744us/step - loss: 22.2520 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 849us/step - loss: 22.4574 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 765us/step - loss: 22.7152 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 23.4190 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 706us/step - loss: 23.9093 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 747us/step - loss: 23.7889 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 702us/step - loss: 23.8892 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21ad17159b0>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.3973]\n",
      " [21.9464]\n",
      " [22.1352]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2000 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2000 = pd.DataFrame()\n",
    "data_2000 = FUNCTION_1(data = data3, dataframe_new = data_2000, time = \"20:00:00\")\n",
    "data_2000_train = FUNCTION_2(data_2000, time=\"20:00:00\")[0]\n",
    "data_2000_test = FUNCTION_2(data_2000, time=\"20:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_2000_train[data_2000_train.columns[2:]].values\n",
    "X_test = data_2000_test[data_2000_test.columns[2:]].values\n",
    "\n",
    "y_train = data_2000_train[\"Value\"].values\n",
    "y_test = data_2000_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 1.2921e-04\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 859us/step - loss: 8.9543e-05\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 907us/step - loss: 7.7436e-05\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 6.0823e-05\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 841us/step - loss: 5.6152e-05\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 863us/step - loss: 6.2639e-05\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 848us/step - loss: 6.0831e-05\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 5.5147e-05\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 917us/step - loss: 5.2494e-05\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 873us/step - loss: 5.4601e-05\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 5.5631e-05\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 851us/step - loss: 5.8116e-05\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 873us/step - loss: 5.4618e-05\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 859us/step - loss: 5.2065e-05\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 916us/step - loss: 5.3904e-05\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 5.7291e-05\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 5.6563e-05\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 911us/step - loss: 5.4744e-05\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 5.2430e-05\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 921us/step - loss: 5.2249e-05\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 5.4408e-05\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 5.3533e-05\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 903us/step - loss: 5.4737e-05\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 907us/step - loss: 5.4560e-05\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 909us/step - loss: 5.2856e-05\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 876us/step - loss: 5.2800e-05\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 874us/step - loss: 5.7546e-05\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 864us/step - loss: 5.2309e-05\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 5.4798e-05\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 884us/step - loss: 5.2438e-05\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 850us/step - loss: 5.7682e-05\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 5.2191e-05\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 5.2311e-05\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 5.2859e-05\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 815us/step - loss: 5.3076e-05\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 5.6238e-05\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 5.2774e-05\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 5.2533e-05\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 5.2014e-05\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 5.3218e-05\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 5.2538e-05\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 859us/step - loss: 5.3423e-05\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 5.2761e-05\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 5.5224e-05\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 5.3795e-05\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 5.1949e-05\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 859us/step - loss: 5.1622e-05\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 5.3175e-05\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 5.1951e-05\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 5.4559e-05\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 5.3040e-05\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 5.2456e-05\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 5.6711e-05\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 5.4890e-05\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 807us/step - loss: 5.3047e-05\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 5.7587e-05\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 947us/step - loss: 5.1860e-05\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 5.2237e-05\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 919us/step - loss: 5.2562e-05\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 944us/step - loss: 5.2533e-05\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 855us/step - loss: 5.2599e-05\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 807us/step - loss: 5.2770e-05\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 5.3525e-05\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 845us/step - loss: 5.5056e-05\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 5.2779e-05\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 909us/step - loss: 5.3328e-05\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 5.3266e-05\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 5.1374e-05\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 5.1546e-05\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 5.2690e-05\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 5.2562e-05\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 815us/step - loss: 5.2324e-05\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 777us/step - loss: 5.3138e-05\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 5.3976e-05\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 5.1382e-05\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 5.3543e-05\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 5.2088e-05\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 5.2686e-05\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 5.1857e-05\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 5.1846e-05\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 5.4326e-05\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 5.2569e-05\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 5.2537e-05\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 5.2026e-05\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 786us/step - loss: 5.1973e-05\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 849us/step - loss: 5.4223e-05\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 5.8228e-05\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 5.7556e-05\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 5.1786e-05\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 5.2307e-05\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 5.3376e-05\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 5.2066e-05 0s - loss: 5.0069e-0\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 838us/step - loss: 5.1722e-05\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 5.3792e-05\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 5.3013e-05\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 5.6533e-05\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 6.1542e-05\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 848us/step - loss: 5.2630e-05\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 5.2373e-05\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 5.0978e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21abc4678d0>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0002]\n",
      " [0.0002]\n",
      " [0.0187]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 0.0048\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 0.0044\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 0.0035\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 870us/step - loss: 0.0033\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 831us/step - loss: 0.0034\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 0.0036\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 0.0035\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 0.0032\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 0.0031\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 856us/step - loss: 0.0031\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 0.0031\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 0.0036\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 0.0032\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 859us/step - loss: 0.0030\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 0.0033\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 834us/step - loss: 0.0037\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 0.0033\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 0.0035\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 0.0030\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 0.0032\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 826us/step - loss: 0.0032\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 0.0031\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 0.0032\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 870us/step - loss: 0.0030\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 837us/step - loss: 0.0031\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 0.0030\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 0.0030\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 0.0033\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 0.0030\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 0.0028\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 0.0031\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 0.0030\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 884us/step - loss: 0.0031\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 882us/step - loss: 0.0031\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 852us/step - loss: 0.0030\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 0.0030\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 0.0032\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 0.0030\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 0.0029\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 0.0031\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 865us/step - loss: 0.0030\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 0.0030\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 0.0029\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 867us/step - loss: 0.0031\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 0.0030\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 0.0030\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 0.0033\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 0.0030\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 0.0030\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 0.0029\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 874us/step - loss: 0.0030\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 0.0028\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 0.0028\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 0.0029 0s - loss: 0.00\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 0.0029\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 0.0030\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - ETA: 0s - loss: 0.002 - 0s 775us/step - loss: 0.0029\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 0.0034\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 0.0032\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 0.0030\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 0.0028\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 0.0031\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 0.0031\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 785us/step - loss: 0.0028\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 0.0031\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 915us/step - loss: 0.0030\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 0.0029\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 0.0031\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 771us/step - loss: 0.0031\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 0.0029\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 772us/step - loss: 0.0031\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 784us/step - loss: 0.0029\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 0.0030\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 0.0029\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 0.0029\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 0.0031\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 807us/step - loss: 0.0031\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 0.0033\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 785us/step - loss: 0.0030\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 0.0030\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 800us/step - loss: 0.0029\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 0.0028\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 0.0031\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 0.0030\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 774us/step - loss: 0.0030\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 0.0029\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 0.0032\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 0.0028\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 775us/step - loss: 0.0028\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 0.0029\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 785us/step - loss: 0.0028\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 0.0031\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 0.0031\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 0.0032\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 0.0031\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 0.0032\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 797us/step - loss: 0.0032\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 0.0030\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 807us/step - loss: 0.0030\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 0.0030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21abff4c438>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0006]\n",
      " [0.0006]\n",
      " [0.0195]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2100 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2100 = pd.DataFrame()\n",
    "data_2100 = FUNCTION_1(data = data3, dataframe_new = data_2100, time = \"21:00:00\")\n",
    "data_2100_train = FUNCTION_2(data_2100, time=\"21:00:00\")[0]\n",
    "data_2100_test = FUNCTION_2(data_2100, time=\"21:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_2100_train[data_2100_train.columns[2:]].values\n",
    "X_test = data_2100_test[data_2100_test.columns[2:]].values\n",
    "\n",
    "y_train = data_2100_train[\"Value\"].values\n",
    "y_test = data_2100_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 853us/step - loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 851us/step - loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 832us/step - loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 815us/step - loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 831us/step - loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 867us/step - loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - ETA: 0s - loss: 0.0000e+0 - 0s 818us/step - loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 887us/step - loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 849us/step - loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 846us/step - loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 807us/step - loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 832us/step - loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 774us/step - loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 784us/step - loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 751us/step - loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 832us/step - loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 775us/step - loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 772us/step - loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - ETA: 0s - loss: 0.0000e+00- ETA: 0s - loss: 0.0000e+ - 0s 769us/step - loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 774us/step - loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 776us/step - loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 776us/step - loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 785us/step - loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 831us/step - loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 769us/step - loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 907us/step - loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 910us/step - loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 0.0000e+00\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 955us/step - loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 893us/step - loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 907us/step - loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 846us/step - loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 981us/step - loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 775us/step - loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21ac1825d68>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 900us/step - loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 852us/step - loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 860us/step - loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 878us/step - loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 907us/step - loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 893us/step - loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 832us/step - loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 815us/step - loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 843us/step - loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 810us/step - loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 874us/step - loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 852us/step - loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 832us/step - loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 841us/step - loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 880us/step - loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 810us/step - loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 782us/step - loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 857us/step - loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 957us/step - loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 850us/step - loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 979us/step - loss: 0.0000e+00 0s - loss: 0.0000e+\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 862us/step - loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 873us/step - loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 871us/step - loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 865us/step - loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 867us/step - loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 907us/step - loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 855us/step - loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 856us/step - loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 910us/step - loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 782us/step - loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 875us/step - loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 907us/step - loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 864us/step - loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 855us/step - loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 978us/step - loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 929us/step - loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 955us/step - loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 933us/step - loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 890us/step - loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 877us/step - loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 786us/step - loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 777us/step - loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 826us/step - loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 760us/step - loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 0.0000e+00\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 774us/step - loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 760us/step - loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 841us/step - loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 846us/step - loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21ac3120940>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2200 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2200 = pd.DataFrame()\n",
    "data_2200 = FUNCTION_1(data = data3, dataframe_new = data_2200, time = \"22:00:00\")\n",
    "data_2200_train = FUNCTION_2(data_2200, time=\"22:00:00\")[0]\n",
    "data_2200_test = FUNCTION_2(data_2200, time=\"22:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(334, 7)\n",
      "(3, 7)\n",
      "(334,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_2200_train[data_2200_train.columns[2:]].values\n",
    "X_test = data_2200_test[data_2200_test.columns[2:]].values\n",
    "\n",
    "y_train = data_2200_train[\"Value\"].values\n",
    "y_test = data_2200_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(334, 7, 1)\n",
      "(3, 7, 1)\n",
      "(334,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 0s 910us/step - loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 0s 862us/step - loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 0s 972us/step - loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 0s 911us/step - loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 0s 957us/step - loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 0s 867us/step - loss: 0.0000e+00 0s - loss: 0.0000e\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 0s 821us/step - loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 0s 838us/step - loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 0s 818us/step - loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 0s 828us/step - loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 0s 877us/step - loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 0s 828us/step - loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 0s 792us/step - loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 0s 836us/step - loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 0s 788us/step - loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 0s 825us/step - loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 0s 847us/step - loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 0s 832us/step - loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 0s 790us/step - loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 0s 837us/step - loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 0s 827us/step - loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 0s 829us/step - loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 0s 828us/step - loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 0s 809us/step - loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 0s 824us/step - loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 0s 805us/step - loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 0s 776us/step - loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 0s 736us/step - loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 0s 913us/step - loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 0s 867us/step - loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 0s 850us/step - loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 0s 827us/step - loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 0s 845us/step - loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 0s 823us/step - loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 0s 809us/step - loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 0s 957us/step - loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 0s 900us/step - loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 0s 899us/step - loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 0s 934us/step - loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 0s 847us/step - loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 0s 831us/step - loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - 0s 824us/step - loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 0s 842us/step - loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 0s 824us/step - loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 0s 831us/step - loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 0s 821us/step - loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 0s 814us/step - loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 0s 828us/step - loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 0s 817us/step - loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 0s 825us/step - loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 0s 821us/step - loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 0s 833us/step - loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 0s 823us/step - loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 0s 815us/step - loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 0s 779us/step - loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 0s 796us/step - loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 0s 807us/step - loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 0s 797us/step - loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - 0s 826us/step - loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - 0s 831us/step - loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 0s 828us/step - loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 0s 818us/step - loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 0s 822us/step - loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 0s 825us/step - loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 0s 840us/step - loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 0s 840us/step - loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 0s 761us/step - loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 0s 831us/step - loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 0s 795us/step - loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "334/334 [==============================] - 0s 803us/step - loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 0s 863us/step - loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "334/334 [==============================] - 0s 799us/step - loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "334/334 [==============================] - 0s 798us/step - loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "334/334 [==============================] - 0s 819us/step - loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "334/334 [==============================] - 0s 802us/step - loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "334/334 [==============================] - 0s 822us/step - loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "334/334 [==============================] - 0s 834us/step - loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "334/334 [==============================] - 0s 882us/step - loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "334/334 [==============================] - 0s 913us/step - loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "334/334 [==============================] - 0s 917us/step - loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "334/334 [==============================] - 0s 927us/step - loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "334/334 [==============================] - 0s 980us/step - loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "334/334 [==============================] - 0s 955us/step - loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "334/334 [==============================] - 0s 938us/step - loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "334/334 [==============================] - 0s 943us/step - loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "334/334 [==============================] - 0s 985us/step - loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "334/334 [==============================] - 0s 966us/step - loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "334/334 [==============================] - 0s 927us/step - loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "334/334 [==============================] - 0s 916us/step - loss: 0.0000e+00\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334/334 [==============================] - 0s 954us/step - loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "334/334 [==============================] - 0s 941us/step - loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "334/334 [==============================] - 0s 861us/step - loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "334/334 [==============================] - 0s 808us/step - loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "334/334 [==============================] - 0s 799us/step - loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "334/334 [==============================] - 0s 814us/step - loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "334/334 [==============================] - 0s 833us/step - loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "334/334 [==============================] - 0s 815us/step - loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21abf676208>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 0s 826us/step - loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 0s 802us/step - loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 0s 840us/step - loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 0s 825us/step - loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 0s 795us/step - loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 0s 855us/step - loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 0s 842us/step - loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 0s 808us/step - loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 0s 827us/step - loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 0s 816us/step - loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 0s 826us/step - loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 0s 835us/step - loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 0s 839us/step - loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 0s 817us/step - loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 0s 828us/step - loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 0s 827us/step - loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 0s 806us/step - loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 0s 815us/step - loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 0s 795us/step - loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 0s 818us/step - loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 0s 798us/step - loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 0s 838us/step - loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 0s 816us/step - loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 0s 816us/step - loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 0s 788us/step - loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 0s 797us/step - loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 0s 814us/step - loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 0s 829us/step - loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 0s 827us/step - loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 0s 822us/step - loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 0s 803us/step - loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 0s 832us/step - loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 0s 816us/step - loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 0s 968us/step - loss: 0.0000e+00 0s - loss: 0.0000e+\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 0s 852us/step - loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 0s 817us/step - loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 0s 828us/step - loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 0s 811us/step - loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 0s 844us/step - loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 0s 801us/step - loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 0s 831us/step - loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - 0s 808us/step - loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 0s 842us/step - loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 0s 830us/step - loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 0s 841us/step - loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 0s 830us/step - loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 0s 808us/step - loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 0s 837us/step - loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 0s 838us/step - loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 0s 835us/step - loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 0s 827us/step - loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 0s 835us/step - loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 0s 782us/step - loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 0s 821us/step - loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 0s 824us/step - loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 0s 783us/step - loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 0s 810us/step - loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 0s 788us/step - loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - 0s 773us/step - loss: 0.0000e+00 0s - loss: 0.0000e+0\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0000e+0 - 0s 814us/step - loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 0s 785us/step - loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 0s 798us/step - loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 0s 817us/step - loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 0s 837us/step - loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 0s 792us/step - loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 0s 793us/step - loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 0s 865us/step - loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 0s 812us/step - loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 0s 830us/step - loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "334/334 [==============================] - 0s 886us/step - loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "334/334 [==============================] - 0s 957us/step - loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "334/334 [==============================] - 0s 957us/step - loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "334/334 [==============================] - 0s 823us/step - loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "334/334 [==============================] - 0s 959us/step - loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "334/334 [==============================] - 0s 934us/step - loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "334/334 [==============================] - 0s 934us/step - loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "334/334 [==============================] - 0s 977us/step - loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "334/334 [==============================] - 0s 845us/step - loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "334/334 [==============================] - 0s 755us/step - loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "334/334 [==============================] - 0s 811us/step - loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "334/334 [==============================] - 0s 817us/step - loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "334/334 [==============================] - 0s 844us/step - loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "334/334 [==============================] - 0s 848us/step - loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "334/334 [==============================] - 0s 838us/step - loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "334/334 [==============================] - 0s 822us/step - loss: 0.0000e+00\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334/334 [==============================] - 0s 812us/step - loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "334/334 [==============================] - 0s 793us/step - loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "334/334 [==============================] - 0s 746us/step - loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "334/334 [==============================] - 0s 803us/step - loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "334/334 [==============================] - 0s 798us/step - loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "334/334 [==============================] - 0s 779us/step - loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "334/334 [==============================] - 0s 798us/step - loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "334/334 [==============================] - 0s 823us/step - loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "334/334 [==============================] - 0s 819us/step - loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21ac56a80b8>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2300 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2300 = pd.DataFrame()\n",
    "data_2300 = FUNCTION_1(data = data3, dataframe_new = data_2300, time = \"23:00:00\")\n",
    "data_2300_train = FUNCTION_2(data_2300, time=\"23:00:00\")[0]\n",
    "data_2300_test = FUNCTION_2(data_2300, time=\"23:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(334, 7)\n",
      "(3, 7)\n",
      "(334,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_2300_train[data_2300_train.columns[2:]].values\n",
    "X_test = data_2300_test[data_2300_test.columns[2:]].values\n",
    "\n",
    "y_train = data_2300_train[\"Value\"].values\n",
    "y_test = data_2300_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(334, 7, 1)\n",
      "(3, 7, 1)\n",
      "(334,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 0s 843us/step - loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 0s 817us/step - loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 0s 774us/step - loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 0s 825us/step - loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 0s 854us/step - loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 0s 804us/step - loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 0s 821us/step - loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 0s 828us/step - loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 0s 818us/step - loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 0s 839us/step - loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 0s 812us/step - loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 0s 801us/step - loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 0s 814us/step - loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 0s 825us/step - loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 0s 820us/step - loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 0s 838us/step - loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 0s 783us/step - loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 0s 818us/step - loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 0s 808us/step - loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 0s 826us/step - loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 0s 860us/step - loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 0s 829us/step - loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 0s 827us/step - loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 0s 828us/step - loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 0s 821us/step - loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 0s 820us/step - loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 0s 818us/step - loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 0s 860us/step - loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 0s 840us/step - loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 0s 838us/step - loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 0s 816us/step - loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 0s 831us/step - loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 0s 805us/step - loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 0s 825us/step - loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 0s 797us/step - loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 0s 826us/step - loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 0s 823us/step - loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 0s 838us/step - loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 0s 825us/step - loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 0s 795us/step - loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 0s 823us/step - loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - 0s 827us/step - loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 0s 878us/step - loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 0s 807us/step - loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 0s 834us/step - loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 0s 833us/step - loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 0s 834us/step - loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 0s 839us/step - loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 0s 815us/step - loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 0s 820us/step - loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 0s 827us/step - loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 0s 876us/step - loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 0s 793us/step - loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 0s 807us/step - loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 0s 781us/step - loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 0s 816us/step - loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 0s 793us/step - loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 0s 807us/step - loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - 0s 781us/step - loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - 0s 772us/step - loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 0s 803us/step - loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 0s 803us/step - loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 0s 805us/step - loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 0s 825us/step - loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 0s 797us/step - loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 0s 793us/step - loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 0s 806us/step - loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 0s 822us/step - loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 0s 800us/step - loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "334/334 [==============================] - 0s 839us/step - loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 0s 827us/step - loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "334/334 [==============================] - 0s 828us/step - loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "334/334 [==============================] - 0s 816us/step - loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "334/334 [==============================] - 0s 792us/step - loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "334/334 [==============================] - 0s 812us/step - loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "334/334 [==============================] - 0s 807us/step - loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "334/334 [==============================] - 0s 818us/step - loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "334/334 [==============================] - 0s 836us/step - loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "334/334 [==============================] - 0s 827us/step - loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "334/334 [==============================] - 0s 807us/step - loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "334/334 [==============================] - 0s 833us/step - loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "334/334 [==============================] - 0s 766us/step - loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "334/334 [==============================] - 0s 778us/step - loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "334/334 [==============================] - 0s 815us/step - loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "334/334 [==============================] - 0s 875us/step - loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "334/334 [==============================] - 0s 830us/step - loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "334/334 [==============================] - 0s 839us/step - loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "334/334 [==============================] - 0s 821us/step - loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "334/334 [==============================] - 0s 834us/step - loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "334/334 [==============================] - 0s 830us/step - loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "334/334 [==============================] - 0s 840us/step - loss: 0.0000e+00\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334/334 [==============================] - 0s 787us/step - loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "334/334 [==============================] - 0s 918us/step - loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "334/334 [==============================] - 0s 833us/step - loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "334/334 [==============================] - 0s 910us/step - loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21ac87ded30>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 0s 840us/step - loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 0s 821us/step - loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 0s 832us/step - loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 0s 877us/step - loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 0s 934us/step - loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 0s 812us/step - loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 0s 833us/step - loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 0s 955us/step - loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 0s 816us/step - loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 0s 805us/step - loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 0s 839us/step - loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 0s 873us/step - loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 0s 832us/step - loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 0s 784us/step - loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 0s 855us/step - loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 0s 854us/step - loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 0s 852us/step - loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 0s 821us/step - loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 0s 957us/step - loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 0s 973us/step - loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 0s 842us/step - loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 0s 981us/step - loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 0s 862us/step - loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 0s 859us/step - loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 0s 820us/step - loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 0s 845us/step - loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 0s 813us/step - loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 0s 806us/step - loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 0s 825us/step - loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 0s 814us/step - loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 0s 842us/step - loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 0s 955us/step - loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 0s 886us/step - loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 0s 964us/step - loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 0s 896us/step - loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 0s 933us/step - loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 0s 981us/step - loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 0s 888us/step - loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 0s 934us/step - loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 0s 938us/step - loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 0s 927us/step - loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 0s 869us/step - loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - 0s 984us/step - loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - 0s 981us/step - loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 0s 958us/step - loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 0s 904us/step - loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 0s 790us/step - loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 0s 985us/step - loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 0s 804us/step - loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 0s 925us/step - loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 0s 934us/step - loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 0s 907us/step - loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "334/334 [==============================] - 0s 981us/step - loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 0s 862us/step - loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "334/334 [==============================] - 0s 830us/step - loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "334/334 [==============================] - 0s 869us/step - loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "334/334 [==============================] - 0s 889us/step - loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "334/334 [==============================] - 0s 892us/step - loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "334/334 [==============================] - 0s 838us/step - loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "334/334 [==============================] - 0s 860us/step - loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "334/334 [==============================] - 0s 957us/step - loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "334/334 [==============================] - 0s 909us/step - loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "334/334 [==============================] - 0s 886us/step - loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "334/334 [==============================] - 0s 814us/step - loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "334/334 [==============================] - 0s 999us/step - loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "334/334 [==============================] - 0s 862us/step - loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "334/334 [==============================] - 0s 823us/step - loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "334/334 [==============================] - 0s 862us/step - loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "334/334 [==============================] - 0s 862us/step - loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "334/334 [==============================] - 0s 778us/step - loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "334/334 [==============================] - 0s 831us/step - loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "334/334 [==============================] - 0s 845us/step - loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "334/334 [==============================] - 0s 860us/step - loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "334/334 [==============================] - 0s 836us/step - loss: 0.0000e+00\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334/334 [==============================] - 0s 869us/step - loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "334/334 [==============================] - 0s 848us/step - loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "334/334 [==============================] - 0s 889us/step - loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "334/334 [==============================] - 0s 845us/step - loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "334/334 [==============================] - 0s 837us/step - loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "334/334 [==============================] - 0s 891us/step - loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "334/334 [==============================] - 0s 837us/step - loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "334/334 [==============================] - 0s 829us/step - loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21ac88764e0>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
