{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 태양광 발전량 예측 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 충북 진천군의 2019년 7월 1일부터 2020년 6월 30일의 1년치 태양광 발전량 데이터\n",
    "\n",
    "\n",
    "- 2020년 1월 31일, 2020년 3월 31일, 2020년 5월 31일을 예측\n",
    "\n",
    "\n",
    "- 하루동안의 데이터는 96개의 데이터가 생성\n",
    "\n",
    "\n",
    "- 데이터는 15분 당 한개씩 생성\n",
    "\n",
    "\n",
    "- 데이터 구조\n",
    "    - 00:00:00 ~ 05:00:00 이 기간은 value=0 (20개) \n",
    "    - 05:15:00 ~ 20:00:00 이 기간은 value=? (63개)\n",
    "    - 21:00:00 ~ 23:00:00 이 기간은 value=0 (13개)\n",
    "    \n",
    "- 총 63개의 각 시간을 맞추는 데이터를 분리하고 모델 생성\n",
    "\n",
    "-> 15분 단위를 1시간 단위로 변경\n",
    "- 데이터 구조    \n",
    "    - 00:00:00 ~ 04:00:00 이 기간의 value = 0(5개)\n",
    "    - 05:00:00 ~ 21:00:00 이 기간의 value = ?(17개)\n",
    "    - 22:00:00 ~ 23:00:00 이 기간의 value = 0(2개)\n",
    "    \n",
    "    17개의 각 시간을 맞추는 데이터를 분리하고 모델 생성 모델 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 총 용량 133kw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 라이브러리 및 환경 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names1 = ['Date', 'Temp','Prec','Wind_S','Wind_D','Humidity','Pressure','Sunshine','Insolation','Snow','Cloud','Municipal','Ground temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/SolarPV_Elec_Problem.csv\", header=None, names=[\"Date\", \"Value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-01T00:00:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-01T00:15:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-01T00:30:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-01T00:45:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-01T01:00:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date  Value\n",
       "0  2019-07-01T00:00:00+09:00    0.0\n",
       "1  2019-07-01T00:15:00+09:00    0.0\n",
       "2  2019-07-01T00:30:00+09:00    0.0\n",
       "3  2019-07-01T00:45:00+09:00    0.0\n",
       "4  2019-07-01T01:00:00+09:00    0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OH59fBgbRLvm"
   },
   "outputs": [],
   "source": [
    "def utc_change (string) : \n",
    "    year = string[:4]\n",
    "    month = string[5:7]\n",
    "    day = string[8:10]\n",
    "    hour = string[11:13]\n",
    "    if hour in \":\" :\n",
    "        hour == int(string[11:12])\n",
    "    else : \n",
    "        hour == int(string[11:13])\n",
    "    minute = string[14:16]\n",
    "    second = string[17:19]\n",
    "    \n",
    "    date = year + \"-\" + month + \"-\" + day + \" \" + str(hour)\n",
    "\n",
    "    return date\n",
    "utc_change(data.loc[0][\"Date\"])\n",
    "data['Date'] = data['Date'].apply(lambda x :utc_change(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K_A0xtHEzaJh"
   },
   "outputs": [],
   "source": [
    "data['Date'] = pd.to_datetime(data['Date'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GhoR_EO77Qki"
   },
   "source": [
    "### 1시간 단위로 변환 후 데이터 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "odKDJ8ST8CIU"
   },
   "outputs": [],
   "source": [
    "data2=data.resample('H', on='Date').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U0O23kRRpoh-"
   },
   "outputs": [],
   "source": [
    "data2[\"Value\"] = data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Value = pd.DataFrame(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value    8782\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Value.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-06-30 17:00:00</th>\n",
       "      <td>7.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-30 18:00:00</th>\n",
       "      <td>3.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-30 19:00:00</th>\n",
       "      <td>0.467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-30 20:00:00</th>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-30 21:00:00</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Value\n",
       "Date                      \n",
       "2020-06-30 17:00:00  7.880\n",
       "2020-06-30 18:00:00  3.408\n",
       "2020-06-30 19:00:00  0.467\n",
       "2020-06-30 20:00:00  0.020\n",
       "2020-06-30 21:00:00  0.000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Value.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2019-07-01 00:00:00+09:00', '2019-07-01 01:00:00+09:00',\n",
       "               '2019-07-01 02:00:00+09:00', '2019-07-01 03:00:00+09:00',\n",
       "               '2019-07-01 04:00:00+09:00', '2019-07-01 05:00:00+09:00',\n",
       "               '2019-07-01 06:00:00+09:00', '2019-07-01 07:00:00+09:00',\n",
       "               '2019-07-01 08:00:00+09:00', '2019-07-01 09:00:00+09:00',\n",
       "               ...\n",
       "               '2020-06-30 12:00:00+09:00', '2020-06-30 13:00:00+09:00',\n",
       "               '2020-06-30 14:00:00+09:00', '2020-06-30 15:00:00+09:00',\n",
       "               '2020-06-30 16:00:00+09:00', '2020-06-30 17:00:00+09:00',\n",
       "               '2020-06-30 18:00:00+09:00', '2020-06-30 19:00:00+09:00',\n",
       "               '2020-06-30 20:00:00+09:00', '2020-06-30 21:00:00+09:00'],\n",
       "              dtype='datetime64[ns, Asia/Seoul]', length=8782, freq='H')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_date= pd.date_range(start = \"2019-07-01 00:00:00\", end = \"2020-06-30 21:00:00\", freq = \"H\",tz = 'Asia/Seoul')\n",
    "new_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_date= pd.date_range(start = \"2019-07-01 00:00:00\", end = \"2020-06-30 21:00:00\", freq = \"H\", tz = 'Asia/Seoul')\n",
    "\n",
    "data3 = pd.DataFrame({\"Date\" : new_date, \"Value\" : data2[\"Value\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-07-01 00:00:00</th>\n",
       "      <td>2019-07-01 00:00:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-01 01:00:00</th>\n",
       "      <td>2019-07-01 01:00:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-01 02:00:00</th>\n",
       "      <td>2019-07-01 02:00:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-01 03:00:00</th>\n",
       "      <td>2019-07-01 03:00:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-01 04:00:00</th>\n",
       "      <td>2019-07-01 04:00:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Date  Value\n",
       "Date                                                \n",
       "2019-07-01 00:00:00 2019-07-01 00:00:00+09:00    0.0\n",
       "2019-07-01 01:00:00 2019-07-01 01:00:00+09:00    0.0\n",
       "2019-07-01 02:00:00 2019-07-01 02:00:00+09:00    0.0\n",
       "2019-07-01 03:00:00 2019-07-01 03:00:00+09:00    0.0\n",
       "2019-07-01 04:00:00 2019-07-01 04:00:00+09:00    0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3['2020-01-31']['Value'] = np.nan\n",
    "data3['2020-03-31']['Value'] = np.nan\n",
    "data3['2020-05-31']['Value'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data3.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8032</th>\n",
       "      <td>2020-05-30 16:00:00+09:00</td>\n",
       "      <td>46.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8033</th>\n",
       "      <td>2020-05-30 17:00:00+09:00</td>\n",
       "      <td>28.297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8034</th>\n",
       "      <td>2020-05-30 18:00:00+09:00</td>\n",
       "      <td>11.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8035</th>\n",
       "      <td>2020-05-30 19:00:00+09:00</td>\n",
       "      <td>2.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8036</th>\n",
       "      <td>2020-05-30 20:00:00+09:00</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8037</th>\n",
       "      <td>2020-05-30 21:00:00+09:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8038</th>\n",
       "      <td>2020-05-30 22:00:00+09:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8039</th>\n",
       "      <td>2020-05-30 23:00:00+09:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8040</th>\n",
       "      <td>2020-05-31 00:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8041</th>\n",
       "      <td>2020-05-31 01:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8042</th>\n",
       "      <td>2020-05-31 02:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8043</th>\n",
       "      <td>2020-05-31 03:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8044</th>\n",
       "      <td>2020-05-31 04:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8045</th>\n",
       "      <td>2020-05-31 05:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8046</th>\n",
       "      <td>2020-05-31 06:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8047</th>\n",
       "      <td>2020-05-31 07:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8048</th>\n",
       "      <td>2020-05-31 08:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8049</th>\n",
       "      <td>2020-05-31 09:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8050</th>\n",
       "      <td>2020-05-31 10:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8051</th>\n",
       "      <td>2020-05-31 11:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8052</th>\n",
       "      <td>2020-05-31 12:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8053</th>\n",
       "      <td>2020-05-31 13:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8054</th>\n",
       "      <td>2020-05-31 14:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8055</th>\n",
       "      <td>2020-05-31 15:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8056</th>\n",
       "      <td>2020-05-31 16:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8057</th>\n",
       "      <td>2020-05-31 17:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8058</th>\n",
       "      <td>2020-05-31 18:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8059</th>\n",
       "      <td>2020-05-31 19:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8060</th>\n",
       "      <td>2020-05-31 20:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8061</th>\n",
       "      <td>2020-05-31 21:00:00+09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8752</th>\n",
       "      <td>2020-06-29 16:00:00+09:00</td>\n",
       "      <td>11.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8753</th>\n",
       "      <td>2020-06-29 17:00:00+09:00</td>\n",
       "      <td>4.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8754</th>\n",
       "      <td>2020-06-29 18:00:00+09:00</td>\n",
       "      <td>1.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8755</th>\n",
       "      <td>2020-06-29 19:00:00+09:00</td>\n",
       "      <td>0.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8756</th>\n",
       "      <td>2020-06-29 20:00:00+09:00</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>2020-06-29 21:00:00+09:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>2020-06-29 22:00:00+09:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>2020-06-29 23:00:00+09:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8760</th>\n",
       "      <td>2020-06-30 00:00:00+09:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8761</th>\n",
       "      <td>2020-06-30 01:00:00+09:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8762</th>\n",
       "      <td>2020-06-30 02:00:00+09:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8763</th>\n",
       "      <td>2020-06-30 03:00:00+09:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8764</th>\n",
       "      <td>2020-06-30 04:00:00+09:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8765</th>\n",
       "      <td>2020-06-30 05:00:00+09:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8766</th>\n",
       "      <td>2020-06-30 06:00:00+09:00</td>\n",
       "      <td>0.614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8767</th>\n",
       "      <td>2020-06-30 07:00:00+09:00</td>\n",
       "      <td>3.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8768</th>\n",
       "      <td>2020-06-30 08:00:00+09:00</td>\n",
       "      <td>7.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8769</th>\n",
       "      <td>2020-06-30 09:00:00+09:00</td>\n",
       "      <td>16.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8770</th>\n",
       "      <td>2020-06-30 10:00:00+09:00</td>\n",
       "      <td>19.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8771</th>\n",
       "      <td>2020-06-30 11:00:00+09:00</td>\n",
       "      <td>19.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8772</th>\n",
       "      <td>2020-06-30 12:00:00+09:00</td>\n",
       "      <td>25.391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8773</th>\n",
       "      <td>2020-06-30 13:00:00+09:00</td>\n",
       "      <td>19.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8774</th>\n",
       "      <td>2020-06-30 14:00:00+09:00</td>\n",
       "      <td>10.835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8775</th>\n",
       "      <td>2020-06-30 15:00:00+09:00</td>\n",
       "      <td>15.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8776</th>\n",
       "      <td>2020-06-30 16:00:00+09:00</td>\n",
       "      <td>11.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8777</th>\n",
       "      <td>2020-06-30 17:00:00+09:00</td>\n",
       "      <td>7.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8778</th>\n",
       "      <td>2020-06-30 18:00:00+09:00</td>\n",
       "      <td>3.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8779</th>\n",
       "      <td>2020-06-30 19:00:00+09:00</td>\n",
       "      <td>0.467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780</th>\n",
       "      <td>2020-06-30 20:00:00+09:00</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8781</th>\n",
       "      <td>2020-06-30 21:00:00+09:00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Date   Value\n",
       "8032 2020-05-30 16:00:00+09:00  46.671\n",
       "8033 2020-05-30 17:00:00+09:00  28.297\n",
       "8034 2020-05-30 18:00:00+09:00  11.976\n",
       "8035 2020-05-30 19:00:00+09:00   2.583\n",
       "8036 2020-05-30 20:00:00+09:00   0.028\n",
       "8037 2020-05-30 21:00:00+09:00   0.000\n",
       "8038 2020-05-30 22:00:00+09:00   0.000\n",
       "8039 2020-05-30 23:00:00+09:00   0.000\n",
       "8040 2020-05-31 00:00:00+09:00     NaN\n",
       "8041 2020-05-31 01:00:00+09:00     NaN\n",
       "8042 2020-05-31 02:00:00+09:00     NaN\n",
       "8043 2020-05-31 03:00:00+09:00     NaN\n",
       "8044 2020-05-31 04:00:00+09:00     NaN\n",
       "8045 2020-05-31 05:00:00+09:00     NaN\n",
       "8046 2020-05-31 06:00:00+09:00     NaN\n",
       "8047 2020-05-31 07:00:00+09:00     NaN\n",
       "8048 2020-05-31 08:00:00+09:00     NaN\n",
       "8049 2020-05-31 09:00:00+09:00     NaN\n",
       "8050 2020-05-31 10:00:00+09:00     NaN\n",
       "8051 2020-05-31 11:00:00+09:00     NaN\n",
       "8052 2020-05-31 12:00:00+09:00     NaN\n",
       "8053 2020-05-31 13:00:00+09:00     NaN\n",
       "8054 2020-05-31 14:00:00+09:00     NaN\n",
       "8055 2020-05-31 15:00:00+09:00     NaN\n",
       "8056 2020-05-31 16:00:00+09:00     NaN\n",
       "8057 2020-05-31 17:00:00+09:00     NaN\n",
       "8058 2020-05-31 18:00:00+09:00     NaN\n",
       "8059 2020-05-31 19:00:00+09:00     NaN\n",
       "8060 2020-05-31 20:00:00+09:00     NaN\n",
       "8061 2020-05-31 21:00:00+09:00     NaN\n",
       "...                        ...     ...\n",
       "8752 2020-06-29 16:00:00+09:00  11.988\n",
       "8753 2020-06-29 17:00:00+09:00   4.120\n",
       "8754 2020-06-29 18:00:00+09:00   1.022\n",
       "8755 2020-06-29 19:00:00+09:00   0.112\n",
       "8756 2020-06-29 20:00:00+09:00   0.001\n",
       "8757 2020-06-29 21:00:00+09:00   0.000\n",
       "8758 2020-06-29 22:00:00+09:00   0.000\n",
       "8759 2020-06-29 23:00:00+09:00   0.000\n",
       "8760 2020-06-30 00:00:00+09:00   0.000\n",
       "8761 2020-06-30 01:00:00+09:00   0.000\n",
       "8762 2020-06-30 02:00:00+09:00   0.000\n",
       "8763 2020-06-30 03:00:00+09:00   0.000\n",
       "8764 2020-06-30 04:00:00+09:00   0.000\n",
       "8765 2020-06-30 05:00:00+09:00   0.000\n",
       "8766 2020-06-30 06:00:00+09:00   0.614\n",
       "8767 2020-06-30 07:00:00+09:00   3.832\n",
       "8768 2020-06-30 08:00:00+09:00   7.549\n",
       "8769 2020-06-30 09:00:00+09:00  16.100\n",
       "8770 2020-06-30 10:00:00+09:00  19.989\n",
       "8771 2020-06-30 11:00:00+09:00  19.745\n",
       "8772 2020-06-30 12:00:00+09:00  25.391\n",
       "8773 2020-06-30 13:00:00+09:00  19.521\n",
       "8774 2020-06-30 14:00:00+09:00  10.835\n",
       "8775 2020-06-30 15:00:00+09:00  15.043\n",
       "8776 2020-06-30 16:00:00+09:00  11.863\n",
       "8777 2020-06-30 17:00:00+09:00   7.880\n",
       "8778 2020-06-30 18:00:00+09:00   3.408\n",
       "8779 2020-06-30 19:00:00+09:00   0.467\n",
       "8780 2020-06-30 20:00:00+09:00   0.020\n",
       "8781 2020-06-30 21:00:00+09:00   0.000\n",
       "\n",
       "[750 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.tail(750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = data3.groupby(data3['Date']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8782.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.991801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.090179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Value\n",
       "count  8782.000000\n",
       "mean      0.991801\n",
       "std       0.090179\n",
       "min       0.000000\n",
       "25%       1.000000\n",
       "50%       1.000000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data4.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8782 entries, 0 to 8781\n",
      "Data columns (total 2 columns):\n",
      "Date     8782 non-null datetime64[ns, Asia/Seoul]\n",
      "Value    8710 non-null float64\n",
      "dtypes: datetime64[ns, Asia/Seoul](1), float64(1)\n",
      "memory usage: 137.3 KB\n"
     ]
    }
   ],
   "source": [
    "data3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3['Date']= data3['Date'].apply(lambda x: x.strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FUNCTION_1 (data, dataframe_new, time) : \n",
    "    \n",
    "    for idx in data.index : \n",
    "    \n",
    "        if time in str(data.loc[idx][\"Date\"]) : \n",
    "\n",
    "            sample = pd.Series({\"Date\" : data.loc[idx][\"Date\"], \"Value\" : data.loc[idx][\"Value\"]})\n",
    "\n",
    "            dataframe_new = dataframe_new.append(sample, ignore_index=True)\n",
    "            \n",
    "    dataframe_new[\"past_01\"] = dataframe_new[\"Value\"].shift(1)\n",
    "    dataframe_new[\"past_02\"] = dataframe_new[\"Value\"].shift(2)\n",
    "    dataframe_new[\"past_03\"] = dataframe_new[\"Value\"].shift(3)\n",
    "    dataframe_new[\"past_04\"] = dataframe_new[\"Value\"].shift(4)\n",
    "    dataframe_new[\"past_05\"] = dataframe_new[\"Value\"].shift(5)\n",
    "    dataframe_new[\"past_06\"] = dataframe_new[\"Value\"].shift(6)\n",
    "    dataframe_new[\"past_07\"] = dataframe_new[\"Value\"].shift(7)\n",
    "\n",
    "    dataframe_new = dataframe_new.dropna(subset=[\"past_01\", \"past_02\", \"past_03\", \"past_04\", \"past_05\", \"past_06\", \"past_07\"])\n",
    "    \n",
    "    dataframe_new = dataframe_new.reset_index()\n",
    "    \n",
    "    dataframe_new = dataframe_new[dataframe_new.columns[1:]]\n",
    "    \n",
    "    return dataframe_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FUNCTION_2 (dataframe, time) : \n",
    "    \n",
    "    train = pd.DataFrame()\n",
    "    test = pd.DataFrame()\n",
    "    \n",
    "    for idx in dataframe.index : \n",
    "        \n",
    "        if dataframe.loc[idx][\"Date\"] == \"2020-01-31\"+\" \"+ time : \n",
    "            dataframe.loc[idx][\"Date\"]\n",
    "            test = test.append(dataframe.loc[idx])\n",
    "        elif dataframe.loc[idx][\"Date\"] == \"2020-03-31\"+\" \"+ time : \n",
    "            test = test.append(dataframe.loc[idx])\n",
    "        elif dataframe.loc[idx][\"Date\"] == \"2020-05-31\"+\" \"+ time : \n",
    "            test = test.append(dataframe.loc[idx])\n",
    "        else :\n",
    "            train = train.append(dataframe.loc[idx])\n",
    "            \n",
    "    train = train.reset_index()\n",
    "    test = test.reset_index()\n",
    "    \n",
    "    train = train[train.columns[1:]]\n",
    "    test = test[test.columns[1:]]\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0600 = pd.DataFrame()\n",
    "data_0600 = FUNCTION_1(data = data3, dataframe_new = data_0600, time = \"06:00:00\")\n",
    "data_0600_train = FUNCTION_2(data_0600, time=\"06:00:00\")[0]\n",
    "data_0600_test = FUNCTION_2(data_0600, time=\"06:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Value</th>\n",
       "      <th>past_01</th>\n",
       "      <th>past_02</th>\n",
       "      <th>past_03</th>\n",
       "      <th>past_04</th>\n",
       "      <th>past_05</th>\n",
       "      <th>past_06</th>\n",
       "      <th>past_07</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-08 06:00:00</td>\n",
       "      <td>1.999866</td>\n",
       "      <td>6.212866</td>\n",
       "      <td>3.969866</td>\n",
       "      <td>4.315866</td>\n",
       "      <td>4.112866</td>\n",
       "      <td>4.189866</td>\n",
       "      <td>5.089866</td>\n",
       "      <td>2.393866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-09 06:00:00</td>\n",
       "      <td>3.491866</td>\n",
       "      <td>1.999866</td>\n",
       "      <td>6.212866</td>\n",
       "      <td>3.969866</td>\n",
       "      <td>4.315866</td>\n",
       "      <td>4.112866</td>\n",
       "      <td>4.189866</td>\n",
       "      <td>5.089866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-10 06:00:00</td>\n",
       "      <td>3.257866</td>\n",
       "      <td>3.491866</td>\n",
       "      <td>1.999866</td>\n",
       "      <td>6.212866</td>\n",
       "      <td>3.969866</td>\n",
       "      <td>4.315866</td>\n",
       "      <td>4.112866</td>\n",
       "      <td>4.189866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-11 06:00:00</td>\n",
       "      <td>1.042866</td>\n",
       "      <td>3.257866</td>\n",
       "      <td>3.491866</td>\n",
       "      <td>1.999866</td>\n",
       "      <td>6.212866</td>\n",
       "      <td>3.969866</td>\n",
       "      <td>4.315866</td>\n",
       "      <td>4.112866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-12 06:00:00</td>\n",
       "      <td>2.364866</td>\n",
       "      <td>1.042866</td>\n",
       "      <td>3.257866</td>\n",
       "      <td>3.491866</td>\n",
       "      <td>1.999866</td>\n",
       "      <td>6.212866</td>\n",
       "      <td>3.969866</td>\n",
       "      <td>4.315866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-07-13 06:00:00</td>\n",
       "      <td>3.228866</td>\n",
       "      <td>2.364866</td>\n",
       "      <td>1.042866</td>\n",
       "      <td>3.257866</td>\n",
       "      <td>3.491866</td>\n",
       "      <td>1.999866</td>\n",
       "      <td>6.212866</td>\n",
       "      <td>3.969866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-07-14 06:00:00</td>\n",
       "      <td>3.668866</td>\n",
       "      <td>3.228866</td>\n",
       "      <td>2.364866</td>\n",
       "      <td>1.042866</td>\n",
       "      <td>3.257866</td>\n",
       "      <td>3.491866</td>\n",
       "      <td>1.999866</td>\n",
       "      <td>6.212866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-07-15 06:00:00</td>\n",
       "      <td>2.054866</td>\n",
       "      <td>3.668866</td>\n",
       "      <td>3.228866</td>\n",
       "      <td>2.364866</td>\n",
       "      <td>1.042866</td>\n",
       "      <td>3.257866</td>\n",
       "      <td>3.491866</td>\n",
       "      <td>1.999866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-07-16 06:00:00</td>\n",
       "      <td>1.773866</td>\n",
       "      <td>2.054866</td>\n",
       "      <td>3.668866</td>\n",
       "      <td>3.228866</td>\n",
       "      <td>2.364866</td>\n",
       "      <td>1.042866</td>\n",
       "      <td>3.257866</td>\n",
       "      <td>3.491866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-07-17 06:00:00</td>\n",
       "      <td>3.688866</td>\n",
       "      <td>1.773866</td>\n",
       "      <td>2.054866</td>\n",
       "      <td>3.668866</td>\n",
       "      <td>3.228866</td>\n",
       "      <td>2.364866</td>\n",
       "      <td>1.042866</td>\n",
       "      <td>3.257866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-07-18 06:00:00</td>\n",
       "      <td>1.377866</td>\n",
       "      <td>3.688866</td>\n",
       "      <td>1.773866</td>\n",
       "      <td>2.054866</td>\n",
       "      <td>3.668866</td>\n",
       "      <td>3.228866</td>\n",
       "      <td>2.364866</td>\n",
       "      <td>1.042866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-07-19 06:00:00</td>\n",
       "      <td>2.438866</td>\n",
       "      <td>1.377866</td>\n",
       "      <td>3.688866</td>\n",
       "      <td>1.773866</td>\n",
       "      <td>2.054866</td>\n",
       "      <td>3.668866</td>\n",
       "      <td>3.228866</td>\n",
       "      <td>2.364866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-07-20 06:00:00</td>\n",
       "      <td>0.561866</td>\n",
       "      <td>2.438866</td>\n",
       "      <td>1.377866</td>\n",
       "      <td>3.688866</td>\n",
       "      <td>1.773866</td>\n",
       "      <td>2.054866</td>\n",
       "      <td>3.668866</td>\n",
       "      <td>3.228866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-07-21 06:00:00</td>\n",
       "      <td>0.236866</td>\n",
       "      <td>0.561866</td>\n",
       "      <td>2.438866</td>\n",
       "      <td>1.377866</td>\n",
       "      <td>3.688866</td>\n",
       "      <td>1.773866</td>\n",
       "      <td>2.054866</td>\n",
       "      <td>3.668866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-07-22 06:00:00</td>\n",
       "      <td>1.461866</td>\n",
       "      <td>0.236866</td>\n",
       "      <td>0.561866</td>\n",
       "      <td>2.438866</td>\n",
       "      <td>1.377866</td>\n",
       "      <td>3.688866</td>\n",
       "      <td>1.773866</td>\n",
       "      <td>2.054866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-07-23 06:00:00</td>\n",
       "      <td>3.397866</td>\n",
       "      <td>1.461866</td>\n",
       "      <td>0.236866</td>\n",
       "      <td>0.561866</td>\n",
       "      <td>2.438866</td>\n",
       "      <td>1.377866</td>\n",
       "      <td>3.688866</td>\n",
       "      <td>1.773866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-07-24 06:00:00</td>\n",
       "      <td>0.524866</td>\n",
       "      <td>3.397866</td>\n",
       "      <td>1.461866</td>\n",
       "      <td>0.236866</td>\n",
       "      <td>0.561866</td>\n",
       "      <td>2.438866</td>\n",
       "      <td>1.377866</td>\n",
       "      <td>3.688866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-07-25 06:00:00</td>\n",
       "      <td>0.125866</td>\n",
       "      <td>0.524866</td>\n",
       "      <td>3.397866</td>\n",
       "      <td>1.461866</td>\n",
       "      <td>0.236866</td>\n",
       "      <td>0.561866</td>\n",
       "      <td>2.438866</td>\n",
       "      <td>1.377866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-07-26 06:00:00</td>\n",
       "      <td>0.975866</td>\n",
       "      <td>0.125866</td>\n",
       "      <td>0.524866</td>\n",
       "      <td>3.397866</td>\n",
       "      <td>1.461866</td>\n",
       "      <td>0.236866</td>\n",
       "      <td>0.561866</td>\n",
       "      <td>2.438866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-07-27 06:00:00</td>\n",
       "      <td>2.236866</td>\n",
       "      <td>0.975866</td>\n",
       "      <td>0.125866</td>\n",
       "      <td>0.524866</td>\n",
       "      <td>3.397866</td>\n",
       "      <td>1.461866</td>\n",
       "      <td>0.236866</td>\n",
       "      <td>0.561866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-07-28 06:00:00</td>\n",
       "      <td>1.494866</td>\n",
       "      <td>2.236866</td>\n",
       "      <td>0.975866</td>\n",
       "      <td>0.125866</td>\n",
       "      <td>0.524866</td>\n",
       "      <td>3.397866</td>\n",
       "      <td>1.461866</td>\n",
       "      <td>0.236866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019-07-29 06:00:00</td>\n",
       "      <td>2.462866</td>\n",
       "      <td>1.494866</td>\n",
       "      <td>2.236866</td>\n",
       "      <td>0.975866</td>\n",
       "      <td>0.125866</td>\n",
       "      <td>0.524866</td>\n",
       "      <td>3.397866</td>\n",
       "      <td>1.461866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2019-07-30 06:00:00</td>\n",
       "      <td>1.334866</td>\n",
       "      <td>2.462866</td>\n",
       "      <td>1.494866</td>\n",
       "      <td>2.236866</td>\n",
       "      <td>0.975866</td>\n",
       "      <td>0.125866</td>\n",
       "      <td>0.524866</td>\n",
       "      <td>3.397866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2019-07-31 06:00:00</td>\n",
       "      <td>0.560866</td>\n",
       "      <td>1.334866</td>\n",
       "      <td>2.462866</td>\n",
       "      <td>1.494866</td>\n",
       "      <td>2.236866</td>\n",
       "      <td>0.975866</td>\n",
       "      <td>0.125866</td>\n",
       "      <td>0.524866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2019-08-01 06:00:00</td>\n",
       "      <td>1.684943</td>\n",
       "      <td>0.560866</td>\n",
       "      <td>1.334866</td>\n",
       "      <td>2.462866</td>\n",
       "      <td>1.494866</td>\n",
       "      <td>2.236866</td>\n",
       "      <td>0.975866</td>\n",
       "      <td>0.125866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2019-08-02 06:00:00</td>\n",
       "      <td>2.424943</td>\n",
       "      <td>1.684943</td>\n",
       "      <td>0.560866</td>\n",
       "      <td>1.334866</td>\n",
       "      <td>2.462866</td>\n",
       "      <td>1.494866</td>\n",
       "      <td>2.236866</td>\n",
       "      <td>0.975866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2019-08-03 06:00:00</td>\n",
       "      <td>3.515943</td>\n",
       "      <td>2.424943</td>\n",
       "      <td>1.684943</td>\n",
       "      <td>0.560866</td>\n",
       "      <td>1.334866</td>\n",
       "      <td>2.462866</td>\n",
       "      <td>1.494866</td>\n",
       "      <td>2.236866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2019-08-04 06:00:00</td>\n",
       "      <td>1.617943</td>\n",
       "      <td>3.515943</td>\n",
       "      <td>2.424943</td>\n",
       "      <td>1.684943</td>\n",
       "      <td>0.560866</td>\n",
       "      <td>1.334866</td>\n",
       "      <td>2.462866</td>\n",
       "      <td>1.494866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019-08-05 06:00:00</td>\n",
       "      <td>2.535943</td>\n",
       "      <td>1.617943</td>\n",
       "      <td>3.515943</td>\n",
       "      <td>2.424943</td>\n",
       "      <td>1.684943</td>\n",
       "      <td>0.560866</td>\n",
       "      <td>1.334866</td>\n",
       "      <td>2.462866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2019-08-06 06:00:00</td>\n",
       "      <td>1.467943</td>\n",
       "      <td>2.535943</td>\n",
       "      <td>1.617943</td>\n",
       "      <td>3.515943</td>\n",
       "      <td>2.424943</td>\n",
       "      <td>1.684943</td>\n",
       "      <td>0.560866</td>\n",
       "      <td>1.334866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2020-01-24 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2020-01-25 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2020-01-26 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>2020-01-27 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2020-01-28 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2020-01-29 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>2020-01-30 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>2020-02-08 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>2020-02-09 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>2020-02-10 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>2020-02-11 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>2020-02-12 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>2020-02-13 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>2020-02-14 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>2020-02-15 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>2020-02-16 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>2020-02-17 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>2020-02-18 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>2020-02-19 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>2020-02-20 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>2020-02-21 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>2020-02-22 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>2020-02-23 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>2020-02-24 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>2020-02-25 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>2020-02-26 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>2020-02-27 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>2020-02-28 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>2020-02-29 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>2020-03-01 06:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date     Value   past_01   past_02   past_03   past_04  \\\n",
       "0    2019-07-08 06:00:00  1.999866  6.212866  3.969866  4.315866  4.112866   \n",
       "1    2019-07-09 06:00:00  3.491866  1.999866  6.212866  3.969866  4.315866   \n",
       "2    2019-07-10 06:00:00  3.257866  3.491866  1.999866  6.212866  3.969866   \n",
       "3    2019-07-11 06:00:00  1.042866  3.257866  3.491866  1.999866  6.212866   \n",
       "4    2019-07-12 06:00:00  2.364866  1.042866  3.257866  3.491866  1.999866   \n",
       "5    2019-07-13 06:00:00  3.228866  2.364866  1.042866  3.257866  3.491866   \n",
       "6    2019-07-14 06:00:00  3.668866  3.228866  2.364866  1.042866  3.257866   \n",
       "7    2019-07-15 06:00:00  2.054866  3.668866  3.228866  2.364866  1.042866   \n",
       "8    2019-07-16 06:00:00  1.773866  2.054866  3.668866  3.228866  2.364866   \n",
       "9    2019-07-17 06:00:00  3.688866  1.773866  2.054866  3.668866  3.228866   \n",
       "10   2019-07-18 06:00:00  1.377866  3.688866  1.773866  2.054866  3.668866   \n",
       "11   2019-07-19 06:00:00  2.438866  1.377866  3.688866  1.773866  2.054866   \n",
       "12   2019-07-20 06:00:00  0.561866  2.438866  1.377866  3.688866  1.773866   \n",
       "13   2019-07-21 06:00:00  0.236866  0.561866  2.438866  1.377866  3.688866   \n",
       "14   2019-07-22 06:00:00  1.461866  0.236866  0.561866  2.438866  1.377866   \n",
       "15   2019-07-23 06:00:00  3.397866  1.461866  0.236866  0.561866  2.438866   \n",
       "16   2019-07-24 06:00:00  0.524866  3.397866  1.461866  0.236866  0.561866   \n",
       "17   2019-07-25 06:00:00  0.125866  0.524866  3.397866  1.461866  0.236866   \n",
       "18   2019-07-26 06:00:00  0.975866  0.125866  0.524866  3.397866  1.461866   \n",
       "19   2019-07-27 06:00:00  2.236866  0.975866  0.125866  0.524866  3.397866   \n",
       "20   2019-07-28 06:00:00  1.494866  2.236866  0.975866  0.125866  0.524866   \n",
       "21   2019-07-29 06:00:00  2.462866  1.494866  2.236866  0.975866  0.125866   \n",
       "22   2019-07-30 06:00:00  1.334866  2.462866  1.494866  2.236866  0.975866   \n",
       "23   2019-07-31 06:00:00  0.560866  1.334866  2.462866  1.494866  2.236866   \n",
       "24   2019-08-01 06:00:00  1.684943  0.560866  1.334866  2.462866  1.494866   \n",
       "25   2019-08-02 06:00:00  2.424943  1.684943  0.560866  1.334866  2.462866   \n",
       "26   2019-08-03 06:00:00  3.515943  2.424943  1.684943  0.560866  1.334866   \n",
       "27   2019-08-04 06:00:00  1.617943  3.515943  2.424943  1.684943  0.560866   \n",
       "28   2019-08-05 06:00:00  2.535943  1.617943  3.515943  2.424943  1.684943   \n",
       "29   2019-08-06 06:00:00  1.467943  2.535943  1.617943  3.515943  2.424943   \n",
       "..                   ...       ...       ...       ...       ...       ...   \n",
       "200  2020-01-24 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "201  2020-01-25 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "202  2020-01-26 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "203  2020-01-27 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "204  2020-01-28 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "205  2020-01-29 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "206  2020-01-30 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "207  2020-02-08 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "208  2020-02-09 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "209  2020-02-10 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "210  2020-02-11 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "211  2020-02-12 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "212  2020-02-13 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "213  2020-02-14 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "214  2020-02-15 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "215  2020-02-16 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "216  2020-02-17 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "217  2020-02-18 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "218  2020-02-19 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "219  2020-02-20 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "220  2020-02-21 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "221  2020-02-22 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "222  2020-02-23 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "223  2020-02-24 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "224  2020-02-25 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "225  2020-02-26 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "226  2020-02-27 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "227  2020-02-28 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "228  2020-02-29 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "229  2020-03-01 06:00:00  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "      past_05   past_06   past_07  \n",
       "0    4.189866  5.089866  2.393866  \n",
       "1    4.112866  4.189866  5.089866  \n",
       "2    4.315866  4.112866  4.189866  \n",
       "3    3.969866  4.315866  4.112866  \n",
       "4    6.212866  3.969866  4.315866  \n",
       "5    1.999866  6.212866  3.969866  \n",
       "6    3.491866  1.999866  6.212866  \n",
       "7    3.257866  3.491866  1.999866  \n",
       "8    1.042866  3.257866  3.491866  \n",
       "9    2.364866  1.042866  3.257866  \n",
       "10   3.228866  2.364866  1.042866  \n",
       "11   3.668866  3.228866  2.364866  \n",
       "12   2.054866  3.668866  3.228866  \n",
       "13   1.773866  2.054866  3.668866  \n",
       "14   3.688866  1.773866  2.054866  \n",
       "15   1.377866  3.688866  1.773866  \n",
       "16   2.438866  1.377866  3.688866  \n",
       "17   0.561866  2.438866  1.377866  \n",
       "18   0.236866  0.561866  2.438866  \n",
       "19   1.461866  0.236866  0.561866  \n",
       "20   3.397866  1.461866  0.236866  \n",
       "21   0.524866  3.397866  1.461866  \n",
       "22   0.125866  0.524866  3.397866  \n",
       "23   0.975866  0.125866  0.524866  \n",
       "24   2.236866  0.975866  0.125866  \n",
       "25   1.494866  2.236866  0.975866  \n",
       "26   2.462866  1.494866  2.236866  \n",
       "27   1.334866  2.462866  1.494866  \n",
       "28   0.560866  1.334866  2.462866  \n",
       "29   1.684943  0.560866  1.334866  \n",
       "..        ...       ...       ...  \n",
       "200  0.000000  0.000000  0.000000  \n",
       "201  0.000000  0.000000  0.000000  \n",
       "202  0.000000  0.000000  0.000000  \n",
       "203  0.000000  0.000000  0.000000  \n",
       "204  0.000000  0.000000  0.000000  \n",
       "205  0.000000  0.000000  0.000000  \n",
       "206  0.000000  0.000000  0.000000  \n",
       "207  0.000000  0.000000  0.000000  \n",
       "208  0.000000  0.000000  0.000000  \n",
       "209  0.000000  0.000000  0.000000  \n",
       "210  0.000000  0.000000  0.000000  \n",
       "211  0.000000  0.000000  0.000000  \n",
       "212  0.000000  0.000000  0.000000  \n",
       "213  0.000000  0.000000  0.000000  \n",
       "214  0.000000  0.000000  0.000000  \n",
       "215  0.000000  0.000000  0.000000  \n",
       "216  0.000000  0.000000  0.000000  \n",
       "217  0.000000  0.000000  0.000000  \n",
       "218  0.000000  0.000000  0.000000  \n",
       "219  0.000000  0.000000  0.000000  \n",
       "220  0.000000  0.000000  0.000000  \n",
       "221  0.000000  0.000000  0.000000  \n",
       "222  0.000000  0.000000  0.000000  \n",
       "223  0.000000  0.000000  0.000000  \n",
       "224  0.000000  0.000000  0.000000  \n",
       "225  0.000000  0.000000  0.000000  \n",
       "226  0.000000  0.000000  0.000000  \n",
       "227  0.000000  0.000000  0.000000  \n",
       "228  0.000000  0.000000  0.000000  \n",
       "229  0.000000  0.000000  0.000000  \n",
       "\n",
       "[230 rows x 9 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_0600_train.head(230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Value</th>\n",
       "      <th>past_01</th>\n",
       "      <th>past_02</th>\n",
       "      <th>past_03</th>\n",
       "      <th>past_04</th>\n",
       "      <th>past_05</th>\n",
       "      <th>past_06</th>\n",
       "      <th>past_07</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>2020-05-24 06:00:00</td>\n",
       "      <td>3.877000</td>\n",
       "      <td>4.496000</td>\n",
       "      <td>2.354000</td>\n",
       "      <td>5.057000</td>\n",
       "      <td>4.989000</td>\n",
       "      <td>3.971000</td>\n",
       "      <td>5.189000</td>\n",
       "      <td>0.855000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>2020-05-25 06:00:00</td>\n",
       "      <td>1.231000</td>\n",
       "      <td>3.877000</td>\n",
       "      <td>4.496000</td>\n",
       "      <td>2.354000</td>\n",
       "      <td>5.057000</td>\n",
       "      <td>4.989000</td>\n",
       "      <td>3.971000</td>\n",
       "      <td>5.189000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>2020-05-26 06:00:00</td>\n",
       "      <td>4.437000</td>\n",
       "      <td>1.231000</td>\n",
       "      <td>3.877000</td>\n",
       "      <td>4.496000</td>\n",
       "      <td>2.354000</td>\n",
       "      <td>5.057000</td>\n",
       "      <td>4.989000</td>\n",
       "      <td>3.971000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>2020-05-27 06:00:00</td>\n",
       "      <td>6.466000</td>\n",
       "      <td>4.437000</td>\n",
       "      <td>1.231000</td>\n",
       "      <td>3.877000</td>\n",
       "      <td>4.496000</td>\n",
       "      <td>2.354000</td>\n",
       "      <td>5.057000</td>\n",
       "      <td>4.989000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>2020-05-28 06:00:00</td>\n",
       "      <td>7.758000</td>\n",
       "      <td>6.466000</td>\n",
       "      <td>4.437000</td>\n",
       "      <td>1.231000</td>\n",
       "      <td>3.877000</td>\n",
       "      <td>4.496000</td>\n",
       "      <td>2.354000</td>\n",
       "      <td>5.057000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>2020-05-29 06:00:00</td>\n",
       "      <td>5.788000</td>\n",
       "      <td>7.758000</td>\n",
       "      <td>6.466000</td>\n",
       "      <td>4.437000</td>\n",
       "      <td>1.231000</td>\n",
       "      <td>3.877000</td>\n",
       "      <td>4.496000</td>\n",
       "      <td>2.354000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>2020-05-30 06:00:00</td>\n",
       "      <td>5.777000</td>\n",
       "      <td>5.788000</td>\n",
       "      <td>7.758000</td>\n",
       "      <td>6.466000</td>\n",
       "      <td>4.437000</td>\n",
       "      <td>1.231000</td>\n",
       "      <td>3.877000</td>\n",
       "      <td>4.496000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>2020-06-08 06:00:00</td>\n",
       "      <td>5.657000</td>\n",
       "      <td>2.936000</td>\n",
       "      <td>4.498000</td>\n",
       "      <td>3.863000</td>\n",
       "      <td>1.949000</td>\n",
       "      <td>1.068000</td>\n",
       "      <td>4.395000</td>\n",
       "      <td>1.641000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>2020-06-09 06:00:00</td>\n",
       "      <td>5.565000</td>\n",
       "      <td>5.657000</td>\n",
       "      <td>2.936000</td>\n",
       "      <td>4.498000</td>\n",
       "      <td>3.863000</td>\n",
       "      <td>1.949000</td>\n",
       "      <td>1.068000</td>\n",
       "      <td>4.395000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>2020-06-10 06:00:00</td>\n",
       "      <td>4.691000</td>\n",
       "      <td>5.565000</td>\n",
       "      <td>5.657000</td>\n",
       "      <td>2.936000</td>\n",
       "      <td>4.498000</td>\n",
       "      <td>3.863000</td>\n",
       "      <td>1.949000</td>\n",
       "      <td>1.068000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>2020-06-11 06:00:00</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>4.691000</td>\n",
       "      <td>5.565000</td>\n",
       "      <td>5.657000</td>\n",
       "      <td>2.936000</td>\n",
       "      <td>4.498000</td>\n",
       "      <td>3.863000</td>\n",
       "      <td>1.949000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>2020-06-12 06:00:00</td>\n",
       "      <td>5.453000</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>4.691000</td>\n",
       "      <td>5.565000</td>\n",
       "      <td>5.657000</td>\n",
       "      <td>2.936000</td>\n",
       "      <td>4.498000</td>\n",
       "      <td>3.863000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>2020-06-13 06:00:00</td>\n",
       "      <td>1.796000</td>\n",
       "      <td>5.453000</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>4.691000</td>\n",
       "      <td>5.565000</td>\n",
       "      <td>5.657000</td>\n",
       "      <td>2.936000</td>\n",
       "      <td>4.498000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>2020-06-14 06:00:00</td>\n",
       "      <td>0.617000</td>\n",
       "      <td>1.796000</td>\n",
       "      <td>5.453000</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>4.691000</td>\n",
       "      <td>5.565000</td>\n",
       "      <td>5.657000</td>\n",
       "      <td>2.936000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>2020-06-15 06:00:00</td>\n",
       "      <td>5.810000</td>\n",
       "      <td>0.617000</td>\n",
       "      <td>1.796000</td>\n",
       "      <td>5.453000</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>4.691000</td>\n",
       "      <td>5.565000</td>\n",
       "      <td>5.657000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>2020-06-16 06:00:00</td>\n",
       "      <td>2.370000</td>\n",
       "      <td>5.810000</td>\n",
       "      <td>0.617000</td>\n",
       "      <td>1.796000</td>\n",
       "      <td>5.453000</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>4.691000</td>\n",
       "      <td>5.565000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>2020-06-17 06:00:00</td>\n",
       "      <td>7.875000</td>\n",
       "      <td>2.370000</td>\n",
       "      <td>5.810000</td>\n",
       "      <td>0.617000</td>\n",
       "      <td>1.796000</td>\n",
       "      <td>5.453000</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>4.691000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>2020-06-18 06:00:00</td>\n",
       "      <td>7.995082</td>\n",
       "      <td>7.875000</td>\n",
       "      <td>2.370000</td>\n",
       "      <td>5.810000</td>\n",
       "      <td>0.617000</td>\n",
       "      <td>1.796000</td>\n",
       "      <td>5.453000</td>\n",
       "      <td>0.824000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>2020-06-19 06:00:00</td>\n",
       "      <td>2.064000</td>\n",
       "      <td>7.995082</td>\n",
       "      <td>7.875000</td>\n",
       "      <td>2.370000</td>\n",
       "      <td>5.810000</td>\n",
       "      <td>0.617000</td>\n",
       "      <td>1.796000</td>\n",
       "      <td>5.453000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>2020-06-20 06:00:00</td>\n",
       "      <td>5.586000</td>\n",
       "      <td>2.064000</td>\n",
       "      <td>7.995082</td>\n",
       "      <td>7.875000</td>\n",
       "      <td>2.370000</td>\n",
       "      <td>5.810000</td>\n",
       "      <td>0.617000</td>\n",
       "      <td>1.796000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>2020-06-21 06:00:00</td>\n",
       "      <td>2.831000</td>\n",
       "      <td>5.586000</td>\n",
       "      <td>2.064000</td>\n",
       "      <td>7.995082</td>\n",
       "      <td>7.875000</td>\n",
       "      <td>2.370000</td>\n",
       "      <td>5.810000</td>\n",
       "      <td>0.617000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>2020-06-22 06:00:00</td>\n",
       "      <td>5.288000</td>\n",
       "      <td>2.831000</td>\n",
       "      <td>5.586000</td>\n",
       "      <td>2.064000</td>\n",
       "      <td>7.995082</td>\n",
       "      <td>7.875000</td>\n",
       "      <td>2.370000</td>\n",
       "      <td>5.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>2020-06-23 06:00:00</td>\n",
       "      <td>5.556000</td>\n",
       "      <td>5.288000</td>\n",
       "      <td>2.831000</td>\n",
       "      <td>5.586000</td>\n",
       "      <td>2.064000</td>\n",
       "      <td>7.995082</td>\n",
       "      <td>7.875000</td>\n",
       "      <td>2.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>2020-06-24 06:00:00</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>5.556000</td>\n",
       "      <td>5.288000</td>\n",
       "      <td>2.831000</td>\n",
       "      <td>5.586000</td>\n",
       "      <td>2.064000</td>\n",
       "      <td>7.995082</td>\n",
       "      <td>7.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>2020-06-25 06:00:00</td>\n",
       "      <td>1.688000</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>5.556000</td>\n",
       "      <td>5.288000</td>\n",
       "      <td>2.831000</td>\n",
       "      <td>5.586000</td>\n",
       "      <td>2.064000</td>\n",
       "      <td>7.995082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>2020-06-26 06:00:00</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>1.688000</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>5.556000</td>\n",
       "      <td>5.288000</td>\n",
       "      <td>2.831000</td>\n",
       "      <td>5.586000</td>\n",
       "      <td>2.064000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>2020-06-27 06:00:00</td>\n",
       "      <td>4.167000</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>1.688000</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>5.556000</td>\n",
       "      <td>5.288000</td>\n",
       "      <td>2.831000</td>\n",
       "      <td>5.586000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>2020-06-28 06:00:00</td>\n",
       "      <td>3.968000</td>\n",
       "      <td>4.167000</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>1.688000</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>5.556000</td>\n",
       "      <td>5.288000</td>\n",
       "      <td>2.831000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2020-06-29 06:00:00</td>\n",
       "      <td>7.707000</td>\n",
       "      <td>3.968000</td>\n",
       "      <td>4.167000</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>1.688000</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>5.556000</td>\n",
       "      <td>5.288000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>2020-06-30 06:00:00</td>\n",
       "      <td>0.614000</td>\n",
       "      <td>7.707000</td>\n",
       "      <td>3.968000</td>\n",
       "      <td>4.167000</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>1.688000</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>5.556000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Date     Value   past_01   past_02   past_03   past_04  \\\n",
       "305  2020-05-24 06:00:00  3.877000  4.496000  2.354000  5.057000  4.989000   \n",
       "306  2020-05-25 06:00:00  1.231000  3.877000  4.496000  2.354000  5.057000   \n",
       "307  2020-05-26 06:00:00  4.437000  1.231000  3.877000  4.496000  2.354000   \n",
       "308  2020-05-27 06:00:00  6.466000  4.437000  1.231000  3.877000  4.496000   \n",
       "309  2020-05-28 06:00:00  7.758000  6.466000  4.437000  1.231000  3.877000   \n",
       "310  2020-05-29 06:00:00  5.788000  7.758000  6.466000  4.437000  1.231000   \n",
       "311  2020-05-30 06:00:00  5.777000  5.788000  7.758000  6.466000  4.437000   \n",
       "312  2020-06-08 06:00:00  5.657000  2.936000  4.498000  3.863000  1.949000   \n",
       "313  2020-06-09 06:00:00  5.565000  5.657000  2.936000  4.498000  3.863000   \n",
       "314  2020-06-10 06:00:00  4.691000  5.565000  5.657000  2.936000  4.498000   \n",
       "315  2020-06-11 06:00:00  0.824000  4.691000  5.565000  5.657000  2.936000   \n",
       "316  2020-06-12 06:00:00  5.453000  0.824000  4.691000  5.565000  5.657000   \n",
       "317  2020-06-13 06:00:00  1.796000  5.453000  0.824000  4.691000  5.565000   \n",
       "318  2020-06-14 06:00:00  0.617000  1.796000  5.453000  0.824000  4.691000   \n",
       "319  2020-06-15 06:00:00  5.810000  0.617000  1.796000  5.453000  0.824000   \n",
       "320  2020-06-16 06:00:00  2.370000  5.810000  0.617000  1.796000  5.453000   \n",
       "321  2020-06-17 06:00:00  7.875000  2.370000  5.810000  0.617000  1.796000   \n",
       "322  2020-06-18 06:00:00  7.995082  7.875000  2.370000  5.810000  0.617000   \n",
       "323  2020-06-19 06:00:00  2.064000  7.995082  7.875000  2.370000  5.810000   \n",
       "324  2020-06-20 06:00:00  5.586000  2.064000  7.995082  7.875000  2.370000   \n",
       "325  2020-06-21 06:00:00  2.831000  5.586000  2.064000  7.995082  7.875000   \n",
       "326  2020-06-22 06:00:00  5.288000  2.831000  5.586000  2.064000  7.995082   \n",
       "327  2020-06-23 06:00:00  5.556000  5.288000  2.831000  5.586000  2.064000   \n",
       "328  2020-06-24 06:00:00  1.488000  5.556000  5.288000  2.831000  5.586000   \n",
       "329  2020-06-25 06:00:00  1.688000  1.488000  5.556000  5.288000  2.831000   \n",
       "330  2020-06-26 06:00:00  0.769000  1.688000  1.488000  5.556000  5.288000   \n",
       "331  2020-06-27 06:00:00  4.167000  0.769000  1.688000  1.488000  5.556000   \n",
       "332  2020-06-28 06:00:00  3.968000  4.167000  0.769000  1.688000  1.488000   \n",
       "333  2020-06-29 06:00:00  7.707000  3.968000  4.167000  0.769000  1.688000   \n",
       "334  2020-06-30 06:00:00  0.614000  7.707000  3.968000  4.167000  0.769000   \n",
       "\n",
       "      past_05   past_06   past_07  \n",
       "305  3.971000  5.189000  0.855000  \n",
       "306  4.989000  3.971000  5.189000  \n",
       "307  5.057000  4.989000  3.971000  \n",
       "308  2.354000  5.057000  4.989000  \n",
       "309  4.496000  2.354000  5.057000  \n",
       "310  3.877000  4.496000  2.354000  \n",
       "311  1.231000  3.877000  4.496000  \n",
       "312  1.068000  4.395000  1.641000  \n",
       "313  1.949000  1.068000  4.395000  \n",
       "314  3.863000  1.949000  1.068000  \n",
       "315  4.498000  3.863000  1.949000  \n",
       "316  2.936000  4.498000  3.863000  \n",
       "317  5.657000  2.936000  4.498000  \n",
       "318  5.565000  5.657000  2.936000  \n",
       "319  4.691000  5.565000  5.657000  \n",
       "320  0.824000  4.691000  5.565000  \n",
       "321  5.453000  0.824000  4.691000  \n",
       "322  1.796000  5.453000  0.824000  \n",
       "323  0.617000  1.796000  5.453000  \n",
       "324  5.810000  0.617000  1.796000  \n",
       "325  2.370000  5.810000  0.617000  \n",
       "326  7.875000  2.370000  5.810000  \n",
       "327  7.995082  7.875000  2.370000  \n",
       "328  2.064000  7.995082  7.875000  \n",
       "329  5.586000  2.064000  7.995082  \n",
       "330  2.831000  5.586000  2.064000  \n",
       "331  5.288000  2.831000  5.586000  \n",
       "332  5.556000  5.288000  2.831000  \n",
       "333  1.488000  5.556000  5.288000  \n",
       "334  1.688000  1.488000  5.556000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_0600_train.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Value</th>\n",
       "      <th>past_01</th>\n",
       "      <th>past_02</th>\n",
       "      <th>past_03</th>\n",
       "      <th>past_04</th>\n",
       "      <th>past_05</th>\n",
       "      <th>past_06</th>\n",
       "      <th>past_07</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-31 06:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-31 06:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-31 06:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.777</td>\n",
       "      <td>5.788</td>\n",
       "      <td>7.758</td>\n",
       "      <td>6.466</td>\n",
       "      <td>4.437</td>\n",
       "      <td>1.231</td>\n",
       "      <td>3.877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date  Value  past_01  past_02  past_03  past_04  past_05  \\\n",
       "0  2020-01-31 06:00:00    NaN    0.000    0.000    0.000    0.000    0.000   \n",
       "1  2020-03-31 06:00:00    NaN    0.270    0.287    0.164    0.010    0.073   \n",
       "2  2020-05-31 06:00:00    NaN    5.777    5.788    7.758    6.466    4.437   \n",
       "\n",
       "   past_06  past_07  \n",
       "0    0.000    0.000  \n",
       "1    0.111    0.076  \n",
       "2    1.231    3.877  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_0600_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0500 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0500 = pd.DataFrame()\n",
    "data_0500 = FUNCTION_1(data = data3, dataframe_new = data_0500, time = \"05:00:00\")\n",
    "data_0500_train = FUNCTION_2(data_0500, time=\"05:00:00\")[0]\n",
    "data_0500_test = FUNCTION_2(data_0500, time=\"05:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_0500_train[data_0500_train.columns[2:]].values\n",
    "X_test = data_0500_test[data_0500_test.columns[2:]].values\n",
    "\n",
    "y_train = data_0500_train[\"Value\"].values\n",
    "y_test = data_0500_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 4ms/step - loss: 0.0078\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 0.0075\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 784us/step - loss: 0.0063\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 0.0080\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 0.0076\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 0.0070\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 0.0063\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 0.0064\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 0.0072\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 772us/step - loss: 0.0075\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 0.0072\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 0.0057\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 769us/step - loss: 0.0065\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 0.0067\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 0.0070\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 0.0067\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 878us/step - loss: 0.0068\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 841us/step - loss: 0.0068\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 0.0079\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 780us/step - loss: 0.0072\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 780us/step - loss: 0.0067\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 905us/step - loss: 0.0070\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 0.0072\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 744us/step - loss: 0.0065\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 848us/step - loss: 0.0071\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 776us/step - loss: 0.0067\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 741us/step - loss: 0.0070\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 767us/step - loss: 0.0069\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 0.0068\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 0.0073\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 767us/step - loss: 0.0062\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 0.0075\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 761us/step - loss: 0.0067\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 0.0068\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 776us/step - loss: 0.0070\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 783us/step - loss: 0.0070\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 0.0067\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 759us/step - loss: 0.0073\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 832us/step - loss: 0.0067\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 0.0064\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 800us/step - loss: 0.0069\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 786us/step - loss: 0.0065\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 0.0064\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 778us/step - loss: 0.0069\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 845us/step - loss: 0.0064\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 0.0075\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 876us/step - loss: 0.0072\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 0.0064\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 0.0061\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 0.0061\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 851us/step - loss: 0.0069\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 0.0072\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 761us/step - loss: 0.0069\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 0.0075\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 884us/step - loss: 0.0074\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 0.0066\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 0.0064\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 941us/step - loss: 0.0070\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 0.0062\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 878us/step - loss: 0.0060\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 872us/step - loss: 0.0069\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 885us/step - loss: 0.0074\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 786us/step - loss: 0.0075\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 976us/step - loss: 0.0066\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 766us/step - loss: 0.0066\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 0.0065\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 849us/step - loss: 0.0067\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 780us/step - loss: 0.0068\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 0.0064\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 751us/step - loss: 0.0072\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 878us/step - loss: 0.0074\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 783us/step - loss: 0.0067\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 923us/step - loss: 0.0066\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 784us/step - loss: 0.0065\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 834us/step - loss: 0.0071\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 941us/step - loss: 0.0064\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 926us/step - loss: 0.0056\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 0.0061\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 902us/step - loss: 0.0064\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 887us/step - loss: 0.0068\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 0.0069\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 0.0064\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 0.0071TA: 0s - loss: 0.00\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 890us/step - loss: 0.0065\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 908us/step - loss: 0.0060\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 848us/step - loss: 0.0060\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 849us/step - loss: 0.0071\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 762us/step - loss: 0.0056\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 0.0068\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 0.0065\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 770us/step - loss: 0.0069\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 0.0069\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 0.0071\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 821us/step - loss: 0.0070\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 810us/step - loss: 0.0071\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 0.0071\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 0.0072\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 747us/step - loss: 0.0065\n",
      "Epoch 99/100\n",
      "208/335 [=================>............] - ETA: 0s - loss: 0.0048  "
     ]
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0e-04]\n",
      " [1.0e-04]\n",
      " [9.5e-02]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 0.0240\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 855us/step - loss: 0.0226\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 0.0218\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 0.0224\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 0.0223\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 726us/step - loss: 0.0247\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 0.0239\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 783us/step - loss: 0.0223\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 781us/step - loss: 0.0226\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 0.0227\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 764us/step - loss: 0.0230\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 0.0214\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 785us/step - loss: 0.0231\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 773us/step - loss: 0.0248\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 0.0227\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 771us/step - loss: 0.0221\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 0.0241\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 743us/step - loss: 0.0234\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 705us/step - loss: 0.0229\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 714us/step - loss: 0.0234\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 0.0232\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 750us/step - loss: 0.0229\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 761us/step - loss: 0.0218\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 785us/step - loss: 0.0233\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 0.0231\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 0.0240\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 750us/step - loss: 0.0208\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 782us/step - loss: 0.0238\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 786us/step - loss: 0.0232\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 778us/step - loss: 0.0216\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 0.0227\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 737us/step - loss: 0.0223\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 0.0231\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 778us/step - loss: 0.0244\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 753us/step - loss: 0.0239\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 0.0227\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 761us/step - loss: 0.0236\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 0.0219\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 741us/step - loss: 0.0230\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 783us/step - loss: 0.0221\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 767us/step - loss: 0.0219\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 771us/step - loss: 0.0214\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 774us/step - loss: 0.0228\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 0.0210\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 748us/step - loss: 0.0216\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 0.0208\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 807us/step - loss: 0.0231\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 720us/step - loss: 0.0218\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 718us/step - loss: 0.0238\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 0.0212\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 758us/step - loss: 0.0240\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 0.0226\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 855us/step - loss: 0.0231\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 843us/step - loss: 0.0222\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 0.0219\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 758us/step - loss: 0.0208\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 0.0226\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 0.0231\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 778us/step - loss: 0.0222\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 761us/step - loss: 0.0205\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 776us/step - loss: 0.0222\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 0.0201\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 0.0231\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 759us/step - loss: 0.0204\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 858us/step - loss: 0.0230\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 763us/step - loss: 0.0228\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 0.0210\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 786us/step - loss: 0.0222\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 747us/step - loss: 0.0233\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 0.0232\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 0.0212\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 769us/step - loss: 0.0231\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 747us/step - loss: 0.0239\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 0.0223\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 764us/step - loss: 0.0219\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 755us/step - loss: 0.0221\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 815us/step - loss: 0.0221\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 0.0241\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 0.0213\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 757us/step - loss: 0.0210\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 0.0227\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 770us/step - loss: 0.0203\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 0.0233\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 769us/step - loss: 0.0209\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 737us/step - loss: 0.0229\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 768us/step - loss: 0.0217\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 0.0220\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 0.0233\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 749us/step - loss: 0.0211\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 905us/step - loss: 0.0238\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 770us/step - loss: 0.0209\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 777us/step - loss: 0.0238\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 741us/step - loss: 0.0219\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 0.0222\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 0.0229\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 774us/step - loss: 0.0213\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 836us/step - loss: 0.0225\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 816us/step - loss: 0.0201\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 759us/step - loss: 0.0213\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 0.0232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1aecea54160>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0024]\n",
      " [-0.0024]\n",
      " [ 0.083 ]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_0600_train[data_0600_train.columns[2:]].values\n",
    "X_test = data_0600_test[data_0600_test.columns[2:]].values\n",
    "\n",
    "y_train = data_0600_train[\"Value\"].values\n",
    "y_test = data_0600_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 2.6166\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 782us/step - loss: 2.4805\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 746us/step - loss: 2.4488\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 762us/step - loss: 2.5863\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 764us/step - loss: 2.3088\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 2.7079\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 829us/step - loss: 2.4312\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 2.3247\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 2.7218\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 2.2333\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 1.9860\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 771us/step - loss: 2.0133\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 786us/step - loss: 2.3255\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 2.4835\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 749us/step - loss: 2.0489\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 845us/step - loss: 2.2473\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 833us/step - loss: 2.5328\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 775us/step - loss: 2.1516\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 2.2484\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 759us/step - loss: 2.0096\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 2.2532\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 2.5658\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 756us/step - loss: 2.6570\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 2.4629\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 769us/step - loss: 2.3632\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 2.4683\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 2.5456\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 2.2504\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 2.1822\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 2.1948\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 2.6130\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 763us/step - loss: 2.4952\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 2.8598\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 2.5607\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 2.2105\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 819us/step - loss: 2.1757\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 2.0281\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 2.5331\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 773us/step - loss: 2.0410\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 2.4514\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 785us/step - loss: 2.3276\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 2.3455\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 775us/step - loss: 2.0369\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 2.5206\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 2.0178\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 782us/step - loss: 2.3743\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 835us/step - loss: 2.2035\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 986us/step - loss: 2.2046\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 884us/step - loss: 2.6785\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 941us/step - loss: 2.3409\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2.3963\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 920us/step - loss: 2.5245 0s - loss: 2.259\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 991us/step - loss: 2.4558\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 935us/step - loss: 2.4360\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 933us/step - loss: 2.1462\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2.0511\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2.6530\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2.7188\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2.1285\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2.1095\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - ETA: 0s - loss: 1.894 - 0s 1ms/step - loss: 2.0375\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2.4549\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2.2165\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2.3900\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2.3119\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2.1405\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2.5292\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2.4259\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2.7821\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2.4311\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2.0327\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2.1625\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2.2638\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2.2165\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2.2894\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 962us/step - loss: 2.2285\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2.1810\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2.2562\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 957us/step - loss: 2.2871\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 953us/step - loss: 2.4127\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 862us/step - loss: 2.2540\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 890us/step - loss: 1.9512\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 2.1419 0s - loss: 2.138\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 902us/step - loss: 2.3267\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 849us/step - loss: 2.2527\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 786us/step - loss: 2.5239\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 845us/step - loss: 2.3261\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 2.4081 0s - loss: 2.530\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 774us/step - loss: 2.5295\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 2.4500\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 823us/step - loss: 2.5216\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 862us/step - loss: 2.2515\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 804us/step - loss: 1.8731\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 2.2767\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 772us/step - loss: 2.2532\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 785us/step - loss: 2.0538\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 815us/step - loss: 2.2359\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 904us/step - loss: 2.0372\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 2.3320\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 2.3138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af1ed34160>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0022]\n",
      " [ 0.0547]\n",
      " [ 1.8513]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 1.0127\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 749us/step - loss: 0.8070\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 790us/step - loss: 0.6654\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 0.5769\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 914us/step - loss: 0.5506\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 852us/step - loss: 0.5417\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 769us/step - loss: 0.5351\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 883us/step - loss: 0.5297\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5269\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.5256\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 834us/step - loss: 0.5234\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 715us/step - loss: 0.5231\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 735us/step - loss: 0.5219\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 0.5232\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 0.5185\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 0.5189\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 639us/step - loss: 0.5183\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 0.5169\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 0.5194\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 0.5169\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 0.5154\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 0.5137\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 0.5135\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 642us/step - loss: 0.5139\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 0.5127\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 0.5135\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 711us/step - loss: 0.5146\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 0.5110\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 741us/step - loss: 0.5099\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 692us/step - loss: 0.5096\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 0.5092\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 0.5143\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 0.5108\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 681us/step - loss: 0.5091\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 0.5084\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 0.5099\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 631us/step - loss: 0.5069\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 0.5097\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 949us/step - loss: 0.5075\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 786us/step - loss: 0.5098\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 714us/step - loss: 0.5075\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 637us/step - loss: 0.5069\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 0.5066\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 0.5064\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 630us/step - loss: 0.5059\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 782us/step - loss: 0.5064\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 632us/step - loss: 0.5052\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 755us/step - loss: 0.5060\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 0.5031\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 698us/step - loss: 0.5077\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 735us/step - loss: 0.5037\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 712us/step - loss: 0.5035\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 0.5024\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 992us/step - loss: 0.5010\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 965us/step - loss: 0.5063\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 946us/step - loss: 0.5037\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 890us/step - loss: 0.5033\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 739us/step - loss: 0.4987\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 0.5013\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 0.4962\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 0.4956\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 0.4938\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 0.4911\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 634us/step - loss: 0.4990\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 633us/step - loss: 0.4890\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 676us/step - loss: 0.4886\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 0.4939\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 0.4917\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 571us/step - loss: 0.4860\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 0.4831\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 612us/step - loss: 0.4850\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 0.4843\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 0.4862\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 712us/step - loss: 0.4939\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 0.4863\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 0.4908\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 0.4858\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 0.4821\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 623us/step - loss: 0.4875\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 634us/step - loss: 0.4858\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 684us/step - loss: 0.4824\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 698us/step - loss: 0.4834\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 0.4958\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 0.4894\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 0.4810\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 888us/step - loss: 0.4801\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 810us/step - loss: 0.4858\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 866us/step - loss: 0.4838\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 956us/step - loss: 0.4869\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.4826\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 0.4797\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 959us/step - loss: 0.4826\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 718us/step - loss: 0.4807\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 827us/step - loss: 0.4779\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 715us/step - loss: 0.4833\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 0.4791\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 0.4773\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 765us/step - loss: 0.4813\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 642us/step - loss: 0.4978\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 642us/step - loss: 0.4751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af206991d0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.0000e-04]\n",
      " [ 1.2140e-01]\n",
      " [ 4.4016e+00]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0700 = pd.DataFrame()\n",
    "data_0700 = FUNCTION_1(data = data3, dataframe_new = data_0700, time = \"07:00:00\")\n",
    "data_0700_train = FUNCTION_2(data_0700, time=\"07:00:00\")[0]\n",
    "data_0700_test = FUNCTION_2(data_0700, time=\"07:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_0700_train[data_0700_train.columns[2:]].values\n",
    "X_test = data_0700_test[data_0700_test.columns[2:]].values\n",
    "\n",
    "y_train = data_0700_train[\"Value\"].values\n",
    "y_test = data_0700_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 78.5994\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 725us/step - loss: 66.0002\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 685us/step - loss: 59.1901\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 605us/step - loss: 53.9294\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 48.7786\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 706us/step - loss: 45.2609\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 629us/step - loss: 48.8392\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 46.6129\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 42.9468\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 41.4715\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 41.2722\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 726us/step - loss: 42.1631\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 877us/step - loss: 43.9654\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 759us/step - loss: 38.3688\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 732us/step - loss: 50.2273\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 708us/step - loss: 44.3056\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 723us/step - loss: 41.1327\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 43.5892\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 47.5011\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 42.5067\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 717us/step - loss: 41.5557\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 830us/step - loss: 52.0776\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 46.9220\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 688us/step - loss: 43.8039\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 42.5801\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 42.9103\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 49.3548\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 40.2226\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 43.3676\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 36.4411\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 46.3003\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 678us/step - loss: 39.3253\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 46.2140\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 46.2144\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 49.0613\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 48.7837\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 45.3376\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 683us/step - loss: 45.9861\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 46.1822\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 37.5788\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 44.4681\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 46.1182\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 44.7920\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 44.5827\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 41.4391\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 47.4158\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 45.4301\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 41.9041\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 49.6544\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 676us/step - loss: 43.2075\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 45.5624\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 46.7286\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 722us/step - loss: 46.2241\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 758us/step - loss: 38.9129\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 699us/step - loss: 44.9426\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 41.5580\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 697us/step - loss: 53.5107\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 39.5731\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 676us/step - loss: 38.0069\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 633us/step - loss: 45.2944\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 626us/step - loss: 45.7533\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 872us/step - loss: 47.9137\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 45.5835\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 41.7149\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 683us/step - loss: 37.8297\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 764us/step - loss: 42.1810\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 769us/step - loss: 39.7578\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 43.4723\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 46.3470\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 45.7268\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 40.6519\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 749us/step - loss: 45.7815\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 48.9543\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 638us/step - loss: 49.4163\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 637us/step - loss: 46.5781\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 765us/step - loss: 45.6085\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 714us/step - loss: 50.8121\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 43.9249\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 42.1325\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 46.5529\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 639us/step - loss: 44.9424\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 625us/step - loss: 41.5338\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 50.2930\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 40.4169\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 870us/step - loss: 44.6274\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 691us/step - loss: 42.6154\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 632us/step - loss: 38.9381\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 727us/step - loss: 44.8962\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 785us/step - loss: 41.4227\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 47.2959\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 724us/step - loss: 46.4735\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 698us/step - loss: 39.5144\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 630us/step - loss: 45.3109\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 703us/step - loss: 38.7440\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 622us/step - loss: 41.7514\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 696us/step - loss: 44.8972\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 632us/step - loss: 45.0589\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 733us/step - loss: 44.4165\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 676us/step - loss: 49.0120\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 42.1409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af21f6ceb8>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0601]\n",
      " [3.9641]\n",
      " [6.7372]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 5.1517\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 772us/step - loss: 4.7125\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 731us/step - loss: 4.6409\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 731us/step - loss: 4.3901\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 725us/step - loss: 4.6519\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 725us/step - loss: 4.5977\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 702us/step - loss: 4.4279\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 734us/step - loss: 4.3866\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 4.4034\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 716us/step - loss: 4.0127\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 700us/step - loss: 4.1802\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 826us/step - loss: 4.4139\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 695us/step - loss: 4.3518\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 770us/step - loss: 4.3068\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 695us/step - loss: 3.9935\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 720us/step - loss: 4.3118\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 4.1709\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 683us/step - loss: 4.1315\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 4.0308\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 3.9846\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 4.1089\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 726us/step - loss: 4.2441\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 4.1847\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 4.4680\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 705us/step - loss: 4.3101\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 642us/step - loss: 4.0139\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 698us/step - loss: 4.5820\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 4.2895\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 715us/step - loss: 4.1816\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 4.2966\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 695us/step - loss: 4.2104\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 857us/step - loss: 4.0227\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 811us/step - loss: 4.1529\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 4.2252\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 691us/step - loss: 4.1519\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 685us/step - loss: 4.2530\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 4.3371\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 727us/step - loss: 4.1545\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 694us/step - loss: 4.0338\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 4.3994\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 4.0567\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 4.2272\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 4.2338\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 4.2379\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 4.3413\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 609us/step - loss: 4.1140\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 4.1587\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 4.1541\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 4.1859\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 4.3029\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 643us/step - loss: 4.2058\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 4.2772\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 4.2902\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 4.2977\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 4.0396\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 3.9571\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 3.8530\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 637us/step - loss: 4.1187\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 685us/step - loss: 3.9328\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 4.3296\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 4.3323\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 4.2090\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 4.2335\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 4.2130\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 944us/step - loss: 4.3208\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 792us/step - loss: 4.1787\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 730us/step - loss: 4.2564\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 726us/step - loss: 4.0237\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 708us/step - loss: 4.3298\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 855us/step - loss: 4.2508\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 726us/step - loss: 4.0328\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 4.0750\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 715us/step - loss: 4.0531\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 4.3189\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 3.8019\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 635us/step - loss: 4.4727\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 3.7606\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 4.1059\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 4.0704\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 678us/step - loss: 4.1913\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 4.1227\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 4.1099\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 695us/step - loss: 4.1119\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 4.1180\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 4.3649\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 678us/step - loss: 4.1358\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 4.1703\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 688us/step - loss: 4.2169\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 694us/step - loss: 3.9437\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 684us/step - loss: 3.9873\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 3.9362\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 987us/step - loss: 3.6956\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 702us/step - loss: 4.2183\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 825us/step - loss: 4.5272\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 4.2561\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 711us/step - loss: 4.1689\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 4.0627\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 742us/step - loss: 4.3519\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 748us/step - loss: 3.8026\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 691us/step - loss: 4.2867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af22916898>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0277]\n",
      " [4.3639]\n",
      " [7.0453]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0800 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0800 = pd.DataFrame()\n",
    "data_0800 = FUNCTION_1(data = data3, dataframe_new = data_0800, time = \"08:00:00\")\n",
    "data_0800_train = FUNCTION_2(data_0800, time=\"08:00:00\")[0]\n",
    "data_0800_test = FUNCTION_2(data_0800, time=\"08:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_0800_train[data_0800_train.columns[2:]].values\n",
    "X_test = data_0800_test[data_0800_test.columns[2:]].values\n",
    "\n",
    "y_train = data_0800_train[\"Value\"].values\n",
    "y_test = data_0800_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam',metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 425.4694 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 768us/step - loss: 394.6173 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 366.6322 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 795us/step - loss: 358.5670 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 345.0245 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 722us/step - loss: 340.3410 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 333.6735 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 299.8021 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 310.3516 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 875us/step - loss: 296.6278 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 887us/step - loss: 286.7489 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 909us/step - loss: 300.8321 - accuracy: 0.0000e+000s - loss: 296.2901 - accuracy: 0.0000e+\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 292.5282 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 872us/step - loss: 268.1043 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 277.6327 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 310.8550 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 293.1234 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 244.1230 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 997us/step - loss: 291.0397 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 931us/step - loss: 282.7452 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 887us/step - loss: 284.2699 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 288.6532 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 894us/step - loss: 287.6733 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 857us/step - loss: 276.7088 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 799us/step - loss: 255.9716 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 893us/step - loss: 253.0805 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 890us/step - loss: 313.7340 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 962us/step - loss: 284.7449 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 944us/step - loss: 247.1500 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 936us/step - loss: 291.2696 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 918us/step - loss: 283.4859 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 699us/step - loss: 275.5061 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 689us/step - loss: 276.3822 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 272.4822 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 693us/step - loss: 293.3961 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 726us/step - loss: 267.3726 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 696us/step - loss: 274.8691 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 709us/step - loss: 301.1169 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 691us/step - loss: 279.8261 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 710us/step - loss: 288.1486 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 254.6384 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 285.9277 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 935us/step - loss: 252.9540 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 932us/step - loss: 249.8622 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 266.0106 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 293.1524 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 854us/step - loss: 311.0623 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 856us/step - loss: 263.8613 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 889us/step - loss: 274.9774 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 834us/step - loss: 289.2770 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 284.7831 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 786us/step - loss: 266.2550 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 295.4454 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 265.6218 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 788us/step - loss: 272.4756 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 268.8217 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 275.1234 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 776us/step - loss: 273.3696 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 251.4198 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 782us/step - loss: 284.1204 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 771us/step - loss: 296.0432 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 854us/step - loss: 254.5304 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 769us/step - loss: 288.3564 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 258.3708 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 862us/step - loss: 284.8920 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 847us/step - loss: 282.1798 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 761us/step - loss: 273.8409 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 268.1801 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 864us/step - loss: 262.7126 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 844us/step - loss: 281.3784 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 840us/step - loss: 254.8136 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 851us/step - loss: 265.6973 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 877us/step - loss: 294.2164 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 896us/step - loss: 255.0127 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 800us/step - loss: 303.5483 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 299.8247 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 813us/step - loss: 286.9128 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 304.2150 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 250.6853 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 771us/step - loss: 287.8471 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 848us/step - loss: 302.4630 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 760us/step - loss: 292.3991 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 814us/step - loss: 279.2758 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 786us/step - loss: 271.7485 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 734us/step - loss: 254.6814 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 734us/step - loss: 262.1497 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 784us/step - loss: 273.7787 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 731us/step - loss: 297.4860 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 763us/step - loss: 255.8240 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 785us/step - loss: 264.4663 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 776us/step - loss: 269.6900 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 778us/step - loss: 268.2503 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 272.2826 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 760us/step - loss: 282.7889 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 760us/step - loss: 296.8007 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 766us/step - loss: 269.8621 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 741us/step - loss: 257.7986 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 839us/step - loss: 285.9463 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 299.8327 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 250.3547 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af242a6208>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.8785]\n",
      " [13.6153]\n",
      " [13.1136]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 16.8752\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 745us/step - loss: 16.3317\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 766us/step - loss: 15.9951\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 783us/step - loss: 15.7547\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 770us/step - loss: 15.3440\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 775us/step - loss: 15.2604\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 758us/step - loss: 14.4338\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 800us/step - loss: 13.9913\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 806us/step - loss: 13.7956\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 770us/step - loss: 13.4526\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 771us/step - loss: 13.4771\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 750us/step - loss: 13.5163\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 768us/step - loss: 13.6185\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 770us/step - loss: 13.6863\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 769us/step - loss: 13.2242\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 770us/step - loss: 12.7787\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 778us/step - loss: 13.5086\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 771us/step - loss: 12.8674\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 776us/step - loss: 12.6198\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 759us/step - loss: 12.7279\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 761us/step - loss: 12.4088\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 777us/step - loss: 12.7167\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 766us/step - loss: 12.4821\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 779us/step - loss: 12.3151\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 782us/step - loss: 12.7520\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 768us/step - loss: 12.3459\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 768us/step - loss: 12.1900\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 12.4106\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 760us/step - loss: 11.9037\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 800us/step - loss: 12.4140\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 764us/step - loss: 12.4294\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 899us/step - loss: 13.0258\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 774us/step - loss: 12.7984\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 807us/step - loss: 12.4304\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 776us/step - loss: 12.6044\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 774us/step - loss: 12.5414\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 803us/step - loss: 11.8790\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 784us/step - loss: 13.2049\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 766us/step - loss: 12.5765\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 768us/step - loss: 12.4120\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 922us/step - loss: 12.5343\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 849us/step - loss: 12.7027\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 752us/step - loss: 12.4696\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 703us/step - loss: 12.4654\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 714us/step - loss: 12.1972\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 694us/step - loss: 12.8492\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 678us/step - loss: 12.1723\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 12.1760\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 12.6491\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 697us/step - loss: 12.4039\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 12.5907\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 637us/step - loss: 12.5397\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 618us/step - loss: 12.6431\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 638us/step - loss: 12.3307\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 612us/step - loss: 12.4595\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 12.3029\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 12.0428\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 12.9367\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 12.2998\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 13.0555\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 12.0210\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 762us/step - loss: 12.5727\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 713us/step - loss: 12.2878\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 631us/step - loss: 12.2673\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 705us/step - loss: 11.9871\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 638us/step - loss: 12.1970\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 703us/step - loss: 12.2799\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 13.2346\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 12.0865\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 718us/step - loss: 12.1244\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 12.4408\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 12.6962\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 689us/step - loss: 12.3211\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 11.9611\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 11.7053\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 12.4610\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 12.1103\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 11.7669\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 12.4059\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 638us/step - loss: 12.5300\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 12.3897\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 11.6377\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 12.7115\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 11.7790\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 12.0860\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 11.4855\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 11.5593\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 11.6446\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 676us/step - loss: 12.7995\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 12.3369\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 12.7935\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 11.8998\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 694us/step - loss: 12.7240\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 625us/step - loss: 12.9453\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 12.4494\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 12.3683\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 683us/step - loss: 12.3598\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 634us/step - loss: 13.1041\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 643us/step - loss: 12.4992\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 12.7736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af25c3a4e0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.9244]\n",
      " [13.2762]\n",
      " [13.7609]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0900 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0900 = pd.DataFrame()\n",
    "data_0900 = FUNCTION_1(data = data3, dataframe_new = data_0900, time = \"09:00:00\")\n",
    "data_0900_train = FUNCTION_2(data_0900, time=\"09:00:00\")[0]\n",
    "data_0900_test = FUNCTION_2(data_0900, time=\"09:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_0900_train[data_0700_train.columns[2:]].values\n",
    "X_test = data_0900_test[data_0700_test.columns[2:]].values\n",
    "\n",
    "y_train = data_0900_train[\"Value\"].values\n",
    "y_test = data_0900_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 1372.7031 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 681us/step - loss: 1342.2871 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 1320.4399 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 1257.6800 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 1171.5032 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 643us/step - loss: 1146.0041 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 1115.6117 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 1083.1721 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 717us/step - loss: 1048.5956 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 992.7323 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 676us/step - loss: 980.9455 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 1062.0701 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 999.7162 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 699us/step - loss: 1028.1742 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 638us/step - loss: 974.2664 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 901.2061 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 966.5127 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 633us/step - loss: 948.7129 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 715us/step - loss: 937.0054 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 847.0802 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 712us/step - loss: 1027.9736 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 628us/step - loss: 880.1190 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 691us/step - loss: 939.8155 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 965.5700 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 713us/step - loss: 912.7737 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 628us/step - loss: 877.6676 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 888.8458 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 639us/step - loss: 967.6614 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 681us/step - loss: 865.4640 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 967.0709 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 831.3630 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 914.8033 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 920.7077 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 712us/step - loss: 929.5345 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 901.1563 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 694us/step - loss: 964.0793 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 872.6227 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 705us/step - loss: 890.9697 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 842.3953 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 700us/step - loss: 949.1439 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 627us/step - loss: 857.3332 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 957.0596 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 801.3382 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 838.0086 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 683us/step - loss: 831.5174 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 902.7690 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 695us/step - loss: 851.2137 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 804.0952 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 880.2482 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 845.9417 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 886.9064 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 900.9465 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 923.9469 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 860.9353 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 704us/step - loss: 831.8628 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 858.3757 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 696us/step - loss: 782.1796 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 923.4921 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 693us/step - loss: 871.5585 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 637us/step - loss: 815.4479 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 678us/step - loss: 890.1346 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 638us/step - loss: 908.7041 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 833.1782 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 959.1443 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 642us/step - loss: 812.7215 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 798.3279 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 904.7813 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 689us/step - loss: 889.8559 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 707us/step - loss: 806.2463 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 822.8172 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 816.6591 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 791.0724 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 895.5466 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 717us/step - loss: 865.8389 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 912.4584 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 880.6774 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 635us/step - loss: 875.7756 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 895.5500 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 904.1872 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 831.2886 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 717us/step - loss: 831.0652 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 834.2088 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 678us/step - loss: 877.4235 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 810.4685 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 951.6920 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 918.6949 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 688us/step - loss: 842.6542 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 846.2353 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 889.8229 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 920.6225 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 914.3950 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 895.2899 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 877.2308 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 704us/step - loss: 837.2101 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 963.6684 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 823.2473 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 684us/step - loss: 949.9209 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 615us/step - loss: 893.7321 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 717us/step - loss: 880.1961 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 886.2295 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af28560dd8>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.5814]\n",
      " [20.293 ]\n",
      " [20.9532]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 1ms/step - loss: 33.3674\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 33.0050\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 32.4661\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 624us/step - loss: 32.0191\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 632us/step - loss: 31.4533\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 30.7866\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 29.9618\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 29.7448\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 28.5551\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 28.3609\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 28.6522\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 27.9246\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 27.5935\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 27.2118\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 26.7033\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 625us/step - loss: 25.9454\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 25.5313\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 633us/step - loss: 25.6716\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 678us/step - loss: 26.2815\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 25.9950\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 624us/step - loss: 25.7183\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 24.4073\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 25.3963\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 642us/step - loss: 24.5697\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 26.2149\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 26.3405\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 619us/step - loss: 24.3015\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 24.7928\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 628us/step - loss: 24.3638\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 681us/step - loss: 26.4049\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 602us/step - loss: 24.8418\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 25.0633\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 643us/step - loss: 24.9563\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 633us/step - loss: 24.7550\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 24.7623\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 24.9247\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 635us/step - loss: 23.9823\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 23.8287\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 23.6653\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 25.3829\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 627us/step - loss: 24.0296\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 24.8291\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 25.3905\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 631us/step - loss: 23.1037\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 24.8074\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 23.3601\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 623us/step - loss: 23.9840\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 23.6144\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 643us/step - loss: 23.9967\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 23.0871\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 625us/step - loss: 23.9836\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 22.2262\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 622us/step - loss: 22.9419\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 24.7569\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 23.1512\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 24.6100\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 23.4005\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 612us/step - loss: 24.2653\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 24.3300\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 24.9196\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 24.5780\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 622us/step - loss: 25.0955\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 22.9762\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 23.6374\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 625us/step - loss: 23.3557\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 21.6450\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 23.0444\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 24.5936\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 643us/step - loss: 24.6628\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 627us/step - loss: 23.8057\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 24.6238\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 24.3035\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 23.1094\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 625us/step - loss: 22.3981\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 24.0994\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 621us/step - loss: 24.8223\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 22.5630\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 631us/step - loss: 23.7946\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 623us/step - loss: 23.0916\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 23.7550\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 22.5876\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 24.0492\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 23.4158\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 614us/step - loss: 23.9392\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 24.3819\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 618us/step - loss: 22.8889\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 616us/step - loss: 23.2631\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 693us/step - loss: 24.2937\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 22.8703\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 24.2825\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 22.4197\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 643us/step - loss: 22.8595\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 25.0193\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 23.6204\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 21.7343\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 23.6848\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 619us/step - loss: 22.7298\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 22.9126\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 23.9848\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 23.1376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af1fffa668>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13.2194]\n",
      " [22.157 ]\n",
      " [22.2848]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1000 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1000 = pd.DataFrame()\n",
    "data_1000 = FUNCTION_1(data = data3, dataframe_new = data_1000, time = \"10:00:00\")\n",
    "data_1000_train = FUNCTION_2(data_1000, time=\"10:00:00\")[0]\n",
    "data_1000_test = FUNCTION_2(data_1000, time=\"10:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_1000_train[data_1000_train.columns[2:]].values\n",
    "X_test = data_1000_test[data_1000_test.columns[2:]].values\n",
    "\n",
    "y_train = data_1000_train[\"Value\"].values\n",
    "y_test = data_1000_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 1ms/step - loss: 2768.7514\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 699us/step - loss: 2732.4818\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 637us/step - loss: 2687.2014\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 637us/step - loss: 2649.0828\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 639us/step - loss: 2638.7189\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 604us/step - loss: 2533.8766\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 624us/step - loss: 2494.9466\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 633us/step - loss: 2347.2778\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 620us/step - loss: 2327.0927\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 629us/step - loss: 2249.8594\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 2276.1018\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 2125.7359\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 711us/step - loss: 2187.7256\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 627us/step - loss: 2151.7501\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 681us/step - loss: 2032.8984\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 2077.7443\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 2196.7386\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 1964.4160\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 629us/step - loss: 1993.6335\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 2016.8229\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 2061.2857\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 1979.2281\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 1939.3079\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 1930.8959\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 1939.7887\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 1913.4965\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 676us/step - loss: 1825.1905\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 1848.4816\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 1753.8524\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 1879.7172\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 1795.9674\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 1846.5801\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 1911.5060\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 1844.4178\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 1865.5928\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 1680.2595\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 1703.0360\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 1964.3375\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 1836.4130\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 1704.1463\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 1858.3682\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 1683.8910\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 1730.0338\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 1802.4335\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 1834.6258\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 1608.1338\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 617us/step - loss: 1719.7572\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 1807.8840\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 1601.2534\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 1809.6750\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 1907.4351\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 1642.6110\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 684us/step - loss: 1548.8767\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 1653.7890\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 1802.0995\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 1648.8136\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 724us/step - loss: 1778.0429\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 779us/step - loss: 1932.4546\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 1619.3473\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 676us/step - loss: 1751.0180\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 1708.8325\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 1791.2677\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 633us/step - loss: 1869.5217\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 610us/step - loss: 1829.3269\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 1499.5588\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 1776.2849\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 1830.3894\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 1843.6114\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 617us/step - loss: 1843.5879\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 764us/step - loss: 1831.3173\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 1788.0900\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 630us/step - loss: 1710.8673\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 1730.2518\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 634us/step - loss: 1705.8136\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 1767.5158\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 620us/step - loss: 1610.5820\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 1747.9174\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 624us/step - loss: 1735.9645\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 692us/step - loss: 1649.5524\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 1658.7217\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 605us/step - loss: 1615.3876\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 1587.2744\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 1609.0812\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 622us/step - loss: 1716.1626\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 1696.9727\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 1604.9578\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 1682.0060\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 633us/step - loss: 1730.3558\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 1800.8553\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 634us/step - loss: 1484.7914\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 681us/step - loss: 1834.2397\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 642us/step - loss: 1702.2482\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 1806.6662\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 692us/step - loss: 1610.8394\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 609us/step - loss: 1741.6944\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 1737.8485\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 639us/step - loss: 1732.5113\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 1690.3372\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 1616.1308\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 633us/step - loss: 1597.9610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af2a8e8048>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20.0705]\n",
      " [26.3298]\n",
      " [26.31  ]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 48.4130\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 47.9447\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 613us/step - loss: 47.4997\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 632us/step - loss: 46.7679\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 631us/step - loss: 46.1498\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 45.7412\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 600us/step - loss: 44.7146\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 44.0728\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 43.2120\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 43.0890\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 42.4039\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 41.5856\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 629us/step - loss: 40.7389\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 685us/step - loss: 40.2441\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 628us/step - loss: 40.4549\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 643us/step - loss: 40.8617\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 38.8602\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 39.3056\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 625us/step - loss: 39.0030\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 39.3411\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 38.7615\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 621us/step - loss: 37.8140\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 613us/step - loss: 36.8082\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 36.7645\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 37.0380\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 622us/step - loss: 36.7330\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 35.9590\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 36.2856\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 36.8116\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 628us/step - loss: 37.9727\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 642us/step - loss: 36.5607\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 643us/step - loss: 37.0495\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 619us/step - loss: 35.5419\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 35.8967\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 619us/step - loss: 34.7327\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 627us/step - loss: 36.3849\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 642us/step - loss: 37.7265\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 36.2612\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 637us/step - loss: 34.7096\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 642us/step - loss: 34.3176\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 642us/step - loss: 35.9830\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 636us/step - loss: 36.2967\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 35.8740\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 37.4175\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 35.1635\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 35.3496\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 34.5428\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 634us/step - loss: 35.2676\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 625us/step - loss: 35.3949\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 33.7779\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 34.4231\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 36.6881\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 601us/step - loss: 34.4637\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 32.9576\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 615us/step - loss: 35.4131\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 678us/step - loss: 35.6200\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 35.4360\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 614us/step - loss: 34.5184\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 33.4550\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 32.9882\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 683us/step - loss: 35.0037\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 34.9535\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 32.9746\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 34.6829\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 634us/step - loss: 33.2718\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 33.6966\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 32.1421\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 587us/step - loss: 33.7890\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 32.9134\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 35.6060\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 34.1098\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 638us/step - loss: 33.8940\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 643us/step - loss: 34.8150\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 631us/step - loss: 34.5775\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 685us/step - loss: 34.5152\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 35.5072\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 32.6286\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 636us/step - loss: 32.2928\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 632us/step - loss: 32.9420\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 35.2906\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 630us/step - loss: 34.9475\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 622us/step - loss: 34.3082\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 594us/step - loss: 33.5830\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 33.3489\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 617us/step - loss: 34.0378\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 35.4010\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 33.9061\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 34.0043\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 634us/step - loss: 34.3694\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 33.5146\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 638us/step - loss: 34.0801\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 34.0959\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 613us/step - loss: 35.1527\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 34.6796\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 32.2994\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 34.3461\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 33.3615\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 34.2921\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 614us/step - loss: 34.6681\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 625us/step - loss: 31.8148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af2c24b6d8>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21.5355]\n",
      " [26.9616]\n",
      " [27.2949]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1100 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1100 = pd.DataFrame()\n",
    "data_1100 = FUNCTION_1(data = data3, dataframe_new = data_1100, time = \"11:00:00\")\n",
    "data_1100_train = FUNCTION_2(data_1100, time=\"11:00:00\")[0]\n",
    "data_1100_test = FUNCTION_2(data_1100, time=\"11:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_1100_train[data_1100_train.columns[2:]].values\n",
    "X_test = data_1100_test[data_1100_test.columns[2:]].values\n",
    "\n",
    "y_train = data_1100_train[\"Value\"].values\n",
    "y_test = data_1100_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4158.3076\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 634us/step - loss: 4072.9340\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 4008.0933\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 625us/step - loss: 3951.8274\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 3867.0541\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 615us/step - loss: 3758.8259\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 3686.8731\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 3571.1805\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 3555.7472\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 3467.5689\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 3458.4550\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 715us/step - loss: 3415.5691\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 637us/step - loss: 3371.1211\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 3324.2292\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 3236.3425\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 744us/step - loss: 3204.9711\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 3131.9142\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 691us/step - loss: 3194.3927\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 3074.4016\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 702us/step - loss: 2903.8416\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 690us/step - loss: 3104.6565\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 624us/step - loss: 3078.6714\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 2947.0824\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 3012.8359\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 2597.9643\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 711us/step - loss: 2943.5380\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 2761.5247\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 2836.3754\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 678us/step - loss: 2711.4148\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 2682.0881\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 676us/step - loss: 2733.3590\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 638us/step - loss: 2727.5291\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 2797.3969\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 2717.2939\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 2757.3427\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 2806.9225\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 2614.2615\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 706us/step - loss: 2603.1333\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 638us/step - loss: 2467.4113\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 2526.9113\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 2647.3039\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 2587.5761\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 2701.4523\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 2550.5290\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 2494.1376\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 2698.4578\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 712us/step - loss: 2589.9287\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 634us/step - loss: 2424.7475\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 2606.8656\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 683us/step - loss: 2562.5418\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 2505.9654\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 2810.7218\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 2413.0773\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 2682.2893\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 688us/step - loss: 2690.1082\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 2495.3023\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 2520.5508\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 2342.6956\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 628us/step - loss: 2613.1906\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 2484.0551\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 2538.1697\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 709us/step - loss: 2531.2019\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 2421.8641\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 2476.1498\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 676us/step - loss: 2298.5248\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 2649.6525\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 756us/step - loss: 2549.7871\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 694us/step - loss: 2578.4309\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 2372.7399\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 2516.6864\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 676us/step - loss: 2524.2951\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 638us/step - loss: 2353.4201\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 2242.8940\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 632us/step - loss: 2440.5821\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 2468.1157\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 2531.7932\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 623us/step - loss: 2359.6394\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 2424.1796\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 2515.0611\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 2437.9705\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 638us/step - loss: 2409.3225\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 2385.7876\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 615us/step - loss: 2469.1757\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 630us/step - loss: 2656.6683\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 2393.7839\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 676us/step - loss: 2410.4767\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 2298.7241\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 2231.9207\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 2636.7640\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 2160.1616\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 2653.7247\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 2650.2090\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 2285.1995\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 2236.1755\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 625us/step - loss: 2472.9140\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 2675.3277\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 2199.8325\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 2459.0077\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 2346.5638\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 708us/step - loss: 2537.5230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af2cbdeeb8>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28.5432]\n",
      " [28.5445]\n",
      " [28.5422]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 58.5515\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 58.1268\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 699us/step - loss: 57.6603\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 597us/step - loss: 57.0323\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 639us/step - loss: 56.3488\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 55.8307\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 54.8545\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 637us/step - loss: 53.5706\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 619us/step - loss: 51.7209\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 51.9567\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 50.9591\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 683us/step - loss: 50.7607\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 50.4918\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 642us/step - loss: 49.7596\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 49.6098\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 619us/step - loss: 48.9720\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 49.2595\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 48.6296\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 622us/step - loss: 47.8629\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 46.8330\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 47.9958\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 630us/step - loss: 48.5022\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 46.8248\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 643us/step - loss: 47.1157\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 639us/step - loss: 46.0347\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 47.1463\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 593us/step - loss: 45.1835\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 623us/step - loss: 46.0958\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 45.3045\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 626us/step - loss: 45.8223\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 44.4559\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 594us/step - loss: 45.4685\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 46.9672\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 43.7133\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 627us/step - loss: 42.9028\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 626us/step - loss: 44.5556\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 43.0507\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 43.9054\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 44.1563\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 629us/step - loss: 42.2474\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 44.0464\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 43.1710\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 616us/step - loss: 43.2010\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 43.5384\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 613us/step - loss: 41.6891\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 42.6298\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 579us/step - loss: 40.4843\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 42.1392\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 42.3750\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 626us/step - loss: 41.2767\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 42.1136\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 632us/step - loss: 41.8118\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 41.0557\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 625us/step - loss: 41.4330\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 41.8315\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 38.7200\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 625us/step - loss: 40.6795\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 41.7757\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 42.9451\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 681us/step - loss: 40.3251\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 41.0099\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 621us/step - loss: 41.1166\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 41.5868\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 41.4309\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 638us/step - loss: 39.5439\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 616us/step - loss: 42.4329\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 38.6969\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 43.1145\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 39.8721\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 629us/step - loss: 40.4873\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 39.7882\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 39.1310\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 638us/step - loss: 41.8973\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 681us/step - loss: 41.9175\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 41.0557\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 622us/step - loss: 41.4137\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 39.6662\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 618us/step - loss: 40.9984\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 37.0563\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 629us/step - loss: 43.2347\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 602us/step - loss: 39.8231\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 39.5924\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 625us/step - loss: 39.9795\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 38.8918\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 41.8431\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 40.0082\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 589us/step - loss: 39.6427\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 636us/step - loss: 39.9941\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 624us/step - loss: 37.9782\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 38.7073\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 627us/step - loss: 41.2235\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 628us/step - loss: 39.8249\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 41.8663\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 622us/step - loss: 42.1189\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 38.9079\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 43.5105\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 40.3002\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 40.2865\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 630us/step - loss: 42.1404\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 39.0926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af2e53c048>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30.9349]\n",
      " [31.1537]\n",
      " [31.0268]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1200 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1200 = pd.DataFrame()\n",
    "data_1200 = FUNCTION_1(data = data3, dataframe_new = data_1200, time = \"12:00:00\")\n",
    "data_1200_train = FUNCTION_2(data_1200, time=\"12:00:00\")[0]\n",
    "data_1200_test = FUNCTION_2(data_1200, time=\"12:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_1200_train[data_1200_train.columns[2:]].values\n",
    "X_test = data_1200_test[data_1200_test.columns[2:]].values\n",
    "\n",
    "y_train = data_1200_train[\"Value\"].values\n",
    "y_test = data_1200_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4481.9561\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 4399.1030\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 702us/step - loss: 4336.0662\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 621us/step - loss: 4294.4497\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 4179.0277\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 4088.5734\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 712us/step - loss: 3999.5451\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 3942.9622\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 700us/step - loss: 3916.4844\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 626us/step - loss: 3800.8840\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 3622.5084\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 3615.6127\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 3579.3082\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 3590.3141\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 3594.8678\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 3490.1060\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 3525.7152\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 3463.4758\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 3293.0233\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 681us/step - loss: 3339.1911\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 3310.5756\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 3120.2264\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 3157.0281\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 3199.0602\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 3131.1056\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 3099.3589\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 3228.6014\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 2967.4531\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 2934.6476\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 3045.2342\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 3027.0707\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 3094.5758\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 2735.3196\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 3140.3324\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 2927.0395\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 2859.8450\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 2990.9349\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 3018.1045\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 2944.1644\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 698us/step - loss: 2879.9449\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 2785.9156\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 3018.2652\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 2657.1519\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 2830.6892\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 2874.8292\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 2897.7036\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 714us/step - loss: 2763.9757\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 631us/step - loss: 2696.6237\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 2718.2626\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 2789.3726\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 2780.6013\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 694us/step - loss: 2752.0997\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 643us/step - loss: 2848.0513\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 2761.2670\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 2763.6127\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 630us/step - loss: 2690.5162\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 2805.6669\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 630us/step - loss: 2785.8232\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 688us/step - loss: 2626.2495\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 2750.0037\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 628us/step - loss: 2637.2749\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 2954.5012\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 2585.0158\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 2891.4626\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 2599.5341\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 2882.0303\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 622us/step - loss: 2505.9873\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 629us/step - loss: 2690.8322\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 2731.3339\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 2708.3606\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 632us/step - loss: 2682.7307\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 2660.0516\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 2871.3113\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 643us/step - loss: 2636.7748\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 2530.8064\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 2590.8967\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 2478.1750\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 634us/step - loss: 2746.7265\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 2654.0531\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 2786.8667\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 622us/step - loss: 2651.6676\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 688us/step - loss: 2465.9002\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 2781.9015\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 2587.5811\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 606us/step - loss: 2622.1734\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 2930.8809\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 628us/step - loss: 2801.0878\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 2611.5068\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 2743.3193\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 636us/step - loss: 2747.7734\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 2896.3574\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 627us/step - loss: 2656.3883\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 685us/step - loss: 2739.0702\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 2747.0548\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 643us/step - loss: 2659.3691\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 2476.5010\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 2747.3856\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 2742.1086\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 2827.6142\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 2629.1544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af2fe7c048>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29.7649]\n",
      " [29.7651]\n",
      " [29.7648]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 62.1196\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 703us/step - loss: 61.8429\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 61.3974\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 627us/step - loss: 60.7396\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 60.1149\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 695us/step - loss: 59.6269\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 59.0596\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 58.2335\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 57.3146\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 57.3221\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 694us/step - loss: 56.8846\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 56.3530\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 55.7097\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 55.7528\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 54.6281\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 54.9834\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 54.1312\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 53.7350\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 630us/step - loss: 53.3389\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 612us/step - loss: 52.2499\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 690us/step - loss: 52.7977\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 623us/step - loss: 52.0333\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 50.7585\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 50.2704\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 48.2605\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 622us/step - loss: 49.3819\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 618us/step - loss: 51.0429\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 683us/step - loss: 49.5301\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 639us/step - loss: 48.5634\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 49.4299\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 48.5230\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 49.5773\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 47.3896\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 685us/step - loss: 47.3791\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 46.6370\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 47.7661\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 47.2125\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 45.1290\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 628us/step - loss: 45.2403\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 46.2550\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 44.5276\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 46.5629\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 44.4327\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 45.6315\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 737us/step - loss: 45.9487\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 699us/step - loss: 44.4936\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 699us/step - loss: 45.0807\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 41.5979\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 44.5515\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 43.4588\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 42.6855\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 45.4666\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 638us/step - loss: 43.5132\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 44.6462\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 683us/step - loss: 44.5617\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 44.1974\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 43.0567\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 638us/step - loss: 43.4868\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 42.0134\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 642us/step - loss: 42.2984\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 689us/step - loss: 43.0211\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 43.8173\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 635us/step - loss: 43.7562\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 41.6691\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 678us/step - loss: 43.1137\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 42.5260\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 43.4381\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 684us/step - loss: 42.9580\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 618us/step - loss: 42.1616\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 43.0146\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 42.6934\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 702us/step - loss: 43.6081\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 631us/step - loss: 40.1408\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 43.1923\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 43.5864\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 42.6524\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 42.6094\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 43.9610\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 42.7327\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 41.6512\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 41.4309\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 45.3991\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 41.8568\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 43.5394\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 42.0355\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 688us/step - loss: 44.4114\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 43.0192\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 638us/step - loss: 42.5280\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 43.3279\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 639us/step - loss: 42.2314\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 41.7361\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 40.8153\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 720us/step - loss: 41.0203\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 40.3363\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 40.6940\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 43.8224\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 42.7679\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 629us/step - loss: 46.1724\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 676us/step - loss: 42.4587\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 42.3791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af317f1e10>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32.4602]\n",
      " [32.4604]\n",
      " [32.4601]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1300 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1300 = pd.DataFrame()\n",
    "data_1300 = FUNCTION_1(data = data3, dataframe_new = data_1300, time = \"13:00:00\")\n",
    "data_1300_train = FUNCTION_2(data_1300, time=\"13:00:00\")[0]\n",
    "data_1300_test = FUNCTION_2(data_1300, time=\"13:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_1300_train[data_1300_train.columns[2:]].values\n",
    "X_test = data_1300_test[data_0800_test.columns[2:]].values\n",
    "\n",
    "y_train = data_1300_train[\"Value\"].values\n",
    "y_test = data_1300_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 4288.6428\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 698us/step - loss: 4232.9631\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 4174.5353\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 590us/step - loss: 4057.9371\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 639us/step - loss: 3980.0463\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 3871.3565\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 3820.2284\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 3639.6628\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 3669.8267\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 3514.1771\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 3558.0385\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 3478.5975\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 3304.6349\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 3296.2548\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 3294.7502\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 642us/step - loss: 3120.0486\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 713us/step - loss: 3095.3897\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 3160.0101\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 3092.2878\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 3027.7144\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 890us/step - loss: 2967.6826\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 893us/step - loss: 3091.0073\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 3003.2444\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 869us/step - loss: 2911.7987\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 853us/step - loss: 3030.4975\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 908us/step - loss: 2733.9153\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 822us/step - loss: 2965.3071\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 2786.9559\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 2738.4569\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 802us/step - loss: 2729.0508\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 928us/step - loss: 2886.4120\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 824us/step - loss: 2819.9371\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 869us/step - loss: 2879.2253\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 968us/step - loss: 2649.9620\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 856us/step - loss: 2655.0510\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 729us/step - loss: 2743.5220\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 2771.3764\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 727us/step - loss: 2603.0227\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 704us/step - loss: 2878.4577\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 706us/step - loss: 2502.7467\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 2704.6762\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 2508.9808\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 2551.5493\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 2639.9874\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 2512.1477\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 2493.0437\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 2559.2903\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 2603.8627\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 634us/step - loss: 2437.9158\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 2467.8384\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 689us/step - loss: 2450.8385\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 2513.4142\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 696us/step - loss: 2432.8148\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 2597.3418\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 690us/step - loss: 2419.8904\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 2646.5728\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 2678.9234\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 2510.2157\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 2345.3185\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 2430.5698\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 2278.9043\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 2721.7859\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 627us/step - loss: 2717.7997\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 2418.8228\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 2721.5592\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 616us/step - loss: 2408.8801\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 643us/step - loss: 2449.2299\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 696us/step - loss: 2558.9784\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 2437.2384\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 2501.5010\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 639us/step - loss: 2458.8486\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 678us/step - loss: 2473.9246\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 2494.4427\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 2747.8613\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 643us/step - loss: 2661.5959\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 2622.6672\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 2553.5734\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 2479.3384\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 743us/step - loss: 2304.6709\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 2525.3389\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 2588.4579\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 707us/step - loss: 2572.4660\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 739us/step - loss: 2563.8060\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 685us/step - loss: 2582.6121\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 2661.0861\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 2682.6935\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 2608.3314\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 2567.7687\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 629us/step - loss: 2393.2199\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 2619.1109\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 642us/step - loss: 2764.1699\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 621us/step - loss: 2619.8653\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 694us/step - loss: 2607.8301\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 2423.5566\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 702us/step - loss: 2264.3165\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 2399.4513\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 828us/step - loss: 2351.5778\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 721us/step - loss: 2681.9388\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 709us/step - loss: 2549.7754\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 690us/step - loss: 2342.0342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af331765c0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28.9212]\n",
      " [28.9219]\n",
      " [28.9215]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 59.8329\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 59.3277\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 629us/step - loss: 58.8691\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 58.0937\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 599us/step - loss: 57.7662\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 57.3332\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 609us/step - loss: 56.7712\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 769us/step - loss: 55.6510\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 54.4143\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 53.5156\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 693us/step - loss: 53.6237\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 52.6846\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 632us/step - loss: 52.3857\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 703us/step - loss: 52.1493\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 51.1139\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 51.4587\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 49.8064\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 48.2626\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 678us/step - loss: 48.3174\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 47.6917\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 47.1142\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 47.9685\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 47.8149\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 635us/step - loss: 47.8110\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 46.3472\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 628us/step - loss: 46.2612\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 619us/step - loss: 46.0196\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 45.1542\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 623us/step - loss: 44.6300\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 45.1161\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 605us/step - loss: 45.6660\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 634us/step - loss: 45.3185\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 44.4075\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 43.8994\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 633us/step - loss: 46.7698\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 45.6198\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 643us/step - loss: 44.2302\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 40.6365\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 630us/step - loss: 46.4573\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 44.7277\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 632us/step - loss: 43.6200\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 678us/step - loss: 42.9608\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 702us/step - loss: 43.8671\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 632us/step - loss: 45.3848\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 42.1865\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 620us/step - loss: 41.7503\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 41.2515\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 642us/step - loss: 43.9574\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 639us/step - loss: 44.0804\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 41.3711\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 639us/step - loss: 43.5374\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 621us/step - loss: 40.2816\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 41.5657\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 43.1135\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 642us/step - loss: 45.1186\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 642us/step - loss: 40.9856\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 43.0281\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 40.4735\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 38.8822\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 41.5514\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 41.3514\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 41.2254\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 40.7456\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 689us/step - loss: 41.0802\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 41.8654\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 41.4675\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 41.1388\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 639us/step - loss: 42.2127\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 690us/step - loss: 43.4881\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 42.6827\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 39.8638\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 630us/step - loss: 42.2513\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 43.1127\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 40.5976\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 629us/step - loss: 40.3632\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 43.0567\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 712us/step - loss: 41.0470\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 623us/step - loss: 40.8153\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 40.4485\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 40.7331\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 628us/step - loss: 42.6582\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 635us/step - loss: 41.9614\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 625us/step - loss: 43.8833\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 634us/step - loss: 40.9773\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 41.5155\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 607us/step - loss: 40.2695\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 40.9731\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 626us/step - loss: 41.2477\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 681us/step - loss: 41.9013\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 642us/step - loss: 39.9500\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 40.6724\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 40.9856\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 41.7413\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 41.3587\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 41.7712\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 41.5145\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 41.3064\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 633us/step - loss: 40.2936\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 42.3571\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 41.9042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af33af4d30>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31.358 ]\n",
      " [31.3583]\n",
      " [31.3581]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1400 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1400 = pd.DataFrame()\n",
    "data_1400 = FUNCTION_1(data = data3, dataframe_new = data_1400, time = \"14:00:00\")\n",
    "data_1400_train = FUNCTION_2(data_1400, time=\"14:00:00\")[0]\n",
    "data_1400_test = FUNCTION_2(data_1400, time=\"14:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_1400_train[data_1400_train.columns[2:]].values\n",
    "X_test = data_1400_test[data_1400_test.columns[2:]].values\n",
    "\n",
    "y_train = data_1400_train[\"Value\"].values\n",
    "y_test = data_1400_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 3411.4767\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 710us/step - loss: 3382.1713\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 3331.1677\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 911us/step - loss: 3255.8554\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 868us/step - loss: 3190.6822\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 852us/step - loss: 3150.4051\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 3089.3898\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2988.8017\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2905.0240\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2812.5499\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 875us/step - loss: 2820.0676\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 773us/step - loss: 2728.0014\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 683us/step - loss: 2740.3252\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 683us/step - loss: 2699.4628\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 681us/step - loss: 2522.7362\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 635us/step - loss: 2541.6895\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2582.3227\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2423.0807\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2446.3823\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 2462.1087\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 953us/step - loss: 2431.8463\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 947us/step - loss: 2434.0512\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 990us/step - loss: 2357.7759\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 2306.8301\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 857us/step - loss: 2279.9106\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2211.9681\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2150.6499\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2347.8619\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 864us/step - loss: 2141.2911\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 929us/step - loss: 2254.9107\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 698us/step - loss: 2185.4160\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 703us/step - loss: 2215.6315\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 701us/step - loss: 2227.5303\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 704us/step - loss: 2185.1983\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 893us/step - loss: 2138.4613\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2128.4764\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 1ms/step - loss: 2197.0632\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 965us/step - loss: 2071.8023\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 882us/step - loss: 2205.0757\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 872us/step - loss: 2139.1971\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 714us/step - loss: 2045.0343\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 678us/step - loss: 2137.6240\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 698us/step - loss: 2244.3063\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 695us/step - loss: 2142.2903\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 2077.6728\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 700us/step - loss: 1961.6257\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 713us/step - loss: 2244.8534\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 698us/step - loss: 2054.2313\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 717us/step - loss: 2119.1796\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 694us/step - loss: 2234.5485\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 706us/step - loss: 1934.9682\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 703us/step - loss: 2130.0503\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 693us/step - loss: 2113.6158\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 2146.9673\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 768us/step - loss: 1907.6228\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 731us/step - loss: 2121.4878\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 691us/step - loss: 2116.7851\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 690us/step - loss: 2052.7552\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 771us/step - loss: 2022.0098\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 915us/step - loss: 2276.5312\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 704us/step - loss: 2130.0391\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 2056.7213\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 700us/step - loss: 1914.1106\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 2127.1959\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 2095.2901\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 614us/step - loss: 1939.3657\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 2076.7251\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 2106.2705\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 684us/step - loss: 2095.3882\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 632us/step - loss: 2117.5548\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 2259.2967\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 2079.5707\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 1908.2988\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 2022.7193\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 618us/step - loss: 1991.0436\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 698us/step - loss: 1921.3640\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 2047.9563\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 2035.8850\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 2173.1462\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 620us/step - loss: 1889.2673\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 2000.5530\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 1979.8011\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 2106.7696\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 2083.4640\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 632us/step - loss: 2087.5000\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 681us/step - loss: 2085.8462\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 678us/step - loss: 2208.6943\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 2067.3200\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 2085.2894\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 594us/step - loss: 2124.0165\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 639us/step - loss: 1956.4485\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 621us/step - loss: 2016.9693\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 2013.1970\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 1863.8319\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 632us/step - loss: 2205.2107\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 634us/step - loss: 2113.3107\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 597us/step - loss: 2174.8775\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 607us/step - loss: 2028.4942\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 2224.1281\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 1933.9819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af36427278>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26.1008]\n",
      " [26.1017]\n",
      " [26.1015]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 53.3056\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 723us/step - loss: 52.5405\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 688us/step - loss: 52.0246\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 51.3478\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 50.3669\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 634us/step - loss: 50.2546\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 49.3072\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 48.3499\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 613us/step - loss: 47.4719\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 47.0930\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 721us/step - loss: 45.4735\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 45.8989\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 628us/step - loss: 44.7376\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 43.7370\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 643us/step - loss: 43.8568\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 43.3461\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 43.3341\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 633us/step - loss: 42.9653\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 637us/step - loss: 42.6772\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 630us/step - loss: 40.9182\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 41.7443\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 40.5339\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 643us/step - loss: 41.6266\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 40.7454\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 681us/step - loss: 41.7421\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 41.2003\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 40.7801\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 40.0451\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 643us/step - loss: 40.5028\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 40.2521\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 40.3578\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 39.8003\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 612us/step - loss: 39.1789\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 616us/step - loss: 39.0029\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 619us/step - loss: 39.2559\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 683us/step - loss: 37.5735\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 614us/step - loss: 37.6401\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 38.5570\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 38.7583\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 37.2925\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 39.7414\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 614us/step - loss: 39.6968\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 698us/step - loss: 36.2091\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 622us/step - loss: 37.3949\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 36.0775\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 629us/step - loss: 39.1032\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 621us/step - loss: 37.4130\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 36.6531\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 685us/step - loss: 38.2836\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 38.6356\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 627us/step - loss: 37.3053\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 684us/step - loss: 38.0002\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 701us/step - loss: 38.1686\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 719us/step - loss: 36.7973\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 37.3277\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 37.4673\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 716us/step - loss: 38.3792\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 37.1760\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 36.6055\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 36.2693\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 38.7805\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 34.9590\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 35.9466\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 37.2126\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 635us/step - loss: 36.0750\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 620us/step - loss: 35.0991\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 681us/step - loss: 37.0603\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 619us/step - loss: 39.2075\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 634us/step - loss: 34.2605\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 38.3243\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 626us/step - loss: 36.7337\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 633us/step - loss: 37.4060\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 627us/step - loss: 36.4914\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 683us/step - loss: 36.6889\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 636us/step - loss: 37.2548\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 689us/step - loss: 36.7542\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 633us/step - loss: 36.7821\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 676us/step - loss: 37.4208\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 34.6771\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 37.1340\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 35.1315\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 684us/step - loss: 39.5156\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 36.9079\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 626us/step - loss: 36.9955\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 691us/step - loss: 37.6355\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 621us/step - loss: 37.1214\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 38.0927\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 627us/step - loss: 38.7454\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 38.6550\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 36.3100\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 37.1404\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 36.7432\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 38.4799\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 629us/step - loss: 38.3630\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 638us/step - loss: 37.7719\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 36.3490\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 35.9863\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 633us/step - loss: 36.1900\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 38.1690\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 36.3400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af36dd8630>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26.2765]\n",
      " [27.8298]\n",
      " [27.8291]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1500 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1500 = pd.DataFrame()\n",
    "data_1500 = FUNCTION_1(data = data3, dataframe_new = data_1500, time = \"15:00:00\")\n",
    "data_1500_train = FUNCTION_2(data_1500, time=\"15:00:00\")[0]\n",
    "data_1500_test = FUNCTION_2(data_1500, time=\"15:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_1500_train[data_1500_train.columns[2:]].values\n",
    "X_test = data_1500_test[data_1500_test.columns[2:]].values\n",
    "\n",
    "y_train = data_1500_train[\"Value\"].values\n",
    "y_test = data_1500_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 2121.8121\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 2086.7279\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 2061.6955\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 2034.1292\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 1997.6279\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 1943.1763\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 1873.2543\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 1816.9844\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 1782.1677\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 710us/step - loss: 1721.9058\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 632us/step - loss: 1679.6542\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 1683.7199\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 642us/step - loss: 1642.1083\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 692us/step - loss: 1625.1659\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 1628.1334\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 698us/step - loss: 1517.2928\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 1517.5385\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 681us/step - loss: 1572.4451\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 1484.9314\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 1551.3073\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 1523.3879\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 714us/step - loss: 1354.3036\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 637us/step - loss: 1413.4267\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 1384.7230\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 703us/step - loss: 1417.7497\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 1369.1055\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 1502.4029\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 678us/step - loss: 1405.6148\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 1429.7866\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 1437.0011\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 713us/step - loss: 1462.1386\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 628us/step - loss: 1345.1979\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 636us/step - loss: 1409.0643\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 1383.7597\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 1396.6172\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 1366.6249\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 1255.7995\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 707us/step - loss: 1250.6627\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 704us/step - loss: 1319.3995\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 720us/step - loss: 1316.3548\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 1358.9033\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 688us/step - loss: 1482.9917\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 1385.0666\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 1318.5208\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 1470.9541\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 1372.3304\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 1376.8864\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 1400.0558\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 685us/step - loss: 1357.9087\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 681us/step - loss: 1445.9329\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 635us/step - loss: 1305.0849\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 683us/step - loss: 1285.7774\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 1400.5374\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 1291.3880\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 1414.8198\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 1317.9460\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 1328.2160\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 1345.3511\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 1376.0944\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 1185.0115\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 1427.3106\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 1272.3509\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 1364.4374\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 1133.1493\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 635us/step - loss: 1321.2326\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 1231.0422\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 639us/step - loss: 1282.3758\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 1432.9176\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 684us/step - loss: 1394.1924\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 1365.1544\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 1321.7617\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 1304.6361\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 620us/step - loss: 1386.5065\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 676us/step - loss: 1302.4860\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 625us/step - loss: 1371.0452\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 1418.2292\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 1400.2542\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 1293.7754\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 628us/step - loss: 1453.3131\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 1292.0786\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 1403.9939\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 1323.3515\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 1327.2650\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 620us/step - loss: 1372.0537\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 709us/step - loss: 1301.0134\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 627us/step - loss: 1298.0807\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 1294.4987\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 1409.4951\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 628us/step - loss: 1231.9312\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 678us/step - loss: 1476.3341\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 1333.6059\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 1263.3086\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 1235.8051\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 1396.3610\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 1212.0153\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 703us/step - loss: 1286.0177\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 1252.2674\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 623us/step - loss: 1181.8738\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 1312.4876\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 1337.2158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af38743b00>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15.1222]\n",
      " [23.5347]\n",
      " [23.5299]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 40.4370\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 701us/step - loss: 39.9482\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 39.4243\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 639us/step - loss: 39.1877\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 39.2397\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 38.5067\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 38.1250\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 638us/step - loss: 37.2938\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 37.1036\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 678us/step - loss: 36.4040\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 746us/step - loss: 34.7846\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 691us/step - loss: 34.6303\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 35.6059\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 702us/step - loss: 35.0572\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 740us/step - loss: 33.1988\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 716us/step - loss: 33.3832\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 33.4392\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 712us/step - loss: 32.7432\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 777us/step - loss: 32.4203\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 742us/step - loss: 33.2634\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 761us/step - loss: 32.0489\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 754us/step - loss: 30.4765\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 800us/step - loss: 31.2695\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 750us/step - loss: 32.6795\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 30.8206\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 716us/step - loss: 31.2722\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 718us/step - loss: 31.1542\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 30.7112\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 30.3468\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 29.5007\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 685us/step - loss: 29.7283\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 31.0993\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 29.9978\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 30.6252\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 723us/step - loss: 29.1743\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 30.9005\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 678us/step - loss: 29.6417\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 714us/step - loss: 29.7660\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 695us/step - loss: 30.1672\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 699us/step - loss: 29.6821\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 693us/step - loss: 29.1674\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 30.1721\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 685us/step - loss: 29.1280\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 685us/step - loss: 28.6567\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 727us/step - loss: 28.8699\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 637us/step - loss: 30.0612\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 642us/step - loss: 28.9956\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 30.8987\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 725us/step - loss: 29.6859\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 681us/step - loss: 27.7537\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 30.4780\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 761us/step - loss: 29.8100\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 31.1525\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 701us/step - loss: 31.2098\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 28.9189\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 30.3019\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 28.7845\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 29.8324\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 30.8801\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 27.9204\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 30.1863\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 30.1864\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 30.3759\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 29.9717\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 31.0440\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 29.3150\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 29.8229\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 28.0953\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 28.8110\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 634us/step - loss: 30.5436\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 685us/step - loss: 27.9997\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 29.9416\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 29.3546\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 29.9436\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 30.2228\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 720us/step - loss: 29.8958\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 697us/step - loss: 31.4639\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 29.3161\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 28.1613\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 703us/step - loss: 28.8548\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 694us/step - loss: 29.0921\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 678us/step - loss: 29.5061\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 29.1141\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 717us/step - loss: 31.8943\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - ETA: 0s - loss: 29.27 - 0s 789us/step - loss: 29.2733\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 724us/step - loss: 29.5117\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 29.5290\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 30.1073\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 716us/step - loss: 28.3449\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 28.9634\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 28.1954\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 29.1823\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 30.3596\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 28.2451\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 31.2533\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 0s 657us/step - loss: 28.7975\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 28.3953\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 712us/step - loss: 30.2599\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 632us/step - loss: 27.4687\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 28.6904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af390cf780>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17.2112]\n",
      " [24.6312]\n",
      " [24.6319]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1600 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1600 = pd.DataFrame()\n",
    "data_1600 = FUNCTION_1(data = data3, dataframe_new = data_1600, time = \"16:00:00\")\n",
    "data_1600_train = FUNCTION_2(data_1600, time=\"16:00:00\")[0]\n",
    "data_1600_test = FUNCTION_2(data_1600, time=\"16:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_1600_train[data_0800_train.columns[2:]].values\n",
    "X_test = data_1600_test[data_0800_test.columns[2:]].values\n",
    "\n",
    "y_train = data_1600_train[\"Value\"].values\n",
    "y_test = data_1600_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 885.8253\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 716us/step - loss: 863.8031\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 841.5846\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 798.8401\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 635us/step - loss: 771.6661\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 734.5853\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 699.0976\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 712us/step - loss: 649.9392\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 682.4943\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 652.5355\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 693us/step - loss: 637.2098\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 628us/step - loss: 665.8286\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 611.6834\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 633us/step - loss: 653.8716\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 606.0757\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 545.8661\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 635us/step - loss: 597.3052\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 614.0114\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 638us/step - loss: 625.5550\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 598.1415\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 584.9426\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 696us/step - loss: 622.7159\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 625us/step - loss: 581.3530\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 717us/step - loss: 572.5154\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 684us/step - loss: 575.9261\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 683us/step - loss: 582.3967\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 554.4194\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 695us/step - loss: 604.6289\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 570.2047\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 681us/step - loss: 538.9125\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 639us/step - loss: 589.6134\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 643us/step - loss: 635.3383\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 707us/step - loss: 535.8219\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 625us/step - loss: 545.3756\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 604.2014\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 721us/step - loss: 521.9298\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 544.2649\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 598.7051\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 555.4370\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 643us/step - loss: 590.7994\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 692us/step - loss: 562.6493\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 545.4078\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 586.2616\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 571.1700\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 634us/step - loss: 496.9108\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 510.3231\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 591.9081\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 572.0465\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 629us/step - loss: 522.7972\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 684us/step - loss: 561.4751\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 541.4253\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 518.7962\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 584.1962\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 720us/step - loss: 570.8581\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 723us/step - loss: 585.1653\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 639us/step - loss: 489.0622\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 701us/step - loss: 627.7185\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 690us/step - loss: 596.6109\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 578.4269\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 692us/step - loss: 529.2385\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 517.8841\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 602.5910\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 681us/step - loss: 568.5694\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 598.6902\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 630us/step - loss: 553.0464\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 693us/step - loss: 589.1869\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 598.9525\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 629us/step - loss: 571.5422\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 526.3118\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 507.9993\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 637us/step - loss: 525.7237\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 522.3251\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 733us/step - loss: 524.8700\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 529.8452\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 519.9453\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 621.8447\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 736us/step - loss: 538.5493\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 566.5812\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 527.1294\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 582.2240\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 546.5381\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 717us/step - loss: 505.8976\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 684us/step - loss: 512.3431\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 532.4143\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 558.3920\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 559.1953\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 622.1365\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 693us/step - loss: 551.9414\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 596.5101\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 544.5212\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 625us/step - loss: 596.9333\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 529.8635\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 638us/step - loss: 545.2866\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 643.3347\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 498.0150\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 688us/step - loss: 589.2107\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 692us/step - loss: 521.8690\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 621us/step - loss: 480.0235\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 514.1584\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 505.8524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af3a9d9c88>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.326 ]\n",
      " [18.0593]\n",
      " [18.2854]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 26.3063\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 25.4821\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 24.3808\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 633us/step - loss: 23.8994\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 23.1802\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 23.0195\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 631us/step - loss: 22.4737\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 692us/step - loss: 21.9052\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 622us/step - loss: 21.7174\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 21.1085\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 20.9155\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 21.5948\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 701us/step - loss: 20.8008\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 634us/step - loss: 20.2081\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 20.9059\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 688us/step - loss: 20.7793\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 20.6729\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 633us/step - loss: 20.0561\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 20.5845\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 20.3246\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 702us/step - loss: 20.4558\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 19.7767\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 19.3680\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 634us/step - loss: 19.9609\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 676us/step - loss: 19.0834\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 732us/step - loss: 19.3208\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 18.6996\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 18.5257\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 738us/step - loss: 18.9524\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 19.3245\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 718us/step - loss: 20.3183\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 19.2042\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 722us/step - loss: 19.0358\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 716us/step - loss: 18.3940\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 18.1577\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 19.3585\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 19.3130\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 18.8062\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 18.9897\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 18.4274\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 19.5920\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 746us/step - loss: 18.8986\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 18.5797\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 19.0106\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 639us/step - loss: 19.0178\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 18.5605\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 18.5456\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 18.9715\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 18.1414\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 18.7264\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 18.4584\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 627us/step - loss: 18.6529\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 685us/step - loss: 17.9095\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 19.0860\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 18.0468\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 19.4308\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 19.4835\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 17.4467\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 18.7533\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 18.3751\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 18.3924\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 18.8910\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 18.4065\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 626us/step - loss: 17.4186\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 16.9279\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 18.2866\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 18.7603\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 613us/step - loss: 17.6380\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 19.0928\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 618us/step - loss: 17.7566\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 18.1007\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 18.6358\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 18.7759\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 18.9208\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 18.1784\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 681us/step - loss: 17.3282\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 600us/step - loss: 18.2693\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 18.6363\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 690us/step - loss: 17.9669\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 642us/step - loss: 18.7476\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 17.8229\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 643us/step - loss: 17.6064\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 18.4513\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 632us/step - loss: 18.2729\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 624us/step - loss: 17.8564\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 17.6532\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 17.9372\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 18.0285\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 18.2083\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 590us/step - loss: 19.0477\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 634us/step - loss: 16.7511\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 676us/step - loss: 18.5412\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 743us/step - loss: 16.9234\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 812us/step - loss: 17.4357\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 764us/step - loss: 18.1074\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 17.6591\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 726us/step - loss: 17.4141\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 705us/step - loss: 18.1002\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 18.3357\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 17.7770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af3c397128>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.7886]\n",
      " [18.9369]\n",
      " [19.1256]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1700 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1700 = pd.DataFrame()\n",
    "data_1700 = FUNCTION_1(data = data3, dataframe_new = data_1700, time = \"17:00:00\")\n",
    "data_1700_train = FUNCTION_2(data_1700, time=\"17:00:00\")[0]\n",
    "data_1700_test = FUNCTION_2(data_1700, time=\"17:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_1700_train[data_1700_train.columns[2:]].values\n",
    "X_test = data_1700_test[data_0800_test.columns[2:]].values\n",
    "\n",
    "y_train = data_1700_train[\"Value\"].values\n",
    "y_test = data_1700_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 236.6995\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 224.7685\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 620us/step - loss: 215.1643\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 636us/step - loss: 209.9566\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 196.3671\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 180.6554\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 710us/step - loss: 177.0735\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 683us/step - loss: 167.6502\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 172.9166\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 637us/step - loss: 170.5934\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 693us/step - loss: 146.0322\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 155.6311\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 141.5236\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 141.3412\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 765us/step - loss: 158.6406\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 147.4423\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 153.4868\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 688us/step - loss: 162.3456\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 692us/step - loss: 159.5283\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 734us/step - loss: 143.7412\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 688us/step - loss: 148.4916\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 148.2280\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 141.9395\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 152.8036\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 156.6148\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 150.9777\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 745us/step - loss: 146.4349\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 137.9193\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 716us/step - loss: 145.4894\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 156.6450\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 716us/step - loss: 128.5799\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 774us/step - loss: 146.8638\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 704us/step - loss: 153.2652\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 709us/step - loss: 148.7139\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 688us/step - loss: 163.3979\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 141.5912\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 722us/step - loss: 147.8493\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 159.3160\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 628us/step - loss: 152.2542\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 708us/step - loss: 154.2720\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 149.0319\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 130.9064\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 143.7116\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 144.4750\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 129.5623\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 676us/step - loss: 153.8261\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 147.3693\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 148.5627\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 139.1939\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 149.5298\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 150.7679\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 676us/step - loss: 150.2558\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 695us/step - loss: 147.3291\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 755us/step - loss: 144.8480\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 160.6405\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 124.3475\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 143.4508\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 159.2361\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 139.2517\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 145.6628\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 626us/step - loss: 152.9232\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 703us/step - loss: 136.3279\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 756us/step - loss: 158.2409\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 124.7110\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 855us/step - loss: 156.4142\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 890us/step - loss: 152.6833\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 913us/step - loss: 130.0046\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 805us/step - loss: 137.9246\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 781us/step - loss: 149.9757\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 169.1133\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 780us/step - loss: 144.9875\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 809us/step - loss: 145.8118\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 791us/step - loss: 140.9002\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 787us/step - loss: 157.8022\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 142.0759\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 762us/step - loss: 165.1708\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 749us/step - loss: 157.1269\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 153.7874\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 716us/step - loss: 136.4669\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 716us/step - loss: 147.5741\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 171.4088\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 136.1273\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 148.7331\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 157.5871\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 156.2594\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 134.9631\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 127.2532\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 145.0002\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 128.3887\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 626us/step - loss: 151.3371\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 150.2588\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 140.1151\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 148.3508\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 631us/step - loss: 142.4340\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 149.4249\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 633us/step - loss: 144.0974\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 689us/step - loss: 151.5165\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 140.6274\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 642us/step - loss: 144.0768\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 634us/step - loss: 148.9905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af3ecbd3c8>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0537]\n",
      " [ 9.4773]\n",
      " [10.5952]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 11.4314\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 720us/step - loss: 11.0844\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 642us/step - loss: 10.7861\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 598us/step - loss: 10.5129\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 643us/step - loss: 10.3678\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 622us/step - loss: 9.8079\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 9.8964\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 9.8249\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 625us/step - loss: 9.4422\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 627us/step - loss: 9.5050\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 755us/step - loss: 9.3262\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 794us/step - loss: 9.4303\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 720us/step - loss: 8.7928\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 9.2126\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 9.1322\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 854us/step - loss: 9.2543\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 741us/step - loss: 9.4705\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 702us/step - loss: 8.4645\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 693us/step - loss: 8.6369\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 8.2151\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 689us/step - loss: 8.5029\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 688us/step - loss: 8.6395\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 757us/step - loss: 8.3065\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 699us/step - loss: 9.1829\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 8.0555\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 726us/step - loss: 8.8123\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 771us/step - loss: 8.5779\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 685us/step - loss: 7.5664\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 732us/step - loss: 8.7439\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 690us/step - loss: 8.5624\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 8.3740\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 705us/step - loss: 8.8329\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 741us/step - loss: 8.2213\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 751us/step - loss: 8.2354\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 8.0026\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 723us/step - loss: 8.3872\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 8.4450\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 8.2882\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 8.7286\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 8.5137\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 842us/step - loss: 8.1186\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 691us/step - loss: 8.3326\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 8.7167\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 699us/step - loss: 8.9284\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 688us/step - loss: 8.3502\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 8.5146\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 685us/step - loss: 8.5295\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 8.6027\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 8.0717\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 716us/step - loss: 8.2762\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 698us/step - loss: 8.4664\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 8.1081\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 692us/step - loss: 8.4925\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 767us/step - loss: 8.4107\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 779us/step - loss: 8.3048\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 785us/step - loss: 7.7676\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 715us/step - loss: 8.0187\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 7.8657\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 726us/step - loss: 7.6492\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 8.3699\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 8.0551\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 676us/step - loss: 8.0943\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 704us/step - loss: 7.6958\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 7.8164\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 8.1325\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 7.8002\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 632us/step - loss: 7.9650\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 7.8851\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 721us/step - loss: 7.9924\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 627us/step - loss: 8.2749\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 8.0930\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 700us/step - loss: 8.6548\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 676us/step - loss: 8.5923\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 728us/step - loss: 8.0359\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 676us/step - loss: 7.9460\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 7.2883\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 706us/step - loss: 8.4368\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 685us/step - loss: 7.9245\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 8.2060\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 8.3382\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 8.6991\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 8.3844\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 8.1079\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 698us/step - loss: 8.0002\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 705us/step - loss: 8.3358\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 8.3356\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 690us/step - loss: 7.8493\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 629us/step - loss: 8.5793\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 797us/step - loss: 8.1351\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 685us/step - loss: 7.7999\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 637us/step - loss: 8.3033\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 698us/step - loss: 8.4708\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 798us/step - loss: 8.3599\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 744us/step - loss: 8.0691\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 770us/step - loss: 7.8124\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 724us/step - loss: 8.6819\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 8.0776\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 8.3306\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 8.9371\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 693us/step - loss: 7.6557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af3f63a208>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0778]\n",
      " [10.6165]\n",
      " [10.6982]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1800 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1800 = pd.DataFrame()\n",
    "data_1800 = FUNCTION_1(data = data3, dataframe_new = data_1800, time = \"18:00:00\")\n",
    "data_1800_train = FUNCTION_2(data_1800, time=\"18:00:00\")[0]\n",
    "data_1800_test = FUNCTION_2(data_1800, time=\"18:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_1800_train[data_1800_train.columns[2:]].values\n",
    "X_test = data_1800_test[data_1800_test.columns[2:]].values\n",
    "\n",
    "y_train = data_1800_train[\"Value\"].values\n",
    "y_test = data_1800_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 23.8443\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 739us/step - loss: 20.1124\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 613us/step - loss: 17.9146\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 18.7049\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 18.0343\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 19.7386\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 16.9836\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 718us/step - loss: 18.0681\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 621us/step - loss: 16.7356\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 17.8806\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 695us/step - loss: 16.6039\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 17.3875\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 730us/step - loss: 18.4935\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 703us/step - loss: 17.5021\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 19.6662\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 19.0134\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 16.5776\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 15.9012\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 15.3555\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 628us/step - loss: 16.8877\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 17.2411\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 19.4828\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 14.5941\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 694us/step - loss: 17.0364\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 15.0636\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 16.5756\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 632us/step - loss: 17.2074\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 17.0995\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 636us/step - loss: 14.8814\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 636us/step - loss: 17.3738\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 683us/step - loss: 19.5794\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 625us/step - loss: 17.0845\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 17.1499\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 874us/step - loss: 15.0800\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 838us/step - loss: 16.4955\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 872us/step - loss: 18.4433\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 846us/step - loss: 19.3512\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 706us/step - loss: 19.8443\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 15.3675\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 18.5773\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 18.9567\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 16.6288\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 745us/step - loss: 15.5726\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 637us/step - loss: 14.0375\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 18.6280\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 637us/step - loss: 15.5217\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 678us/step - loss: 16.8428\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 688us/step - loss: 17.0374\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 700us/step - loss: 16.5241\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 18.3848\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 18.8225\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 18.3191\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 691us/step - loss: 16.0799\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 698us/step - loss: 17.7083\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 16.4712\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 18.0474\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 18.0969\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 16.0996\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 18.8153\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 17.8041\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 18.1891\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 17.1548\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 689us/step - loss: 18.1738\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 634us/step - loss: 17.4954\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 17.8168\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 16.0592\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 635us/step - loss: 17.8658\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 624us/step - loss: 17.6584\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 14.7657\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 628us/step - loss: 17.2341\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 17.3216\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 635us/step - loss: 15.6817\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 17.8987\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 599us/step - loss: 17.6043\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 15.1417\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 16.1475\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 17.4076\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 618us/step - loss: 20.0683\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 683us/step - loss: 17.5813\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 18.1666\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 620us/step - loss: 16.8245\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 692us/step - loss: 16.4912\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 17.7945\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 18.1147\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 632us/step - loss: 18.7825\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 15.9706\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 17.3417\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 637us/step - loss: 16.8608\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 685us/step - loss: 16.4680\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 635us/step - loss: 17.8416\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 684us/step - loss: 17.5557\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 638us/step - loss: 17.7010\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 635us/step - loss: 16.5736\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 678us/step - loss: 18.5790\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 628us/step - loss: 15.8411\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 17.6034\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 16.8487\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 14.0173\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 619us/step - loss: 16.9015\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 18.6547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af40fce6d8>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0433]\n",
      " [2.1198]\n",
      " [4.3483]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 3.4340\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 3.0967\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 2.7272\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 609us/step - loss: 2.5700\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 2.5327\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 2.4392\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 2.6141\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 2.4125\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 2.4418\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 610us/step - loss: 2.4946\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 2.5546\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 2.2907\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 2.3690\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 2.2417\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 629us/step - loss: 2.5272\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 615us/step - loss: 2.2795\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 2.4010\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 2.5779\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 2.2387\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 2.3069\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 2.3726\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 2.3294\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 2.1587\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 616us/step - loss: 2.3209\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 2.5115\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 688us/step - loss: 2.4253\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 2.3559\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 2.2453\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 683us/step - loss: 2.4271\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 2.4355\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 2.3442\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 2.3970\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 2.4909\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 2.4486\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 2.3215\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 2.2918\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 614us/step - loss: 2.4423\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 642us/step - loss: 2.4330\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 2.3347\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 2.5708\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 2.4166\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 2.3844\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 2.4368\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 2.5714\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 2.5463\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 2.4916\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 681us/step - loss: 2.4422\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 2.3424\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 2.1957\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 2.5116\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 2.4155\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 2.3715\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 692us/step - loss: 2.3375\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 633us/step - loss: 2.3590\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 631us/step - loss: 2.3586\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 683us/step - loss: 2.3117\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 2.4746\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 2.4601\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 2.2480\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 625us/step - loss: 2.2617\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 620us/step - loss: 2.3678\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 2.2762\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 2.4209\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 2.2383\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 2.3537\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 2.3260\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 643us/step - loss: 2.3313\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 635us/step - loss: 2.6193\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 614us/step - loss: 2.3214\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 2.5599\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 607us/step - loss: 2.4232\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 588us/step - loss: 2.3787\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 633us/step - loss: 2.2720\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 2.1871\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 637us/step - loss: 2.1212\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 639us/step - loss: 2.4092\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 2.1908\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 2.3040\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 2.2511\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 637us/step - loss: 2.3387\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 625us/step - loss: 2.4667\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 2.4663\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 2.7087\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 597us/step - loss: 2.3400\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 2.2969\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 610us/step - loss: 2.2714\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 619us/step - loss: 2.2098\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 634us/step - loss: 2.3947\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 2.4372\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 604us/step - loss: 2.4479\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 633us/step - loss: 2.5252\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 2.3167\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 621us/step - loss: 2.2824\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 2.4536\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 2.3082\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 2.3349\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 639us/step - loss: 2.4307\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 627us/step - loss: 2.2892\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 2.3849\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 621us/step - loss: 2.3480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af419544a8>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0173]\n",
      " [2.2326]\n",
      " [4.6661]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1900 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1900 = pd.DataFrame()\n",
    "data_1900 = FUNCTION_1(data = data3, dataframe_new = data_1900, time = \"19:00:00\")\n",
    "data_1900_train = FUNCTION_2(data_1900, time=\"19:00:00\")[0]\n",
    "data_1900_test = FUNCTION_2(data_1900, time=\"19:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_1900_train[data_1900_train.columns[2:]].values\n",
    "X_test = data_1900_test[data_1900_test.columns[2:]].values\n",
    "\n",
    "y_train = data_1900_train[\"Value\"].values\n",
    "y_test = data_1900_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 0.3665\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 0.3375\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 0.3464\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 626us/step - loss: 0.3197\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 0.3729\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 0.2825\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 0.3334\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 0.3793\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 0.3309\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 0.3086\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 0.3600\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 0.3095\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 0.3899\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 0.3579\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 0.2676\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 0.3591\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 629us/step - loss: 0.3334\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 0.3065\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 0.3790\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 0.3970\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 0.2739\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 0.3225\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 0.3160\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 0.2990\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 0.3384\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 0.3021\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 0.2683\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 0.2442\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 0.3116\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 702us/step - loss: 0.3083\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 620us/step - loss: 0.3040\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 0.3367\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 0.3288\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 732us/step - loss: 0.3176\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 0.2846\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 0.3128\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 0.2930\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 0.3431\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 0.3090\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 0.3411\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 0.3380\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 0.3336\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 0.3338\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 0.3246\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 711us/step - loss: 0.3071\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 0.3219\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 0.3776\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 0.3427\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 0.3840\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 0.3024\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 0.3520\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 0.3411\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 694us/step - loss: 0.3737\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 631us/step - loss: 0.2932\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 0.3311\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 0.3200\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 633us/step - loss: 0.3515\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 0.3631\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 620us/step - loss: 0.3142\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 0.3185\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 0.3551\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 618us/step - loss: 0.2524\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 0.3400\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 0.3006\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 0.3292\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 604us/step - loss: 0.3625\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 0.3813\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 0.3105\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 636us/step - loss: 0.3451\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 622us/step - loss: 0.3528\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 622us/step - loss: 0.3072\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 0.3246\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 637us/step - loss: 0.3568\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 612us/step - loss: 0.3019\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 637us/step - loss: 0.3468\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 624us/step - loss: 0.3113\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 0.3387\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 0.2919\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 618us/step - loss: 0.2861\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 635us/step - loss: 0.2881\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 0.2858\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 0.2795\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 0.3102\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 631us/step - loss: 0.3347\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 683us/step - loss: 0.2950\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 683us/step - loss: 0.2977\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 634us/step - loss: 0.2306\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 0.2935\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 0.2758\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 0.3005\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 619us/step - loss: 0.2750\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 0.3722\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 625us/step - loss: 0.2902\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 0.3454\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 0.3121\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 605us/step - loss: 0.3500\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 676us/step - loss: 0.3353\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 623us/step - loss: 0.2918\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 0.3565\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 0.3216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af432cc128>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0031]\n",
      " [ 0.0134]\n",
      " [ 0.667 ]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 0.3046 - accuracy: 0.3761\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 692us/step - loss: 0.2730 - accuracy: 0.3761\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 697us/step - loss: 0.2482 - accuracy: 0.3761\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 609us/step - loss: 0.2603 - accuracy: 0.3761\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 626us/step - loss: 0.2565 - accuracy: 0.3761\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 0.2513 - accuracy: 0.3761\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 683us/step - loss: 0.2434 - accuracy: 0.3761\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 0.2583 - accuracy: 0.3761\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 712us/step - loss: 0.2649 - accuracy: 0.3761\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 632us/step - loss: 0.2454 - accuracy: 0.3761\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 676us/step - loss: 0.2438 - accuracy: 0.3761\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 689us/step - loss: 0.2531 - accuracy: 0.3761\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 689us/step - loss: 0.2787 - accuracy: 0.3761\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 681us/step - loss: 0.2485 - accuracy: 0.3761\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 707us/step - loss: 0.2459 - accuracy: 0.3761\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 0.2598 - accuracy: 0.3761\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 0.2434 - accuracy: 0.3761\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 0.2516 - accuracy: 0.3761\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 0.2432 - accuracy: 0.3761\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 0.2716 - accuracy: 0.3761\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 685us/step - loss: 0.2558 - accuracy: 0.3761\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 702us/step - loss: 0.2434 - accuracy: 0.3761\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 0.2595 - accuracy: 0.3761\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 0.2454 - accuracy: 0.3761\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 700us/step - loss: 0.2555 - accuracy: 0.3761\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 712us/step - loss: 0.2435 - accuracy: 0.3761\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 0.2497 - accuracy: 0.3761\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 689us/step - loss: 0.2244 - accuracy: 0.3761\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 0.2701 - accuracy: 0.3761\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 678us/step - loss: 0.2591 - accuracy: 0.3761\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 0.2719 - accuracy: 0.3761\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 0.2445 - accuracy: 0.3761\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 726us/step - loss: 0.2475 - accuracy: 0.3761\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 627us/step - loss: 0.2492 - accuracy: 0.3761\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 0.2531 - accuracy: 0.3761\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 0.2396 - accuracy: 0.3761\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 705us/step - loss: 0.2547 - accuracy: 0.3761\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 717us/step - loss: 0.2805 - accuracy: 0.3761\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 786us/step - loss: 0.2387 - accuracy: 0.3761\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 746us/step - loss: 0.2350 - accuracy: 0.3761\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 737us/step - loss: 0.2519 - accuracy: 0.3761\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 690us/step - loss: 0.2624 - accuracy: 0.3761\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 746us/step - loss: 0.2409 - accuracy: 0.3761\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 692us/step - loss: 0.2440 - accuracy: 0.3761\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 701us/step - loss: 0.2319 - accuracy: 0.3761\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 711us/step - loss: 0.2418 - accuracy: 0.3761\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 685us/step - loss: 0.2657 - accuracy: 0.3761\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 0.2412 - accuracy: 0.3761\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 691us/step - loss: 0.2560 - accuracy: 0.3761\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 0.2488 - accuracy: 0.3761\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 683us/step - loss: 0.2580 - accuracy: 0.3761\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 0.2503 - accuracy: 0.3761\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 723us/step - loss: 0.2449 - accuracy: 0.3761\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 0.2620 - accuracy: 0.3761\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 0.2662 - accuracy: 0.3761\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 0.2593 - accuracy: 0.3761\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 0.2527 - accuracy: 0.3761\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 0.2578 - accuracy: 0.3761\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 690us/step - loss: 0.2437 - accuracy: 0.3761\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 0.2380 - accuracy: 0.3761\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 0.2498 - accuracy: 0.3761\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 714us/step - loss: 0.2481 - accuracy: 0.3761\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 639us/step - loss: 0.2458 - accuracy: 0.3761\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 721us/step - loss: 0.2538 - accuracy: 0.3761\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 684us/step - loss: 0.2453 - accuracy: 0.3761\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 684us/step - loss: 0.2522 - accuracy: 0.3761\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 697us/step - loss: 0.2599 - accuracy: 0.3761\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 0.2576 - accuracy: 0.3761\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 734us/step - loss: 0.2550 - accuracy: 0.3761\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 727us/step - loss: 0.2423 - accuracy: 0.3761\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 0.2541 - accuracy: 0.3761\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 719us/step - loss: 0.2398 - accuracy: 0.3761\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 743us/step - loss: 0.2557 - accuracy: 0.3761\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 717us/step - loss: 0.2403 - accuracy: 0.3761\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 698us/step - loss: 0.2472 - accuracy: 0.3761\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 684us/step - loss: 0.2660 - accuracy: 0.3761\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 700us/step - loss: 0.2173 - accuracy: 0.3761\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 0.2576 - accuracy: 0.3761\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 718us/step - loss: 0.2607 - accuracy: 0.3761\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 0.2475 - accuracy: 0.3761\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 698us/step - loss: 0.2674 - accuracy: 0.3761\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 721us/step - loss: 0.2471 - accuracy: 0.3761\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 0.2397 - accuracy: 0.3761\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 705us/step - loss: 0.2597 - accuracy: 0.3761\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 699us/step - loss: 0.2363 - accuracy: 0.3761\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 0.2514 - accuracy: 0.3761\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 713us/step - loss: 0.2441 - accuracy: 0.3761\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 717us/step - loss: 0.2620 - accuracy: 0.3761\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 706us/step - loss: 0.2377 - accuracy: 0.3761\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 696us/step - loss: 0.2632 - accuracy: 0.3761\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 705us/step - loss: 0.2437 - accuracy: 0.3761\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 731us/step - loss: 0.2518 - accuracy: 0.3761\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 723us/step - loss: 0.2541 - accuracy: 0.3761\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 0.2563 - accuracy: 0.3761\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 0.2430 - accuracy: 0.3761\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 683us/step - loss: 0.2443 - accuracy: 0.3761\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 722us/step - loss: 0.2324 - accuracy: 0.3761\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 867us/step - loss: 0.2359 - accuracy: 0.3761\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 716us/step - loss: 0.2339 - accuracy: 0.3761\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 0.2552 - accuracy: 0.3761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af44c2a278>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.000e-04]\n",
      " [ 1.800e-02]\n",
      " [ 7.229e-01]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2000 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2000 = pd.DataFrame()\n",
    "data_2000 = FUNCTION_1(data = data3, dataframe_new = data_2000, time = \"20:00:00\")\n",
    "data_2000_train = FUNCTION_2(data_2000, time=\"20:00:00\")[0]\n",
    "data_2000_test = FUNCTION_2(data_2000, time=\"20:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_2000_train[data_2000_train.columns[2:]].values\n",
    "X_test = data_2000_test[data_2000_test.columns[2:]].values\n",
    "\n",
    "y_train = data_2000_train[\"Value\"].values\n",
    "y_test = data_2000_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 1.2163e-04\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 712us/step - loss: 9.4359e-05\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 633us/step - loss: 1.0414e-04\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 638us/step - loss: 9.1159e-05\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 690us/step - loss: 8.6034e-05\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 741us/step - loss: 9.1115e-05\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 713us/step - loss: 9.5706e-05\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 9.6413e-05\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 8.7579e-05\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 688us/step - loss: 8.1206e-05\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 9.8723e-05\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 7.2654e-05\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 697us/step - loss: 8.6939e-05\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 676us/step - loss: 7.8584e-05\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 8.2181e-05\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 8.0630e-05\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 7.8433e-05\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 681us/step - loss: 8.9861e-05\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 693us/step - loss: 9.6436e-05\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 7.0119e-05\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 775us/step - loss: 1.0087e-04\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 772us/step - loss: 9.2855e-05\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 932us/step - loss: 8.6186e-05\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 923us/step - loss: 8.9981e-05\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 976us/step - loss: 9.7990e-05\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 699us/step - loss: 8.8736e-05\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 692us/step - loss: 9.3256e-05\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 748us/step - loss: 9.8049e-05\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 717us/step - loss: 8.9924e-05\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 821us/step - loss: 9.4900e-05\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 732us/step - loss: 9.1393e-05\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 708us/step - loss: 1.1311e-04\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 717us/step - loss: 9.6962e-05\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 678us/step - loss: 7.9830e-05\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 692us/step - loss: 9.7793e-05\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 1.0309e-04\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 9.7560e-05\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 9.3784e-05\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 1.0633e-04\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 9.7553e-05\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 711us/step - loss: 8.4157e-05\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 9.7526e-05\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 710us/step - loss: 1.0169e-04\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 1.0049e-04\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 8.3001e-05\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 9.2679e-05\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 7.9723e-05\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 8.9475e-05\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 1.0664e-04\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 8.1978e-05\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 9.7776e-05\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 7.9472e-05\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 684us/step - loss: 9.7692e-05\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 1.0086e-04\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 636us/step - loss: 8.1751e-05\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 624us/step - loss: 9.5431e-05\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 615us/step - loss: 9.4436e-05\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 8.6444e-05\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 8.5597e-05\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 9.8491e-05\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 9.7997e-05\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 1.0685e-04\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 1.1413e-04\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 626us/step - loss: 9.7590e-05\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 743us/step - loss: 8.6314e-05\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 626us/step - loss: 7.8343e-05\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 623us/step - loss: 8.4431e-05\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 6.9290e-05\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 715us/step - loss: 1.0900e-04\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 7.3816e-05\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 8.6106e-05\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 8.4573e-05\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 1.0553e-04\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 691us/step - loss: 8.7328e-05\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 749us/step - loss: 8.9857e-05\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 864us/step - loss: 1.0316e-04\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 1.0074e-04\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 807us/step - loss: 9.7342e-05\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 746us/step - loss: 8.3048e-05\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 9.0953e-05\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 818us/step - loss: 9.2678e-05\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 8.3910e-05\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 8.4722e-05\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 1.0090e-04\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 856us/step - loss: 7.5040e-05\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 630us/step - loss: 9.6155e-05\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 783us/step - loss: 1.1147e-04\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 645us/step - loss: 9.4604e-05\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 710us/step - loss: 1.0688e-04\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 762us/step - loss: 8.8135e-05\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 726us/step - loss: 9.4069e-05\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 703us/step - loss: 7.6049e-05\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 694us/step - loss: 9.5738e-05\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 613us/step - loss: 7.1697e-05\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 681us/step - loss: 8.6852e-05\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 9.5644e-05\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 639us/step - loss: 9.5520e-05\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 8.7021e-05\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 631us/step - loss: 7.8585e-05\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 630us/step - loss: 9.3025e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af465f5630>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0004]\n",
      " [0.0004]\n",
      " [0.0098]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 0.0046\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 727us/step - loss: 0.0044\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 0.0043\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 817us/step - loss: 0.0035\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 688us/step - loss: 0.0041\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 0.0039\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 0.0041\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 717us/step - loss: 0.0035\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 684us/step - loss: 0.0037\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 0.0033\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 0.0035\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 714us/step - loss: 0.0039\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 688us/step - loss: 0.0040\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 692us/step - loss: 0.0035\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 638us/step - loss: 0.0041\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 731us/step - loss: 0.0033\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 0.0037\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 0.0036\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 699us/step - loss: 0.0036\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 693us/step - loss: 0.0035\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 635us/step - loss: 0.0034\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 729us/step - loss: 0.0034\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 684us/step - loss: 0.0035\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 632us/step - loss: 0.0038\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 712us/step - loss: 0.0040\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 685us/step - loss: 0.0033\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 0.0036\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 719us/step - loss: 0.0031\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 625us/step - loss: 0.0039\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 734us/step - loss: 0.0040\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 0.0035\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 0.0036\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 717us/step - loss: 0.0036\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 0.0033\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 0.0033\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 0.0035\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 689us/step - loss: 0.0041\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 679us/step - loss: 0.0037\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 684us/step - loss: 0.0038\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 0.0040\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 0.0037\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 711us/step - loss: 0.0036\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 716us/step - loss: 0.0035\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 697us/step - loss: 0.0034\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 0.0036\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 0.0042\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 635us/step - loss: 0.0032\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 0.0035\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 0.0036\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 0.0034\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 0.0034\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 0.0035\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 0.0035\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 0.0036\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 0.0032\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 631us/step - loss: 0.0034\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 0.0035\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 0.0030\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 684us/step - loss: 0.0037\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 0.0036\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 0.0034\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 630us/step - loss: 0.0034\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 631us/step - loss: 0.0032\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 0.0038\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 0.0038\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 0.0034\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 0.0036\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 0.0038\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 0.0036\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 638us/step - loss: 0.0036\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 0.0038\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 624us/step - loss: 0.0033\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 0.0034\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 652us/step - loss: 0.0036\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 0.0036\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 0.0036\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 621us/step - loss: 0.0037\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 619us/step - loss: 0.0035\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 0.0030\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 0.0030\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 0.0040\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 0.0041\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 639us/step - loss: 0.0036\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 0.0037\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 0.0034\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 681us/step - loss: 0.0034\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 0.0038\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 0.0033\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 629us/step - loss: 0.0034\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 0.0036\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 0.0039\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 625us/step - loss: 0.0036\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 684us/step - loss: 0.0032\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 0.0032\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 0.0034\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 622us/step - loss: 0.0035\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 0.0035\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 672us/step - loss: 0.0033\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 0.0033\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 0.0038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af46f6b978>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0e-04]\n",
      " [1.0e-04]\n",
      " [8.9e-03]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2100 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2100 = pd.DataFrame()\n",
    "data_2100 = FUNCTION_1(data = data3, dataframe_new = data_2100, time = \"21:00:00\")\n",
    "data_2100_train = FUNCTION_2(data_2100, time=\"21:00:00\")[0]\n",
    "data_2100_test = FUNCTION_2(data_2100, time=\"21:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 7)\n",
      "(3, 7)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_2100_train[data_2100_train.columns[2:]].values\n",
    "X_test = data_2100_test[data_2100_test.columns[2:]].values\n",
    "\n",
    "y_train = data_2100_train[\"Value\"].values\n",
    "y_test = data_2100_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(335, 7, 1)\n",
      "(3, 7, 1)\n",
      "(335,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 700us/step - loss: 0.0000e+00 0s - loss: 0.0000e+\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 631us/step - loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 714us/step - loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 625us/step - loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 703us/step - loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 635us/step - loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 715us/step - loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 633us/step - loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 724us/step - loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 651us/step - loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 715us/step - loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 635us/step - loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 685us/step - loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 665us/step - loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 723us/step - loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 688us/step - loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 724us/step - loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 639us/step - loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 707us/step - loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 712us/step - loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 715us/step - loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 716us/step - loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 716us/step - loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 688us/step - loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 706us/step - loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 771us/step - loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 808us/step - loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 752us/step - loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 614us/step - loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 661us/step - loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 690us/step - loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 674us/step - loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 611us/step - loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 635us/step - loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 622us/step - loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 621us/step - loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 624us/step - loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 631us/step - loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 682us/step - loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 685us/step - loss: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 662us/step - loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 635us/step - loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 637us/step - loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 678us/step - loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af4a1a5860>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 1s 2ms/step - loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 0s 732us/step - loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 0s 603us/step - loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 0s 650us/step - loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 0s 698us/step - loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 0s 644us/step - loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 0s 676us/step - loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 0s 653us/step - loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 0s 669us/step - loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 0s 676us/step - loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 0s 718us/step - loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 0s 748us/step - loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 0s 789us/step - loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 0s 820us/step - loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 0s 784us/step - loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 0s 866us/step - loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 0s 801us/step - loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 0s 784us/step - loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 0s 793us/step - loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 0s 796us/step - loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 0s 776us/step - loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 0s 746us/step - loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 0s 725us/step - loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 0s 675us/step - loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 0s 663us/step - loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 0s 680us/step - loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 0s 687us/step - loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 0s 670us/step - loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 0s 667us/step - loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 0s 654us/step - loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 0s 683us/step - loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 0s 666us/step - loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 0s 660us/step - loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 0s 664us/step - loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 0s 668us/step - loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 0s 685us/step - loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 0s 684us/step - loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 0s 640us/step - loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 0s 649us/step - loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 0s 647us/step - loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 0s 641us/step - loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 0s 623us/step - loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 0s 613us/step - loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 0s 611us/step - loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 0s 633us/step - loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 0s 615us/step - loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 0s 671us/step - loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 0s 600us/step - loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 0s 646us/step - loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 0s 648us/step - loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 0s 615us/step - loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 0s 673us/step - loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 0s 638us/step - loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 0s 704us/step - loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 0s 694us/step - loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "335/335 [==============================] - 0s 659us/step - loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "335/335 [==============================] - 0s 655us/step - loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "335/335 [==============================] - 0s 686us/step - loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "335/335 [==============================] - 0s 677us/step - loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "335/335 [==============================] - 0s 739us/step - loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "335/335 [==============================] - 0s 658us/step - loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "335/335 [==============================] - 0s 656us/step - loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "335/335 [==============================] - 0s 657us/step - loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af4a244278>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2200 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2200 = pd.DataFrame()\n",
    "data_2200 = FUNCTION_1(data = data3, dataframe_new = data_2200, time = \"22:00:00\")\n",
    "data_2200_train = FUNCTION_2(data_2200, time=\"22:00:00\")[0]\n",
    "data_2200_test = FUNCTION_2(data_2200, time=\"22:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(334, 7)\n",
      "(3, 7)\n",
      "(334,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_2200_train[data_2200_train.columns[2:]].values\n",
    "X_test = data_2200_test[data_2200_test.columns[2:]].values\n",
    "\n",
    "y_train = data_2200_train[\"Value\"].values\n",
    "y_test = data_2200_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(334, 7, 1)\n",
      "(3, 7, 1)\n",
      "(334,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 0s 710us/step - loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 0s 676us/step - loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 0s 643us/step - loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 0s 668us/step - loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 0s 752us/step - loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 0s 689us/step - loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 0s 657us/step - loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 0s 660us/step - loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 0s 663us/step - loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 0s 659us/step - loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 0s 689us/step - loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 0s 688us/step - loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 0s 688us/step - loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 0s 689us/step - loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 0s 688us/step - loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 0s 650us/step - loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 0s 636us/step - loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 0s 628us/step - loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 0s 662us/step - loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 0s 731us/step - loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 0s 682us/step - loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 0s 697us/step - loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 0s 806us/step - loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 0s 961us/step - loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 0s 817us/step - loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 0s 785us/step - loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 0s 781us/step - loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 0s 708us/step - loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 0s 680us/step - loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 0s 770us/step - loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 0s 804us/step - loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 0s 817us/step - loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 0s 878us/step - loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 0s 920us/step - loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 0s 853us/step - loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 0s 844us/step - loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 0s 890us/step - loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 0s 824us/step - loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 0s 724us/step - loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - 0s 796us/step - loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 0s 830us/step - loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 0s 818us/step - loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 0s 876us/step - loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 0s 750us/step - loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 0s 713us/step - loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 0s 800us/step - loss: 0.0000e+00 0s - loss: 0.0000e+\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 0s 791us/step - loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 0s 694us/step - loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 0s 751us/step - loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 0s 784us/step - loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 0s 760us/step - loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 0s 723us/step - loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 0s 879us/step - loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 0s 826us/step - loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 0s 825us/step - loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 0s 764us/step - loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - 0s 696us/step - loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - 0s 643us/step - loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 0s 663us/step - loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 0s 708us/step - loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 0s 661us/step - loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 0s 638us/step - loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 0s 678us/step - loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 0s 717us/step - loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 0s 745us/step - loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 0s 670us/step - loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 0s 665us/step - loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "334/334 [==============================] - 0s 777us/step - loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 0s 724us/step - loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "334/334 [==============================] - 0s 744us/step - loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "334/334 [==============================] - 0s 838us/step - loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "334/334 [==============================] - 0s 689us/step - loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "334/334 [==============================] - 0s 718us/step - loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "334/334 [==============================] - 0s 658us/step - loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "334/334 [==============================] - 0s 780us/step - loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "334/334 [==============================] - 0s 812us/step - loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "334/334 [==============================] - 0s 775us/step - loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "334/334 [==============================] - 0s 724us/step - loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "334/334 [==============================] - 0s 771us/step - loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "334/334 [==============================] - 0s 690us/step - loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "334/334 [==============================] - 0s 714us/step - loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "334/334 [==============================] - 0s 726us/step - loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "334/334 [==============================] - 0s 749us/step - loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "334/334 [==============================] - 0s 691us/step - loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "334/334 [==============================] - 0s 627us/step - loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "334/334 [==============================] - 0s 738us/step - loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "334/334 [==============================] - 0s 798us/step - loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "334/334 [==============================] - 0s 991us/step - loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "334/334 [==============================] - 0s 869us/step - loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "334/334 [==============================] - 0s 841us/step - loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "334/334 [==============================] - 0s 920us/step - loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "334/334 [==============================] - 0s 854us/step - loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af498badd8>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 0s 829us/step - loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 0s 923us/step - loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 0s 933us/step - loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 0s 953us/step - loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 0s 815us/step - loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 0s 795us/step - loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 0s 797us/step - loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 0s 796us/step - loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 0s 799us/step - loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 0s 886us/step - loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 0s 831us/step - loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 0s 947us/step - loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 0s 908us/step - loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 0s 944us/step - loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 0s 994us/step - loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 0s 813us/step - loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 0s 816us/step - loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 0s 832us/step - loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 0s 811us/step - loss: 0.0000e+00 0s - loss: 0.0000e\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 0s 767us/step - loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 0s 805us/step - loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 0s 821us/step - loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 0s 774us/step - loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 0s 800us/step - loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 0s 797us/step - loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 0s 798us/step - loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 0s 787us/step - loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 0s 790us/step - loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 0s 780us/step - loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 0s 811us/step - loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 0s 803us/step - loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 0s 788us/step - loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 0s 808us/step - loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 0s 795us/step - loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 0s 806us/step - loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 0s 800us/step - loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 0s 782us/step - loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 0s 763us/step - loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 0s 809us/step - loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 0s 796us/step - loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - 0s 787us/step - loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 0s 826us/step - loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 0s 813us/step - loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 0s 781us/step - loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 0s 778us/step - loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 0s 846us/step - loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 0s 861us/step - loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 0s 811us/step - loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 0s 797us/step - loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 0s 776us/step - loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 0s 932us/step - loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 0s 1ms/step - loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 0s 971us/step - loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 0s 830us/step - loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - 0s 801us/step - loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - 0s 781us/step - loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 0s 805us/step - loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 0s 792us/step - loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 0s 754us/step - loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 0s 842us/step - loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 0s 790us/step - loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 0s 794us/step - loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 0s 767us/step - loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 0s 825us/step - loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 0s 785us/step - loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "334/334 [==============================] - 0s 824us/step - loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 0s 775us/step - loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "334/334 [==============================] - 0s 782us/step - loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "334/334 [==============================] - 0s 792us/step - loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "334/334 [==============================] - 0s 820us/step - loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "334/334 [==============================] - 0s 898us/step - loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "334/334 [==============================] - 0s 872us/step - loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "334/334 [==============================] - 0s 823us/step - loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "334/334 [==============================] - 0s 761us/step - loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "334/334 [==============================] - 0s 813us/step - loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "334/334 [==============================] - 0s 824us/step - loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "334/334 [==============================] - 0s 764us/step - loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "334/334 [==============================] - 0s 801us/step - loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "334/334 [==============================] - 0s 761us/step - loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "334/334 [==============================] - 0s 791us/step - loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "334/334 [==============================] - 0s 784us/step - loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "334/334 [==============================] - 0s 797us/step - loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "334/334 [==============================] - 0s 821us/step - loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "334/334 [==============================] - 0s 769us/step - loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "334/334 [==============================] - 0s 784us/step - loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "334/334 [==============================] - 0s 797us/step - loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "334/334 [==============================] - 0s 769us/step - loss: 0.0000e+00\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334/334 [==============================] - 0s 806us/step - loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "334/334 [==============================] - 0s 795us/step - loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "334/334 [==============================] - 0s 789us/step - loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "334/334 [==============================] - 0s 815us/step - loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "334/334 [==============================] - 0s 753us/step - loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "334/334 [==============================] - 0s 790us/step - loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "334/334 [==============================] - 0s 784us/step - loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "334/334 [==============================] - 0s 768us/step - loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af4c54f048>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2300 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2300 = pd.DataFrame()\n",
    "data_2300 = FUNCTION_1(data = data3, dataframe_new = data_2300, time = \"23:00:00\")\n",
    "data_2300_train = FUNCTION_2(data_2300, time=\"23:00:00\")[0]\n",
    "data_2300_test = FUNCTION_2(data_2300, time=\"23:00:00\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(334, 7)\n",
      "(3, 7)\n",
      "(334,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_2300_train[data_2300_train.columns[2:]].values\n",
    "X_test = data_2300_test[data_2300_test.columns[2:]].values\n",
    "\n",
    "y_train = data_2300_train[\"Value\"].values\n",
    "y_test = data_2300_test[\"Value\"].values\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Data\n",
      "(334, 7, 1)\n",
      "(3, 7, 1)\n",
      "(334,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# 최종 트레이닝 셋\n",
    "X_train_t = X_train.reshape(X_train.shape[0],7,1)\n",
    "X_test_t = X_test.reshape(X_test.shape[0],7,1)\n",
    "\n",
    "print(\"최종 Data\")\n",
    "print(X_train_t.shape)\n",
    "print(X_test_t.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델 실행(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 0s 817us/step - loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 0s 802us/step - loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 0s 766us/step - loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 0s 782us/step - loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 0s 794us/step - loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 0s 770us/step - loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 0s 859us/step - loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 0s 825us/step - loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 0s 783us/step - loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 0s 805us/step - loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 0s 801us/step - loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 0s 763us/step - loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 0s 826us/step - loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 0s 769us/step - loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 0s 812us/step - loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 0s 797us/step - loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 0s 787us/step - loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 0s 803us/step - loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 0s 792us/step - loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 0s 816us/step - loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 0s 780us/step - loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 0s 839us/step - loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 0s 852us/step - loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 0s 787us/step - loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 0s 779us/step - loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 0s 837us/step - loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 0s 798us/step - loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 0s 821us/step - loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 0s 805us/step - loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 0s 798us/step - loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 0s 813us/step - loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 0s 773us/step - loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 0s 796us/step - loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 0s 797us/step - loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 0s 835us/step - loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 0s 803us/step - loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 0s 820us/step - loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 0s 762us/step - loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 0s 831us/step - loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 0s 808us/step - loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 0s 825us/step - loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0000e+00- ETA: 0s - loss: 0.0000e+ - 0s 774us/step - loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 0s 803us/step - loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 0s 795us/step - loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 0s 798us/step - loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 0s 781us/step - loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 0s 823us/step - loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 0s 798us/step - loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 0s 804us/step - loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 0s 837us/step - loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 0s 808us/step - loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 0s 797us/step - loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 0s 782us/step - loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 0s 829us/step - loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 0s 816us/step - loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 0s 796us/step - loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 0s 784us/step - loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 0s 823us/step - loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - 0s 768us/step - loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - 0s 813us/step - loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 0s 795us/step - loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 0s 820us/step - loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 0s 806us/step - loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 0s 790us/step - loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 0s 830us/step - loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 0s 771us/step - loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 0s 839us/step - loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 0s 812us/step - loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 0s 810us/step - loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "334/334 [==============================] - 0s 830us/step - loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 0s 782us/step - loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "334/334 [==============================] - 0s 800us/step - loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "334/334 [==============================] - 0s 788us/step - loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "334/334 [==============================] - 0s 798us/step - loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "334/334 [==============================] - 0s 792us/step - loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "334/334 [==============================] - 0s 799us/step - loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "334/334 [==============================] - 0s 810us/step - loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "334/334 [==============================] - 0s 804us/step - loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "334/334 [==============================] - 0s 841us/step - loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "334/334 [==============================] - 0s 781us/step - loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "334/334 [==============================] - 0s 833us/step - loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "334/334 [==============================] - 0s 783us/step - loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "334/334 [==============================] - 0s 864us/step - loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "334/334 [==============================] - 0s 783us/step - loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "334/334 [==============================] - 0s 813us/step - loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "334/334 [==============================] - 0s 790us/step - loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "334/334 [==============================] - 0s 835us/step - loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "334/334 [==============================] - 0s 793us/step - loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "334/334 [==============================] - 0s 816us/step - loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "334/334 [==============================] - 0s 795us/step - loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "334/334 [==============================] - 0s 787us/step - loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "334/334 [==============================] - 0s 776us/step - loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "334/334 [==============================] - 0s 759us/step - loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "334/334 [==============================] - 0s 802us/step - loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "334/334 [==============================] - 0s 793us/step - loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "334/334 [==============================] - 0s 778us/step - loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "334/334 [==============================] - 0s 757us/step - loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "334/334 [==============================] - 0s 815us/step - loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "334/334 [==============================] - 0s 749us/step - loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af4de71748>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,781\n",
      "Trainable params: 1,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape = (7,1)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss = 'mean_absolute_error', optimizer = 'adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 0s 816us/step - loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 0s 742us/step - loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 0s 810us/step - loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 0s 785us/step - loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 0s 800us/step - loss: 0.0000e+00 0s - loss: 0.0000e+\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 0s 799us/step - loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 0s 776us/step - loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 0s 838us/step - loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 0s 810us/step - loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 0s 796us/step - loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 0s 803us/step - loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 0s 796us/step - loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 0s 770us/step - loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 0s 810us/step - loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 0s 806us/step - loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 0s 766us/step - loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 0s 819us/step - loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 0s 807us/step - loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 0s 763us/step - loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 0s 844us/step - loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 0s 784us/step - loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 0s 858us/step - loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 0s 883us/step - loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 0s 831us/step - loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 0s 826us/step - loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 0s 794us/step - loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 0s 891us/step - loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 0s 811us/step - loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 0s 832us/step - loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 0s 828us/step - loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 0s 810us/step - loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 0s 804us/step - loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 0s 815us/step - loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 0s 807us/step - loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 0s 826us/step - loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 0s 825us/step - loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 0s 819us/step - loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 0s 816us/step - loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 0s 802us/step - loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 0s 795us/step - loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 0s 791us/step - loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - 0s 780us/step - loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 0s 840us/step - loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 0s 812us/step - loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 0s 814us/step - loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 0s 807us/step - loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 0s 827us/step - loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 0s 806us/step - loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 0s 809us/step - loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 0s 795us/step - loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 0s 806us/step - loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 0s 824us/step - loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 0s 751us/step - loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 0s 797us/step - loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 0s 764us/step - loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 0s 802us/step - loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 0s 805us/step - loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 0s 752us/step - loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - 0s 772us/step - loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - 0s 764us/step - loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 0s 814us/step - loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 0s 787us/step - loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 0s 780us/step - loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 0s 764us/step - loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 0s 815us/step - loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 0s 768us/step - loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 0s 794us/step - loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 0s 782us/step - loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 0s 795us/step - loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "334/334 [==============================] - 0s 796us/step - loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 0s 774us/step - loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "334/334 [==============================] - 0s 782us/step - loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "334/334 [==============================] - 0s 791us/step - loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "334/334 [==============================] - 0s 785us/step - loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "334/334 [==============================] - 0s 757us/step - loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "334/334 [==============================] - 0s 766us/step - loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "334/334 [==============================] - 0s 780us/step - loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "334/334 [==============================] - 0s 779us/step - loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "334/334 [==============================] - 0s 799us/step - loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0000e+0 - 0s 750us/step - loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "334/334 [==============================] - 0s 790us/step - loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "334/334 [==============================] - 0s 745us/step - loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "334/334 [==============================] - 0s 779us/step - loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "334/334 [==============================] - 0s 826us/step - loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "334/334 [==============================] - 0s 759us/step - loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "334/334 [==============================] - 0s 764us/step - loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "334/334 [==============================] - 0s 811us/step - loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "334/334 [==============================] - 0s 786us/step - loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "334/334 [==============================] - 0s 765us/step - loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "334/334 [==============================] - 0s 783us/step - loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "334/334 [==============================] - 0s 781us/step - loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "334/334 [==============================] - 0s 767us/step - loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "334/334 [==============================] - 0s 775us/step - loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "334/334 [==============================] - 0s 779us/step - loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "334/334 [==============================] - 0s 768us/step - loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "334/334 [==============================] - 0s 780us/step - loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "334/334 [==============================] - 0s 775us/step - loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "334/334 [==============================] - 0s 786us/step - loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "334/334 [==============================] - 0s 761us/step - loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1af4de59080>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_t,y_train, epochs = 100,\n",
    "         batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t).round(4)\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
